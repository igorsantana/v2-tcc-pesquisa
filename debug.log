[INFO ] 2018-05-22 11:37:57,758 -- WorkingPath: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/
[INFO ] 2018-05-22 11:37:57,770 -- Your original rating data path: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/reduzido.csv
[INFO ] 2018-05-22 11:37:57,771 -- Current working path: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/
[WARN ] 2018-05-22 11:37:57,775 -- You rating data is in Compact format. CARSKit is working on transformation on the data format...
[INFO ] 2018-05-22 11:37:58,066 -- Data transformaton completed (from Compact to Binary format). See new rating file: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/ratings_binary.txt
[INFO ] 2018-05-22 11:37:58,090 -- Dataset: ...ARSKit.Workspace/ratings_binary.txt
[INFO ] 2018-05-22 11:37:58,093 -- DataPath: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/ratings_binary.txt
[INFO ] 2018-05-22 11:37:58,619 -- Rating data set has been successfully loaded.
[INFO ] 2018-05-22 11:37:58,628 -- 
/***************************************************************************************************
 *
 * Dataset: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/ratings_binary.txt
 * 
 * Statistics of U-I-C Matrix:
 * User amount: 548
 * Item amount: 549
 * Rate amount: 607
 * Context dimensions: 2 (latitude, longitude)
 * Context conditions: 1096 (latitude: 548, longitude: 548)
 * Context situations: 547
 * Data density: 0.00000067185363493266%
 * Scale distribution: [2.0 x 61, 4.0 x 194, 1.0 x 33, 5.0 x 180, 3.0 x 139]
 * Average value of all ratings: 3.703460
 * Standard deviation of all ratings: 1.152765
 * Mode of all rating values: 4.000000
 * Median of all rating values: 4.000000
 *
 ***************************************************************************************************/
[INFO ] 2018-05-22 11:37:58,631 -- With Setup: cv -k 10 -p on --rand-seed 1 --test-view all
[DEBUG] 2018-05-22 11:37:58,640 -- Fold [1]: training amount: 546, test amount: 61
[DEBUG] 2018-05-22 11:37:58,647 -- Fold [2]: training amount: 546, test amount: 61
[DEBUG] 2018-05-22 11:37:58,662 -- Fold [3]: training amount: 546, test amount: 61
[DEBUG] 2018-05-22 11:37:58,679 -- Fold [4]: training amount: 547, test amount: 60
[DEBUG] 2018-05-22 11:37:58,699 -- Fold [5]: training amount: 546, test amount: 61
[DEBUG] 2018-05-22 11:37:58,728 -- Fold [6]: training amount: 546, test amount: 61
[DEBUG] 2018-05-22 11:37:58,756 -- Fold [7]: training amount: 547, test amount: 60
[DEBUG] 2018-05-22 11:37:58,840 -- Fold [8]: training amount: 546, test amount: 61
[DEBUG] 2018-05-22 11:37:58,847 -- Fold [9]: training amount: 546, test amount: 61
[DEBUG] 2018-05-22 11:37:58,850 -- Fold [10]: training amount: 547, test amount: 60
[DEBUG] 2018-05-22 11:37:59,808 -- BPR fold [8] iter 1: loss = 37995.945, delta_loss = -37995.945, learn_rate = 0.002
[DEBUG] 2018-05-22 11:37:59,812 -- BPR fold [7] iter 1: loss = 38094.156, delta_loss = -38094.156, learn_rate = 0.002
[DEBUG] 2018-05-22 11:37:59,813 -- BPR fold [4] iter 1: loss = 38283.56, delta_loss = -38283.56, learn_rate = 0.002
[DEBUG] 2018-05-22 11:37:59,815 -- BPR fold [9] iter 1: loss = 37576.926, delta_loss = -37576.926, learn_rate = 0.002
[DEBUG] 2018-05-22 11:37:59,826 -- BPR fold [6] iter 1: loss = 38375.67, delta_loss = -38375.67, learn_rate = 0.002
[DEBUG] 2018-05-22 11:37:59,830 -- BPR fold [1] iter 1: loss = 37511.555, delta_loss = -37511.555, learn_rate = 0.002
[DEBUG] 2018-05-22 11:37:59,886 -- BPR fold [3] iter 1: loss = 38316.34, delta_loss = -38316.34, learn_rate = 0.002
[DEBUG] 2018-05-22 11:37:59,890 -- BPR fold [10] iter 1: loss = 37372.86, delta_loss = -37372.86, learn_rate = 0.002
[DEBUG] 2018-05-22 11:37:59,898 -- BPR fold [2] iter 1: loss = 38237.016, delta_loss = -38237.016, learn_rate = 0.002
[DEBUG] 2018-05-22 11:37:59,946 -- BPR fold [5] iter 1: loss = 37885.176, delta_loss = -37885.176, learn_rate = 0.002
[DEBUG] 2018-05-22 11:38:00,653 -- BPR fold [8] iter 2: loss = 32331.21, delta_loss = 5664.736, learn_rate = 0.002
[DEBUG] 2018-05-22 11:38:00,656 -- BPR fold [7] iter 2: loss = 32479.139, delta_loss = 5615.019, learn_rate = 0.002
[DEBUG] 2018-05-22 11:38:00,672 -- BPR fold [1] iter 2: loss = 32171.58, delta_loss = 5339.9766, learn_rate = 0.002
[DEBUG] 2018-05-22 11:38:00,674 -- BPR fold [6] iter 2: loss = 32827.555, delta_loss = 5548.117, learn_rate = 0.002
[DEBUG] 2018-05-22 11:38:00,677 -- BPR fold [4] iter 2: loss = 32750.922, delta_loss = 5532.6343, learn_rate = 0.002
[DEBUG] 2018-05-22 11:38:00,679 -- BPR fold [5] iter 2: loss = 32401.676, delta_loss = 5483.4985, learn_rate = 0.002
[DEBUG] 2018-05-22 11:38:00,681 -- BPR fold [9] iter 2: loss = 32028.986, delta_loss = 5547.9395, learn_rate = 0.002
[DEBUG] 2018-05-22 11:38:00,682 -- BPR fold [2] iter 2: loss = 32515.645, delta_loss = 5721.3726, learn_rate = 0.002
[DEBUG] 2018-05-22 11:38:00,686 -- BPR fold [10] iter 2: loss = 31924.533, delta_loss = 5448.326, learn_rate = 0.002
[DEBUG] 2018-05-22 11:38:00,692 -- BPR fold [3] iter 2: loss = 32730.654, delta_loss = 5585.687, learn_rate = 0.002
[DEBUG] 2018-05-22 11:38:01,064 -- BPR fold [4] iter 3: loss = 28763.754, delta_loss = 3987.1694, learn_rate = 0.0021000002
[DEBUG] 2018-05-22 11:38:01,065 -- BPR fold [8] iter 3: loss = 28391.195, delta_loss = 3940.016, learn_rate = 0.0021000002
[DEBUG] 2018-05-22 11:38:01,074 -- BPR fold [2] iter 3: loss = 28480.246, delta_loss = 4035.397, learn_rate = 0.0021000002
[DEBUG] 2018-05-22 11:38:01,079 -- BPR fold [10] iter 3: loss = 27910.418, delta_loss = 4014.115, learn_rate = 0.0021000002
[DEBUG] 2018-05-22 11:38:01,082 -- BPR fold [3] iter 3: loss = 28612.639, delta_loss = 4118.0156, learn_rate = 0.0021000002
[DEBUG] 2018-05-22 11:38:01,084 -- BPR fold [5] iter 3: loss = 28311.996, delta_loss = 4089.679, learn_rate = 0.0021000002
[DEBUG] 2018-05-22 11:38:01,085 -- BPR fold [6] iter 3: loss = 28633.783, delta_loss = 4193.772, learn_rate = 0.0021000002
[DEBUG] 2018-05-22 11:38:01,088 -- BPR fold [1] iter 3: loss = 28350.621, delta_loss = 3820.9578, learn_rate = 0.0021000002
[DEBUG] 2018-05-22 11:38:01,089 -- BPR fold [9] iter 3: loss = 27965.814, delta_loss = 4063.171, learn_rate = 0.0021000002
[DEBUG] 2018-05-22 11:38:01,096 -- BPR fold [7] iter 3: loss = 28438.71, delta_loss = 4040.4277, learn_rate = 0.0021000002
[DEBUG] 2018-05-22 11:38:01,263 -- BPR fold [10] iter 4: loss = 24733.084, delta_loss = 3177.3337, learn_rate = 0.002205
[DEBUG] 2018-05-22 11:38:01,264 -- BPR fold [8] iter 4: loss = 24979.158, delta_loss = 3412.0364, learn_rate = 0.002205
[DEBUG] 2018-05-22 11:38:01,268 -- BPR fold [3] iter 4: loss = 25328.729, delta_loss = 3283.9087, learn_rate = 0.002205
[DEBUG] 2018-05-22 11:38:01,274 -- BPR fold [5] iter 4: loss = 25016.129, delta_loss = 3295.868, learn_rate = 0.002205
[DEBUG] 2018-05-22 11:38:01,275 -- BPR fold [2] iter 4: loss = 25112.68, delta_loss = 3367.5671, learn_rate = 0.002205
[DEBUG] 2018-05-22 11:38:01,278 -- BPR fold [6] iter 4: loss = 25388.49, delta_loss = 3245.2937, learn_rate = 0.002205
[DEBUG] 2018-05-22 11:38:01,280 -- BPR fold [4] iter 4: loss = 25487.87, delta_loss = 3275.8833, learn_rate = 0.002205
[DEBUG] 2018-05-22 11:38:01,286 -- BPR fold [9] iter 4: loss = 24731.568, delta_loss = 3234.2458, learn_rate = 0.002205
[DEBUG] 2018-05-22 11:38:01,289 -- BPR fold [1] iter 4: loss = 25093.05, delta_loss = 3257.5713, learn_rate = 0.002205
[DEBUG] 2018-05-22 11:38:01,309 -- BPR fold [7] iter 4: loss = 25133.928, delta_loss = 3304.7832, learn_rate = 0.002205
[DEBUG] 2018-05-22 11:38:01,441 -- BPR fold [8] iter 5: loss = 22262.047, delta_loss = 2717.1123, learn_rate = 0.0023152502
[DEBUG] 2018-05-22 11:38:01,458 -- BPR fold [4] iter 5: loss = 22728.828, delta_loss = 2759.0413, learn_rate = 0.0023152502
[DEBUG] 2018-05-22 11:38:01,460 -- BPR fold [6] iter 5: loss = 22449.06, delta_loss = 2939.43, learn_rate = 0.0023152502
[DEBUG] 2018-05-22 11:38:01,479 -- BPR fold [2] iter 5: loss = 22335.385, delta_loss = 2777.295, learn_rate = 0.0023152502
[DEBUG] 2018-05-22 11:38:01,484 -- BPR fold [3] iter 5: loss = 22387.764, delta_loss = 2940.9663, learn_rate = 0.0023152502
[DEBUG] 2018-05-22 11:38:01,488 -- BPR fold [9] iter 5: loss = 21895.197, delta_loss = 2836.3713, learn_rate = 0.0023152502
[DEBUG] 2018-05-22 11:38:01,491 -- BPR fold [7] iter 5: loss = 22312.908, delta_loss = 2821.02, learn_rate = 0.0023152502
[DEBUG] 2018-05-22 11:38:01,490 -- BPR fold [1] iter 5: loss = 22302.486, delta_loss = 2790.5635, learn_rate = 0.0023152502
[DEBUG] 2018-05-22 11:38:01,511 -- BPR fold [10] iter 5: loss = 21946.258, delta_loss = 2786.8271, learn_rate = 0.0023152502
[DEBUG] 2018-05-22 11:38:01,519 -- BPR fold [5] iter 5: loss = 22141.373, delta_loss = 2874.7554, learn_rate = 0.0023152502
[DEBUG] 2018-05-22 11:38:01,662 -- BPR fold [8] iter 6: loss = 19792.426, delta_loss = 2469.6194, learn_rate = 0.0024310127
[DEBUG] 2018-05-22 11:38:01,681 -- BPR fold [6] iter 6: loss = 19964.314, delta_loss = 2484.7446, learn_rate = 0.0024310127
[DEBUG] 2018-05-22 11:38:01,682 -- BPR fold [4] iter 6: loss = 20056.969, delta_loss = 2671.8599, learn_rate = 0.0024310127
[DEBUG] 2018-05-22 11:38:01,691 -- BPR fold [3] iter 6: loss = 19841.633, delta_loss = 2546.1304, learn_rate = 0.0024310127
[DEBUG] 2018-05-22 11:38:01,694 -- BPR fold [1] iter 6: loss = 19735.076, delta_loss = 2567.4111, learn_rate = 0.0024310127
[DEBUG] 2018-05-22 11:38:01,704 -- BPR fold [2] iter 6: loss = 19848.285, delta_loss = 2487.0999, learn_rate = 0.0024310127
[DEBUG] 2018-05-22 11:38:01,705 -- BPR fold [5] iter 6: loss = 19753.012, delta_loss = 2388.3613, learn_rate = 0.0024310127
[DEBUG] 2018-05-22 11:38:01,716 -- BPR fold [7] iter 6: loss = 19816.215, delta_loss = 2496.6921, learn_rate = 0.0024310127
[DEBUG] 2018-05-22 11:38:01,724 -- BPR fold [9] iter 6: loss = 19352.09, delta_loss = 2543.1077, learn_rate = 0.0024310127
[DEBUG] 2018-05-22 11:38:01,739 -- BPR fold [10] iter 6: loss = 19593.844, delta_loss = 2352.4128, learn_rate = 0.0024310127
[DEBUG] 2018-05-22 11:38:01,861 -- BPR fold [8] iter 7: loss = 17539.076, delta_loss = 2253.3496, learn_rate = 0.0025525633
[DEBUG] 2018-05-22 11:38:01,888 -- BPR fold [1] iter 7: loss = 17638.37, delta_loss = 2096.706, learn_rate = 0.0025525633
[DEBUG] 2018-05-22 11:38:01,908 -- BPR fold [2] iter 7: loss = 17514.814, delta_loss = 2333.471, learn_rate = 0.0025525633
[DEBUG] 2018-05-22 11:38:01,893 -- BPR fold [4] iter 7: loss = 17875.184, delta_loss = 2181.785, learn_rate = 0.0025525633
[DEBUG] 2018-05-22 11:38:01,914 -- BPR fold [7] iter 7: loss = 17550.75, delta_loss = 2265.4656, learn_rate = 0.0025525633
[DEBUG] 2018-05-22 11:38:01,905 -- BPR fold [3] iter 7: loss = 17755.82, delta_loss = 2085.8132, learn_rate = 0.0025525633
[DEBUG] 2018-05-22 11:38:01,895 -- BPR fold [6] iter 7: loss = 17641.623, delta_loss = 2322.6912, learn_rate = 0.0025525633
[DEBUG] 2018-05-22 11:38:01,929 -- BPR fold [9] iter 7: loss = 17206.227, delta_loss = 2145.8623, learn_rate = 0.0025525633
[DEBUG] 2018-05-22 11:38:01,939 -- BPR fold [5] iter 7: loss = 17462.723, delta_loss = 2290.2896, learn_rate = 0.0025525633
[DEBUG] 2018-05-22 11:38:01,956 -- BPR fold [10] iter 7: loss = 17308.432, delta_loss = 2285.4128, learn_rate = 0.0025525633
[DEBUG] 2018-05-22 11:38:02,072 -- BPR fold [8] iter 8: loss = 15552.744, delta_loss = 1986.333, learn_rate = 0.0026801913
[DEBUG] 2018-05-22 11:38:02,091 -- BPR fold [6] iter 8: loss = 15706.036, delta_loss = 1935.5874, learn_rate = 0.0026801913
[DEBUG] 2018-05-22 11:38:02,095 -- BPR fold [2] iter 8: loss = 15598.1875, delta_loss = 1916.6266, learn_rate = 0.0026801913
[DEBUG] 2018-05-22 11:38:02,098 -- BPR fold [4] iter 8: loss = 15797.002, delta_loss = 2078.1812, learn_rate = 0.0026801913
[DEBUG] 2018-05-22 11:38:02,101 -- BPR fold [1] iter 8: loss = 15542.093, delta_loss = 2096.2766, learn_rate = 0.0026801913
[DEBUG] 2018-05-22 11:38:02,106 -- BPR fold [3] iter 8: loss = 15701.377, delta_loss = 2054.4421, learn_rate = 0.0026801913
[DEBUG] 2018-05-22 11:38:02,118 -- BPR fold [9] iter 8: loss = 15244.292, delta_loss = 1961.9357, learn_rate = 0.0026801913
[DEBUG] 2018-05-22 11:38:02,111 -- BPR fold [5] iter 8: loss = 15552.661, delta_loss = 1910.061, learn_rate = 0.0026801913
[DEBUG] 2018-05-22 11:38:02,134 -- BPR fold [7] iter 8: loss = 15521.084, delta_loss = 2029.6652, learn_rate = 0.0026801913
[DEBUG] 2018-05-22 11:38:02,157 -- BPR fold [10] iter 8: loss = 15279.087, delta_loss = 2029.3448, learn_rate = 0.0026801913
[DEBUG] 2018-05-22 11:38:02,348 -- BPR fold [8] iter 9: loss = 13873.31, delta_loss = 1679.4343, learn_rate = 0.002814201
[DEBUG] 2018-05-22 11:38:02,363 -- BPR fold [4] iter 9: loss = 13981.608, delta_loss = 1815.3942, learn_rate = 0.002814201
[DEBUG] 2018-05-22 11:38:02,365 -- BPR fold [6] iter 9: loss = 13875.801, delta_loss = 1830.2357, learn_rate = 0.002814201
[DEBUG] 2018-05-22 11:38:02,392 -- BPR fold [2] iter 9: loss = 13789.307, delta_loss = 1808.8809, learn_rate = 0.002814201
[DEBUG] 2018-05-22 11:38:02,412 -- BPR fold [9] iter 9: loss = 13393.767, delta_loss = 1850.5251, learn_rate = 0.002814201
[DEBUG] 2018-05-22 11:38:02,458 -- BPR fold [3] iter 9: loss = 13786.87, delta_loss = 1914.5071, learn_rate = 0.002814201
[DEBUG] 2018-05-22 11:38:02,472 -- BPR fold [1] iter 9: loss = 13774.258, delta_loss = 1767.835, learn_rate = 0.002814201
[DEBUG] 2018-05-22 11:38:02,487 -- BPR fold [10] iter 9: loss = 13602.366, delta_loss = 1676.7211, learn_rate = 0.002814201
[DEBUG] 2018-05-22 11:38:02,472 -- BPR fold [7] iter 9: loss = 13829.826, delta_loss = 1691.2587, learn_rate = 0.002814201
[DEBUG] 2018-05-22 11:38:02,512 -- BPR fold [5] iter 9: loss = 13761.906, delta_loss = 1790.7551, learn_rate = 0.002814201
[DEBUG] 2018-05-22 11:38:02,634 -- BPR fold [4] iter 10: loss = 12347.777, delta_loss = 1633.8304, learn_rate = 0.002954911
[DEBUG] 2018-05-22 11:38:02,648 -- BPR fold [8] iter 10: loss = 12184.125, delta_loss = 1689.1843, learn_rate = 0.002954911
[DEBUG] 2018-05-22 11:38:02,711 -- BPR fold [6] iter 10: loss = 12268.559, delta_loss = 1607.2423, learn_rate = 0.002954911
[DEBUG] 2018-05-22 11:38:02,732 -- BPR fold [2] iter 10: loss = 12199.162, delta_loss = 1590.1448, learn_rate = 0.002954911
[DEBUG] 2018-05-22 11:38:02,755 -- BPR fold [9] iter 10: loss = 11885.368, delta_loss = 1508.3983, learn_rate = 0.002954911
[DEBUG] 2018-05-22 11:38:02,776 -- BPR fold [3] iter 10: loss = 12208.347, delta_loss = 1578.5238, learn_rate = 0.002954911
[DEBUG] 2018-05-22 11:38:02,783 -- BPR fold [1] iter 10: loss = 12188.416, delta_loss = 1585.8419, learn_rate = 0.002954911
[DEBUG] 2018-05-22 11:38:02,796 -- BPR fold [7] iter 10: loss = 12217.944, delta_loss = 1611.8818, learn_rate = 0.002954911
[DEBUG] 2018-05-22 11:38:02,828 -- BPR fold [5] iter 10: loss = 12085.255, delta_loss = 1676.6516, learn_rate = 0.002954911
[DEBUG] 2018-05-22 11:38:02,836 -- BPR fold [10] iter 10: loss = 12013.249, delta_loss = 1589.1166, learn_rate = 0.002954911
[DEBUG] 2018-05-22 11:38:02,904 -- BPR fold [8] iter 11: loss = 10800.603, delta_loss = 1383.5226, learn_rate = 0.0031026567
[DEBUG] 2018-05-22 11:38:02,989 -- BPR fold [4] iter 11: loss = 10937.44, delta_loss = 1410.3376, learn_rate = 0.0031026567
[DEBUG] 2018-05-22 11:38:02,998 -- BPR fold [6] iter 11: loss = 10817.348, delta_loss = 1451.2108, learn_rate = 0.0031026567
[DEBUG] 2018-05-22 11:38:03,025 -- BPR fold [3] iter 11: loss = 10789.838, delta_loss = 1418.5088, learn_rate = 0.0031026567
[DEBUG] 2018-05-22 11:38:03,049 -- BPR fold [1] iter 11: loss = 10692.983, delta_loss = 1495.4333, learn_rate = 0.0031026567
[DEBUG] 2018-05-22 11:38:03,049 -- BPR fold [7] iter 11: loss = 10755.324, delta_loss = 1462.6194, learn_rate = 0.0031026567
[DEBUG] 2018-05-22 11:38:03,081 -- BPR fold [2] iter 11: loss = 10763.986, delta_loss = 1435.1757, learn_rate = 0.0031026567
[DEBUG] 2018-05-22 11:38:03,092 -- BPR fold [9] iter 11: loss = 10453.157, delta_loss = 1432.2107, learn_rate = 0.0031026567
[DEBUG] 2018-05-22 11:38:03,106 -- BPR fold [5] iter 11: loss = 10729.393, delta_loss = 1355.8619, learn_rate = 0.0031026567
[DEBUG] 2018-05-22 11:38:03,141 -- BPR fold [10] iter 11: loss = 10620.058, delta_loss = 1393.1915, learn_rate = 0.0031026567
[DEBUG] 2018-05-22 11:38:03,200 -- BPR fold [8] iter 12: loss = 9525.991, delta_loss = 1274.6112, learn_rate = 0.0032577894
[DEBUG] 2018-05-22 11:38:03,234 -- BPR fold [6] iter 12: loss = 9574.29, delta_loss = 1243.0574, learn_rate = 0.0032577894
[DEBUG] 2018-05-22 11:38:03,241 -- BPR fold [4] iter 12: loss = 9612.164, delta_loss = 1325.2761, learn_rate = 0.0032577894
[DEBUG] 2018-05-22 11:38:03,259 -- BPR fold [2] iter 12: loss = 9535.284, delta_loss = 1228.7023, learn_rate = 0.0032577894
[DEBUG] 2018-05-22 11:38:03,263 -- BPR fold [3] iter 12: loss = 9483.771, delta_loss = 1306.0662, learn_rate = 0.0032577894
[DEBUG] 2018-05-22 11:38:03,279 -- BPR fold [1] iter 12: loss = 9537.143, delta_loss = 1155.8403, learn_rate = 0.0032577894
[DEBUG] 2018-05-22 11:38:03,305 -- BPR fold [7] iter 12: loss = 9521.203, delta_loss = 1234.1217, learn_rate = 0.0032577894
[DEBUG] 2018-05-22 11:38:03,307 -- BPR fold [5] iter 12: loss = 9517.267, delta_loss = 1212.126, learn_rate = 0.0032577894
[DEBUG] 2018-05-22 11:38:03,314 -- BPR fold [9] iter 12: loss = 9282.768, delta_loss = 1170.3898, learn_rate = 0.0032577894
[DEBUG] 2018-05-22 11:38:03,354 -- BPR fold [10] iter 12: loss = 9382.745, delta_loss = 1237.3127, learn_rate = 0.0032577894
[DEBUG] 2018-05-22 11:38:03,402 -- BPR fold [8] iter 13: loss = 8521.457, delta_loss = 1004.5348, learn_rate = 0.003420679
[DEBUG] 2018-05-22 11:38:03,457 -- BPR fold [4] iter 13: loss = 8533.883, delta_loss = 1078.2815, learn_rate = 0.003420679
[DEBUG] 2018-05-22 11:38:03,477 -- BPR fold [3] iter 13: loss = 8342.959, delta_loss = 1140.8129, learn_rate = 0.003420679
[DEBUG] 2018-05-22 11:38:03,477 -- BPR fold [6] iter 13: loss = 8436.249, delta_loss = 1138.041, learn_rate = 0.003420679
[DEBUG] 2018-05-22 11:38:03,504 -- BPR fold [2] iter 13: loss = 8381.33, delta_loss = 1153.9543, learn_rate = 0.003420679
[DEBUG] 2018-05-22 11:38:03,513 -- BPR fold [5] iter 13: loss = 8382.05, delta_loss = 1135.2173, learn_rate = 0.003420679
[DEBUG] 2018-05-22 11:38:03,515 -- BPR fold [1] iter 13: loss = 8390.599, delta_loss = 1146.5441, learn_rate = 0.003420679
[DEBUG] 2018-05-22 11:38:03,526 -- BPR fold [9] iter 13: loss = 8206.465, delta_loss = 1076.3026, learn_rate = 0.003420679
[DEBUG] 2018-05-22 11:38:03,527 -- BPR fold [7] iter 13: loss = 8430.045, delta_loss = 1091.1582, learn_rate = 0.003420679
[DEBUG] 2018-05-22 11:38:03,578 -- BPR fold [10] iter 13: loss = 8351.193, delta_loss = 1031.5514, learn_rate = 0.003420679
[DEBUG] 2018-05-22 11:38:03,631 -- BPR fold [8] iter 14: loss = 7528.086, delta_loss = 993.3705, learn_rate = 0.0035917128
[DEBUG] 2018-05-22 11:38:03,693 -- BPR fold [9] iter 14: loss = 7303.471, delta_loss = 902.9941, learn_rate = 0.0035917128
[DEBUG] 2018-05-22 11:38:03,715 -- BPR fold [4] iter 14: loss = 7566.976, delta_loss = 966.9066, learn_rate = 0.0035917128
[DEBUG] 2018-05-22 11:38:03,724 -- BPR fold [6] iter 14: loss = 7524.335, delta_loss = 911.91406, learn_rate = 0.0035917128
[DEBUG] 2018-05-22 11:38:03,734 -- BPR fold [3] iter 14: loss = 7436.005, delta_loss = 906.95386, learn_rate = 0.0035917128
[DEBUG] 2018-05-22 11:38:03,740 -- BPR fold [2] iter 14: loss = 7474.809, delta_loss = 906.5206, learn_rate = 0.0035917128
[DEBUG] 2018-05-22 11:38:03,747 -- BPR fold [1] iter 14: loss = 7505.5684, delta_loss = 885.0302, learn_rate = 0.0035917128
[DEBUG] 2018-05-22 11:38:03,769 -- BPR fold [7] iter 14: loss = 7442.179, delta_loss = 987.8656, learn_rate = 0.0035917128
[DEBUG] 2018-05-22 11:38:03,786 -- BPR fold [5] iter 14: loss = 7419.161, delta_loss = 962.8885, learn_rate = 0.0035917128
[DEBUG] 2018-05-22 11:38:03,865 -- BPR fold [8] iter 15: loss = 6657.987, delta_loss = 870.0994, learn_rate = 0.0037712986
[DEBUG] 2018-05-22 11:38:03,880 -- BPR fold [10] iter 14: loss = 7399.6426, delta_loss = 951.55096, learn_rate = 0.0035917128
[DEBUG] 2018-05-22 11:38:03,931 -- BPR fold [6] iter 15: loss = 6647.405, delta_loss = 876.9302, learn_rate = 0.0037712986
[DEBUG] 2018-05-22 11:38:03,938 -- BPR fold [2] iter 15: loss = 6573.182, delta_loss = 901.62665, learn_rate = 0.0037712986
[DEBUG] 2018-05-22 11:38:03,938 -- BPR fold [3] iter 15: loss = 6597.882, delta_loss = 838.1228, learn_rate = 0.0037712986
[DEBUG] 2018-05-22 11:38:03,945 -- BPR fold [9] iter 15: loss = 6485.811, delta_loss = 817.66, learn_rate = 0.0037712986
[DEBUG] 2018-05-22 11:38:03,956 -- BPR fold [1] iter 15: loss = 6662.277, delta_loss = 843.2918, learn_rate = 0.0037712986
[DEBUG] 2018-05-22 11:38:03,971 -- BPR fold [4] iter 15: loss = 6765.133, delta_loss = 801.8431, learn_rate = 0.0037712986
[DEBUG] 2018-05-22 11:38:03,980 -- BPR fold [7] iter 15: loss = 6623.1846, delta_loss = 818.99457, learn_rate = 0.0037712986
[DEBUG] 2018-05-22 11:38:04,009 -- BPR fold [5] iter 15: loss = 6631.364, delta_loss = 787.7971, learn_rate = 0.0037712986
[DEBUG] 2018-05-22 11:38:04,083 -- BPR fold [10] iter 15: loss = 6604.451, delta_loss = 795.19135, learn_rate = 0.0037712986
[DEBUG] 2018-05-22 11:38:04,101 -- BPR fold [8] iter 16: loss = 5976.4443, delta_loss = 681.54224, learn_rate = 0.0039598634
[DEBUG] 2018-05-22 11:38:04,138 -- BPR fold [6] iter 16: loss = 5935.039, delta_loss = 712.3657, learn_rate = 0.0039598634
[DEBUG] 2018-05-22 11:38:04,157 -- BPR fold [9] iter 16: loss = 5846.0664, delta_loss = 639.7447, learn_rate = 0.0039598634
[DEBUG] 2018-05-22 11:38:04,156 -- BPR fold [3] iter 16: loss = 5916.886, delta_loss = 680.996, learn_rate = 0.0039598634
[DEBUG] 2018-05-22 11:38:04,173 -- BPR fold [2] iter 16: loss = 5923.8896, delta_loss = 649.2925, learn_rate = 0.0039598634
[DEBUG] 2018-05-22 11:38:04,186 -- BPR fold [1] iter 16: loss = 5919.3843, delta_loss = 742.8924, learn_rate = 0.0039598634
[DEBUG] 2018-05-22 11:38:04,200 -- BPR fold [7] iter 16: loss = 5920.1606, delta_loss = 703.02374, learn_rate = 0.0039598634
[DEBUG] 2018-05-22 11:38:04,203 -- BPR fold [4] iter 16: loss = 6012.735, delta_loss = 752.3978, learn_rate = 0.0039598634
[DEBUG] 2018-05-22 11:38:04,234 -- BPR fold [5] iter 16: loss = 5879.915, delta_loss = 751.449, learn_rate = 0.0039598634
[DEBUG] 2018-05-22 11:38:04,329 -- BPR fold [10] iter 16: loss = 5854.4116, delta_loss = 750.0397, learn_rate = 0.0039598634
[DEBUG] 2018-05-22 11:38:04,333 -- BPR fold [8] iter 17: loss = 5356.1274, delta_loss = 620.3168, learn_rate = 0.0041578566
[DEBUG] 2018-05-22 11:38:04,348 -- BPR fold [6] iter 17: loss = 5333.2847, delta_loss = 601.75433, learn_rate = 0.0041578566
[DEBUG] 2018-05-22 11:38:04,359 -- BPR fold [3] iter 17: loss = 5281.0366, delta_loss = 635.8493, learn_rate = 0.0041578566
[DEBUG] 2018-05-22 11:38:04,375 -- BPR fold [9] iter 17: loss = 5212.8936, delta_loss = 633.17267, learn_rate = 0.0041578566
[DEBUG] 2018-05-22 11:38:04,387 -- BPR fold [1] iter 17: loss = 5321.5474, delta_loss = 597.8369, learn_rate = 0.0041578566
[DEBUG] 2018-05-22 11:38:04,404 -- BPR fold [2] iter 17: loss = 5301.9214, delta_loss = 621.96857, learn_rate = 0.0041578566
[DEBUG] 2018-05-22 11:38:04,406 -- BPR fold [7] iter 17: loss = 5291.76, delta_loss = 628.4007, learn_rate = 0.0041578566
[DEBUG] 2018-05-22 11:38:04,428 -- BPR fold [4] iter 17: loss = 5347.2886, delta_loss = 665.4466, learn_rate = 0.0041578566
[DEBUG] 2018-05-22 11:38:04,444 -- BPR fold [5] iter 17: loss = 5249.3354, delta_loss = 630.57935, learn_rate = 0.0041578566
[DEBUG] 2018-05-22 11:38:04,504 -- BPR fold [8] iter 18: loss = 4850.8345, delta_loss = 505.29343, learn_rate = 0.004365749
[DEBUG] 2018-05-22 11:38:04,522 -- BPR fold [10] iter 17: loss = 5304.709, delta_loss = 549.70276, learn_rate = 0.0041578566
[DEBUG] 2018-05-22 11:38:04,536 -- BPR fold [3] iter 18: loss = 4744.7666, delta_loss = 536.27, learn_rate = 0.004365749
[DEBUG] 2018-05-22 11:38:04,567 -- BPR fold [9] iter 18: loss = 4687.5547, delta_loss = 525.3388, learn_rate = 0.004365749
[DEBUG] 2018-05-22 11:38:04,577 -- BPR fold [1] iter 18: loss = 4771.5605, delta_loss = 549.9866, learn_rate = 0.004365749
[DEBUG] 2018-05-22 11:38:04,579 -- BPR fold [6] iter 18: loss = 4760.0864, delta_loss = 573.19836, learn_rate = 0.004365749
[DEBUG] 2018-05-22 11:38:04,597 -- BPR fold [2] iter 18: loss = 4738.424, delta_loss = 563.49725, learn_rate = 0.004365749
[DEBUG] 2018-05-22 11:38:04,609 -- BPR fold [7] iter 18: loss = 4766.9165, delta_loss = 524.84344, learn_rate = 0.004365749
[DEBUG] 2018-05-22 11:38:04,624 -- BPR fold [4] iter 18: loss = 4780.473, delta_loss = 566.81506, learn_rate = 0.004365749
[DEBUG] 2018-05-22 11:38:04,640 -- BPR fold [5] iter 18: loss = 4739.485, delta_loss = 509.85065, learn_rate = 0.004365749
[DEBUG] 2018-05-22 11:38:04,715 -- BPR fold [8] iter 19: loss = 4317.065, delta_loss = 533.7693, learn_rate = 0.004584037
[DEBUG] 2018-05-22 11:38:04,732 -- BPR fold [10] iter 18: loss = 4717.9272, delta_loss = 586.78186, learn_rate = 0.004365749
[DEBUG] 2018-05-22 11:38:04,757 -- BPR fold [3] iter 19: loss = 4311.1553, delta_loss = 433.61145, learn_rate = 0.004584037
[DEBUG] 2018-05-22 11:38:04,769 -- BPR fold [9] iter 19: loss = 4197.4824, delta_loss = 490.07233, learn_rate = 0.004584037
[DEBUG] 2018-05-22 11:38:04,779 -- BPR fold [6] iter 19: loss = 4281.936, delta_loss = 478.15045, learn_rate = 0.004584037
[DEBUG] 2018-05-22 11:38:04,787 -- BPR fold [1] iter 19: loss = 4307.621, delta_loss = 463.9396, learn_rate = 0.004584037
[DEBUG] 2018-05-22 11:38:04,812 -- BPR fold [2] iter 19: loss = 4297.304, delta_loss = 441.11966, learn_rate = 0.004584037
[DEBUG] 2018-05-22 11:38:04,844 -- BPR fold [4] iter 19: loss = 4336.947, delta_loss = 443.52673, learn_rate = 0.004584037
[DEBUG] 2018-05-22 11:38:04,845 -- BPR fold [5] iter 19: loss = 4244.497, delta_loss = 494.98785, learn_rate = 0.004584037
[DEBUG] 2018-05-22 11:38:04,846 -- BPR fold [7] iter 19: loss = 4320.309, delta_loss = 446.6077, learn_rate = 0.004584037
[DEBUG] 2018-05-22 11:38:04,940 -- BPR fold [8] iter 20: loss = 3914.3428, delta_loss = 402.7221, learn_rate = 0.0048132385
[DEBUG] 2018-05-22 11:38:04,963 -- BPR fold [6] iter 20: loss = 3880.381, delta_loss = 401.5549, learn_rate = 0.0048132385
[DEBUG] 2018-05-22 11:38:04,973 -- BPR fold [10] iter 19: loss = 4246.822, delta_loss = 471.105, learn_rate = 0.004584037
[DEBUG] 2018-05-22 11:38:04,987 -- BPR fold [3] iter 20: loss = 3887.9426, delta_loss = 423.2125, learn_rate = 0.0048132385
[DEBUG] 2018-05-22 11:38:04,994 -- BPR fold [9] iter 20: loss = 3867.2363, delta_loss = 330.24634, learn_rate = 0.0048132385
[DEBUG] 2018-05-22 11:38:05,001 -- BPR fold [1] iter 20: loss = 3904.0916, delta_loss = 403.5296, learn_rate = 0.0048132385
[DEBUG] 2018-05-22 11:38:05,016 -- BPR fold [2] iter 20: loss = 3852.0771, delta_loss = 445.22717, learn_rate = 0.0048132385
[DEBUG] 2018-05-22 11:38:05,033 -- BPR fold [7] iter 20: loss = 3899.809, delta_loss = 420.49976, learn_rate = 0.0048132385
[DEBUG] 2018-05-22 11:38:05,053 -- BPR fold [5] iter 20: loss = 3865.9077, delta_loss = 378.58942, learn_rate = 0.0048132385
[DEBUG] 2018-05-22 11:38:05,065 -- BPR fold [4] iter 20: loss = 3911.6675, delta_loss = 425.27893, learn_rate = 0.0048132385
[DEBUG] 2018-05-22 11:38:05,169 -- BPR fold [8] iter 21: loss = 3548.747, delta_loss = 365.59573, learn_rate = 0.0050539006
[DEBUG] 2018-05-22 11:38:05,199 -- BPR fold [6] iter 21: loss = 3561.068, delta_loss = 319.31308, learn_rate = 0.0050539006
[DEBUG] 2018-05-22 11:38:05,202 -- BPR fold [10] iter 20: loss = 3879.2131, delta_loss = 367.60895, learn_rate = 0.0048132385
[DEBUG] 2018-05-22 11:38:05,236 -- BPR fold [3] iter 21: loss = 3510.0205, delta_loss = 377.92215, learn_rate = 0.0050539006
[DEBUG] 2018-05-22 11:38:05,254 -- BPR fold [9] iter 21: loss = 3457.1572, delta_loss = 410.0789, learn_rate = 0.0050539006
[DEBUG] 2018-05-22 11:38:05,269 -- BPR fold [2] iter 21: loss = 3502.5256, delta_loss = 349.55148, learn_rate = 0.0050539006
[DEBUG] 2018-05-22 11:38:05,292 -- BPR fold [1] iter 21: loss = 3499.175, delta_loss = 404.9164, learn_rate = 0.0050539006
[DEBUG] 2018-05-22 11:38:05,337 -- BPR fold [4] iter 21: loss = 3549.6787, delta_loss = 361.9888, learn_rate = 0.0050539006
[DEBUG] 2018-05-22 11:38:05,338 -- BPR fold [7] iter 21: loss = 3518.4946, delta_loss = 381.31448, learn_rate = 0.0050539006
[DEBUG] 2018-05-22 11:38:05,360 -- BPR fold [5] iter 21: loss = 3509.8098, delta_loss = 356.09787, learn_rate = 0.0050539006
[DEBUG] 2018-05-22 11:38:05,441 -- BPR fold [8] iter 22: loss = 3224.5427, delta_loss = 324.20428, learn_rate = 0.0053065955
[DEBUG] 2018-05-22 11:38:05,503 -- BPR fold [10] iter 21: loss = 3518.0308, delta_loss = 361.18243, learn_rate = 0.0050539006
[DEBUG] 2018-05-22 11:38:05,530 -- BPR fold [1] iter 22: loss = 3255.0667, delta_loss = 244.1084, learn_rate = 0.0053065955
[DEBUG] 2018-05-22 11:38:05,564 -- BPR fold [6] iter 22: loss = 3193.1116, delta_loss = 367.95657, learn_rate = 0.0053065955
[DEBUG] 2018-05-22 11:38:05,586 -- BPR fold [9] iter 22: loss = 3149.0303, delta_loss = 308.12717, learn_rate = 0.0053065955
[DEBUG] 2018-05-22 11:38:05,596 -- BPR fold [3] iter 22: loss = 3222.9956, delta_loss = 287.0251, learn_rate = 0.0053065955
[DEBUG] 2018-05-22 11:38:05,611 -- BPR fold [2] iter 22: loss = 3197.4307, delta_loss = 305.09497, learn_rate = 0.0053065955
[DEBUG] 2018-05-22 11:38:05,658 -- BPR fold [5] iter 22: loss = 3202.9712, delta_loss = 306.83856, learn_rate = 0.0053065955
[DEBUG] 2018-05-22 11:38:05,678 -- BPR fold [7] iter 22: loss = 3207.6584, delta_loss = 310.8362, learn_rate = 0.0053065955
[DEBUG] 2018-05-22 11:38:05,681 -- BPR fold [4] iter 22: loss = 3240.1956, delta_loss = 309.48322, learn_rate = 0.0053065955
[DEBUG] 2018-05-22 11:38:05,796 -- BPR fold [8] iter 23: loss = 2977.2253, delta_loss = 247.31757, learn_rate = 0.0055719255
[DEBUG] 2018-05-22 11:38:05,852 -- BPR fold [10] iter 22: loss = 3214.053, delta_loss = 303.9776, learn_rate = 0.0053065955
[DEBUG] 2018-05-22 11:38:05,869 -- BPR fold [9] iter 23: loss = 2889.7837, delta_loss = 259.24655, learn_rate = 0.0055719255
[DEBUG] 2018-05-22 11:38:05,873 -- BPR fold [6] iter 23: loss = 2949.5112, delta_loss = 243.60019, learn_rate = 0.0055719255
[DEBUG] 2018-05-22 11:38:05,874 -- BPR fold [1] iter 23: loss = 2930.0674, delta_loss = 324.99936, learn_rate = 0.0055719255
[DEBUG] 2018-05-22 11:38:05,889 -- BPR fold [2] iter 23: loss = 2939.5781, delta_loss = 257.8525, learn_rate = 0.0055719255
[DEBUG] 2018-05-22 11:38:05,906 -- BPR fold [3] iter 23: loss = 2919.804, delta_loss = 303.19156, learn_rate = 0.0055719255
[DEBUG] 2018-05-22 11:38:05,927 -- BPR fold [4] iter 23: loss = 2926.9583, delta_loss = 313.23737, learn_rate = 0.0055719255
[DEBUG] 2018-05-22 11:38:05,930 -- BPR fold [5] iter 23: loss = 2903.2068, delta_loss = 299.7645, learn_rate = 0.0055719255
[DEBUG] 2018-05-22 11:38:05,970 -- BPR fold [7] iter 23: loss = 2921.8264, delta_loss = 285.83212, learn_rate = 0.0055719255
[DEBUG] 2018-05-22 11:38:06,063 -- BPR fold [8] iter 24: loss = 2701.0796, delta_loss = 276.14563, learn_rate = 0.005850522
[DEBUG] 2018-05-22 11:38:06,086 -- BPR fold [10] iter 23: loss = 2941.9597, delta_loss = 272.09323, learn_rate = 0.0055719255
[DEBUG] 2018-05-22 11:38:06,102 -- BPR fold [9] iter 24: loss = 2674.5325, delta_loss = 215.25113, learn_rate = 0.005850522
[DEBUG] 2018-05-22 11:38:06,114 -- BPR fold [3] iter 24: loss = 2655.7, delta_loss = 264.10388, learn_rate = 0.005850522
[DEBUG] 2018-05-22 11:38:06,115 -- BPR fold [1] iter 24: loss = 2657.976, delta_loss = 272.09137, learn_rate = 0.005850522
[DEBUG] 2018-05-22 11:38:06,120 -- BPR fold [2] iter 24: loss = 2683.3105, delta_loss = 256.2677, learn_rate = 0.005850522
[DEBUG] 2018-05-22 11:38:06,127 -- BPR fold [6] iter 24: loss = 2697.3577, delta_loss = 252.1538, learn_rate = 0.005850522
[DEBUG] 2018-05-22 11:38:06,133 -- BPR fold [5] iter 24: loss = 2665.9631, delta_loss = 237.24376, learn_rate = 0.005850522
[DEBUG] 2018-05-22 11:38:06,165 -- BPR fold [4] iter 24: loss = 2712.208, delta_loss = 214.7503, learn_rate = 0.005850522
[DEBUG] 2018-05-22 11:38:06,210 -- BPR fold [7] iter 24: loss = 2685.0815, delta_loss = 236.74484, learn_rate = 0.005850522
[DEBUG] 2018-05-22 11:38:06,295 -- BPR fold [8] iter 25: loss = 2458.6765, delta_loss = 242.40305, learn_rate = 0.006143048
[DEBUG] 2018-05-22 11:38:06,302 -- BPR fold [10] iter 24: loss = 2670.7888, delta_loss = 271.17105, learn_rate = 0.005850522
[DEBUG] 2018-05-22 11:38:06,308 -- BPR fold [1] iter 25: loss = 2475.2168, delta_loss = 182.75922, learn_rate = 0.006143048
[DEBUG] 2018-05-22 11:38:06,324 -- BPR fold [9] iter 25: loss = 2453.0579, delta_loss = 221.47467, learn_rate = 0.006143048
[DEBUG] 2018-05-22 11:38:06,327 -- BPR fold [3] iter 25: loss = 2479.5818, delta_loss = 176.1184, learn_rate = 0.006143048
[DEBUG] 2018-05-22 11:38:06,368 -- BPR fold [2] iter 25: loss = 2459.9038, delta_loss = 223.4067, learn_rate = 0.006143048
[DEBUG] 2018-05-22 11:38:06,379 -- BPR fold [6] iter 25: loss = 2432.309, delta_loss = 265.0485, learn_rate = 0.006143048
[DEBUG] 2018-05-22 11:38:06,389 -- BPR fold [4] iter 25: loss = 2505.528, delta_loss = 206.6799, learn_rate = 0.006143048
[DEBUG] 2018-05-22 11:38:06,398 -- BPR fold [5] iter 25: loss = 2452.7722, delta_loss = 213.19077, learn_rate = 0.006143048
[DEBUG] 2018-05-22 11:38:06,447 -- BPR fold [7] iter 25: loss = 2469.539, delta_loss = 215.54231, learn_rate = 0.006143048
[DEBUG] 2018-05-22 11:38:06,541 -- BPR fold [8] iter 26: loss = 2312.4414, delta_loss = 146.23528, learn_rate = 0.0064502
[DEBUG] 2018-05-22 11:38:06,622 -- BPR fold [10] iter 25: loss = 2501.5952, delta_loss = 169.19345, learn_rate = 0.006143048
[DEBUG] 2018-05-22 11:38:06,629 -- BPR fold [2] iter 26: loss = 2269.0796, delta_loss = 190.82433, learn_rate = 0.0064502
[DEBUG] 2018-05-22 11:38:06,635 -- BPR fold [1] iter 26: loss = 2258.1602, delta_loss = 217.05676, learn_rate = 0.0064502
[DEBUG] 2018-05-22 11:38:06,625 -- BPR fold [3] iter 26: loss = 2257.378, delta_loss = 222.20364, learn_rate = 0.0064502
[DEBUG] 2018-05-22 11:38:06,627 -- BPR fold [9] iter 26: loss = 2256.1191, delta_loss = 196.93872, learn_rate = 0.0064502
[DEBUG] 2018-05-22 11:38:06,689 -- BPR fold [6] iter 26: loss = 2265.2744, delta_loss = 167.0347, learn_rate = 0.0064502
[DEBUG] 2018-05-22 11:38:06,711 -- BPR fold [7] iter 26: loss = 2265.883, delta_loss = 203.65613, learn_rate = 0.0064502
[DEBUG] 2018-05-22 11:38:06,718 -- BPR fold [4] iter 26: loss = 2297.6965, delta_loss = 207.83139, learn_rate = 0.0064502
[DEBUG] 2018-05-22 11:38:06,719 -- BPR fold [5] iter 26: loss = 2239.5103, delta_loss = 213.26208, learn_rate = 0.0064502
[DEBUG] 2018-05-22 11:38:06,781 -- BPR fold [8] iter 27: loss = 2128.3503, delta_loss = 184.09106, learn_rate = 0.00677271
[DEBUG] 2018-05-22 11:38:06,812 -- BPR fold [10] iter 26: loss = 2311.8318, delta_loss = 189.76344, learn_rate = 0.0064502
[DEBUG] 2018-05-22 11:38:06,821 -- BPR fold [1] iter 27: loss = 2103.1035, delta_loss = 155.05653, learn_rate = 0.00677271
[DEBUG] 2018-05-22 11:38:06,832 -- BPR fold [2] iter 27: loss = 2108.898, delta_loss = 160.18147, learn_rate = 0.00677271
[DEBUG] 2018-05-22 11:38:06,865 -- BPR fold [9] iter 27: loss = 2096.2876, delta_loss = 159.83159, learn_rate = 0.00677271
[DEBUG] 2018-05-22 11:38:06,871 -- BPR fold [3] iter 27: loss = 2083.0173, delta_loss = 174.36073, learn_rate = 0.00677271
[DEBUG] 2018-05-22 11:38:06,909 -- BPR fold [4] iter 27: loss = 2134.0864, delta_loss = 163.61008, learn_rate = 0.00677271
[DEBUG] 2018-05-22 11:38:06,915 -- BPR fold [6] iter 27: loss = 2100.585, delta_loss = 164.6895, learn_rate = 0.00677271
[DEBUG] 2018-05-22 11:38:06,921 -- BPR fold [7] iter 27: loss = 2109.4395, delta_loss = 156.44347, learn_rate = 0.00677271
[DEBUG] 2018-05-22 11:38:06,926 -- BPR fold [5] iter 27: loss = 2098.7957, delta_loss = 140.71454, learn_rate = 0.00677271
[DEBUG] 2018-05-22 11:38:06,999 -- BPR fold [8] iter 28: loss = 1959.3193, delta_loss = 169.03096, learn_rate = 0.007111346
[DEBUG] 2018-05-22 11:38:07,041 -- BPR fold [10] iter 27: loss = 2134.4744, delta_loss = 177.35753, learn_rate = 0.00677271
[DEBUG] 2018-05-22 11:38:07,052 -- BPR fold [9] iter 28: loss = 1956.8857, delta_loss = 139.4018, learn_rate = 0.007111346
[DEBUG] 2018-05-22 11:38:07,054 -- BPR fold [2] iter 28: loss = 1939.3165, delta_loss = 169.58157, learn_rate = 0.007111346
[DEBUG] 2018-05-22 11:38:07,078 -- BPR fold [3] iter 28: loss = 1951.2915, delta_loss = 131.72583, learn_rate = 0.007111346
[DEBUG] 2018-05-22 11:38:07,078 -- BPR fold [1] iter 28: loss = 1950.8567, delta_loss = 152.24681, learn_rate = 0.007111346
[DEBUG] 2018-05-22 11:38:07,098 -- BPR fold [6] iter 28: loss = 1946.0623, delta_loss = 154.52261, learn_rate = 0.007111346
[DEBUG] 2018-05-22 11:38:07,120 -- BPR fold [5] iter 28: loss = 1950.6605, delta_loss = 148.1351, learn_rate = 0.007111346
[DEBUG] 2018-05-22 11:38:07,129 -- BPR fold [7] iter 28: loss = 1944.9135, delta_loss = 164.52615, learn_rate = 0.007111346
[DEBUG] 2018-05-22 11:38:07,137 -- BPR fold [4] iter 28: loss = 1976.4331, delta_loss = 157.65343, learn_rate = 0.007111346
[DEBUG] 2018-05-22 11:38:07,220 -- BPR fold [8] iter 29: loss = 1817.6492, delta_loss = 141.67012, learn_rate = 0.007466913
[DEBUG] 2018-05-22 11:38:07,255 -- BPR fold [9] iter 29: loss = 1799.5217, delta_loss = 157.36392, learn_rate = 0.007466913
[DEBUG] 2018-05-22 11:38:07,269 -- BPR fold [2] iter 29: loss = 1828.4565, delta_loss = 110.85989, learn_rate = 0.007466913
[DEBUG] 2018-05-22 11:38:07,271 -- BPR fold [3] iter 29: loss = 1814.782, delta_loss = 136.50949, learn_rate = 0.007466913
[DEBUG] 2018-05-22 11:38:07,276 -- BPR fold [1] iter 29: loss = 1820.2928, delta_loss = 130.56384, learn_rate = 0.007466913
[DEBUG] 2018-05-22 11:38:07,288 -- BPR fold [10] iter 28: loss = 1930.4111, delta_loss = 204.06322, learn_rate = 0.007111346
[DEBUG] 2018-05-22 11:38:07,296 -- BPR fold [6] iter 29: loss = 1821.8934, delta_loss = 124.168785, learn_rate = 0.007466913
[DEBUG] 2018-05-22 11:38:07,321 -- BPR fold [7] iter 29: loss = 1823.2482, delta_loss = 121.66522, learn_rate = 0.007466913
[DEBUG] 2018-05-22 11:38:07,334 -- BPR fold [5] iter 29: loss = 1813.6998, delta_loss = 136.96071, learn_rate = 0.007466913
[DEBUG] 2018-05-22 11:38:07,346 -- BPR fold [4] iter 29: loss = 1809.5173, delta_loss = 166.91574, learn_rate = 0.007466913
[DEBUG] 2018-05-22 11:38:07,421 -- BPR fold [8] iter 30: loss = 1694.4802, delta_loss = 123.16897, learn_rate = 0.007840259
[DEBUG] 2018-05-22 11:38:07,447 -- BPR fold [9] iter 30: loss = 1644.8188, delta_loss = 154.70296, learn_rate = 0.007840259
[DEBUG] 2018-05-22 11:38:07,480 -- BPR fold [2] iter 30: loss = 1701.0671, delta_loss = 127.389465, learn_rate = 0.007840259
[DEBUG] 2018-05-22 11:38:07,485 -- BPR fold [10] iter 29: loss = 1832.3955, delta_loss = 98.01553, learn_rate = 0.007466913
[DEBUG] 2018-05-22 11:38:07,494 -- BPR fold [3] iter 30: loss = 1670.2761, delta_loss = 144.50586, learn_rate = 0.007840259
[DEBUG] 2018-05-22 11:38:07,500 -- BPR fold [5] iter 30: loss = 1679.7479, delta_loss = 133.95183, learn_rate = 0.007840259
[DEBUG] 2018-05-22 11:38:07,509 -- BPR fold [1] iter 30: loss = 1697.7432, delta_loss = 122.54975, learn_rate = 0.007840259
[DEBUG] 2018-05-22 11:38:07,576 -- BPR fold [6] iter 30: loss = 1698.7094, delta_loss = 123.184105, learn_rate = 0.007840259
[DEBUG] 2018-05-22 11:38:07,586 -- BPR fold [7] iter 30: loss = 1652.393, delta_loss = 170.85527, learn_rate = 0.007840259
[DEBUG] 2018-05-22 11:38:07,618 -- BPR fold [4] iter 30: loss = 1705.754, delta_loss = 103.76332, learn_rate = 0.007840259
[DEBUG] 2018-05-22 11:38:07,656 -- BPR fold [8] iter 31: loss = 1595.0919, delta_loss = 99.388245, learn_rate = 0.008232271
[DEBUG] 2018-05-22 11:38:07,701 -- BPR fold [2] iter 31: loss = 1567.0242, delta_loss = 134.04292, learn_rate = 0.008232271
[DEBUG] 2018-05-22 11:38:07,712 -- BPR fold [9] iter 31: loss = 1563.2502, delta_loss = 81.568634, learn_rate = 0.008232271
[DEBUG] 2018-05-22 11:38:07,719 -- BPR fold [10] iter 30: loss = 1696.7107, delta_loss = 135.68483, learn_rate = 0.007840259
[DEBUG] 2018-05-22 11:38:07,728 -- BPR fold [1] iter 31: loss = 1584.8279, delta_loss = 112.91526, learn_rate = 0.008232271
[DEBUG] 2018-05-22 11:38:07,730 -- BPR fold [5] iter 31: loss = 1584.7135, delta_loss = 95.03447, learn_rate = 0.008232271
[DEBUG] 2018-05-22 11:38:07,736 -- BPR fold [3] iter 31: loss = 1565.6836, delta_loss = 104.592476, learn_rate = 0.008232271
[DEBUG] 2018-05-22 11:38:07,738 -- BPR fold [6] iter 31: loss = 1568.0195, delta_loss = 130.68983, learn_rate = 0.008232271
[DEBUG] 2018-05-22 11:38:07,802 -- BPR fold [7] iter 31: loss = 1580.3926, delta_loss = 72.00037, learn_rate = 0.008232271
[DEBUG] 2018-05-22 11:38:07,829 -- BPR fold [4] iter 31: loss = 1594.5901, delta_loss = 111.164024, learn_rate = 0.008232271
[DEBUG] 2018-05-22 11:38:07,847 -- BPR fold [8] iter 32: loss = 1495.0376, delta_loss = 100.054375, learn_rate = 0.008643885
[DEBUG] 2018-05-22 11:38:07,915 -- BPR fold [10] iter 31: loss = 1575.5796, delta_loss = 121.13108, learn_rate = 0.008232271
[DEBUG] 2018-05-22 11:38:07,927 -- BPR fold [2] iter 32: loss = 1473.3015, delta_loss = 93.72271, learn_rate = 0.008643885
[DEBUG] 2018-05-22 11:38:07,945 -- BPR fold [9] iter 32: loss = 1455.0612, delta_loss = 108.18898, learn_rate = 0.008643885
[DEBUG] 2018-05-22 11:38:07,953 -- BPR fold [1] iter 32: loss = 1476.9816, delta_loss = 107.84628, learn_rate = 0.008643885
[DEBUG] 2018-05-22 11:38:08,020 -- BPR fold [3] iter 32: loss = 1467.4194, delta_loss = 98.26415, learn_rate = 0.008643885
[DEBUG] 2018-05-22 11:38:08,032 -- BPR fold [5] iter 32: loss = 1473.214, delta_loss = 111.49951, learn_rate = 0.008643885
[DEBUG] 2018-05-22 11:38:08,035 -- BPR fold [6] iter 32: loss = 1482.3346, delta_loss = 85.68497, learn_rate = 0.008643885
[DEBUG] 2018-05-22 11:38:08,054 -- BPR fold [7] iter 32: loss = 1461.4581, delta_loss = 118.9344, learn_rate = 0.008643885
[DEBUG] 2018-05-22 11:38:08,130 -- BPR fold [4] iter 32: loss = 1491.6598, delta_loss = 102.93022, learn_rate = 0.008643885
[DEBUG] 2018-05-22 11:38:08,147 -- BPR fold [8] iter 33: loss = 1395.0228, delta_loss = 100.014786, learn_rate = 0.009076079
[DEBUG] 2018-05-22 11:38:08,223 -- BPR fold [10] iter 32: loss = 1490.7695, delta_loss = 84.81006, learn_rate = 0.008643885
[DEBUG] 2018-05-22 11:38:08,229 -- BPR fold [2] iter 33: loss = 1399.0986, delta_loss = 74.2029, learn_rate = 0.009076079
[DEBUG] 2018-05-22 11:38:08,268 -- BPR fold [9] iter 33: loss = 1384.5293, delta_loss = 70.531944, learn_rate = 0.009076079
[DEBUG] 2018-05-22 11:38:08,274 -- BPR fold [1] iter 33: loss = 1376.7635, delta_loss = 100.21804, learn_rate = 0.009076079
[DEBUG] 2018-05-22 11:38:08,303 -- BPR fold [5] iter 33: loss = 1380.8246, delta_loss = 92.38937, learn_rate = 0.009076079
[DEBUG] 2018-05-22 11:38:08,315 -- BPR fold [3] iter 33: loss = 1374.6256, delta_loss = 92.79383, learn_rate = 0.009076079
[DEBUG] 2018-05-22 11:38:08,355 -- BPR fold [6] iter 33: loss = 1372.8104, delta_loss = 109.524124, learn_rate = 0.009076079
[DEBUG] 2018-05-22 11:38:08,370 -- BPR fold [7] iter 33: loss = 1383.3722, delta_loss = 78.08598, learn_rate = 0.009076079
[DEBUG] 2018-05-22 11:38:08,424 -- BPR fold [4] iter 33: loss = 1368.9121, delta_loss = 122.747696, learn_rate = 0.009076079
[DEBUG] 2018-05-22 11:38:08,460 -- BPR fold [8] iter 34: loss = 1305.5739, delta_loss = 89.448975, learn_rate = 0.009529883
[DEBUG] 2018-05-22 11:38:08,530 -- BPR fold [10] iter 33: loss = 1375.2142, delta_loss = 115.555374, learn_rate = 0.009076079
[DEBUG] 2018-05-22 11:38:08,552 -- BPR fold [2] iter 34: loss = 1294.7098, delta_loss = 104.38868, learn_rate = 0.009529883
[DEBUG] 2018-05-22 11:38:08,584 -- BPR fold [1] iter 34: loss = 1305.0868, delta_loss = 71.676704, learn_rate = 0.009529883
[DEBUG] 2018-05-22 11:38:08,584 -- BPR fold [9] iter 34: loss = 1301.1831, delta_loss = 83.346115, learn_rate = 0.009529883
[DEBUG] 2018-05-22 11:38:08,600 -- BPR fold [3] iter 34: loss = 1305.7285, delta_loss = 68.897125, learn_rate = 0.009529883
[DEBUG] 2018-05-22 11:38:08,616 -- BPR fold [5] iter 34: loss = 1276.0631, delta_loss = 104.76152, learn_rate = 0.009529883
[DEBUG] 2018-05-22 11:38:08,616 -- BPR fold [7] iter 34: loss = 1311.6857, delta_loss = 71.68643, learn_rate = 0.009529883
[DEBUG] 2018-05-22 11:38:08,627 -- BPR fold [6] iter 34: loss = 1298.495, delta_loss = 74.315475, learn_rate = 0.009529883
[DEBUG] 2018-05-22 11:38:08,701 -- BPR fold [4] iter 34: loss = 1293.9417, delta_loss = 74.97047, learn_rate = 0.009529883
[DEBUG] 2018-05-22 11:38:08,741 -- BPR fold [10] iter 34: loss = 1296.7799, delta_loss = 78.43432, learn_rate = 0.009529883
[DEBUG] 2018-05-22 11:38:08,748 -- BPR fold [8] iter 35: loss = 1209.403, delta_loss = 96.17093, learn_rate = 0.0100063775
[DEBUG] 2018-05-22 11:38:08,779 -- BPR fold [2] iter 35: loss = 1234.7897, delta_loss = 59.920273, learn_rate = 0.0100063775
[DEBUG] 2018-05-22 11:38:08,805 -- BPR fold [9] iter 35: loss = 1211.9907, delta_loss = 89.19245, learn_rate = 0.0100063775
[DEBUG] 2018-05-22 11:38:08,814 -- BPR fold [5] iter 35: loss = 1210.1559, delta_loss = 65.90726, learn_rate = 0.0100063775
[DEBUG] 2018-05-22 11:38:08,816 -- BPR fold [6] iter 35: loss = 1207.7089, delta_loss = 90.78611, learn_rate = 0.0100063775
[DEBUG] 2018-05-22 11:38:08,860 -- BPR fold [7] iter 35: loss = 1229.9487, delta_loss = 81.73694, learn_rate = 0.0100063775
[DEBUG] 2018-05-22 11:38:08,884 -- BPR fold [3] iter 35: loss = 1243.0409, delta_loss = 62.687565, learn_rate = 0.0100063775
[DEBUG] 2018-05-22 11:38:08,891 -- BPR fold [1] iter 35: loss = 1250.2537, delta_loss = 54.83323, learn_rate = 0.0100063775
[DEBUG] 2018-05-22 11:38:08,966 -- BPR fold [4] iter 35: loss = 1212.3015, delta_loss = 81.64017, learn_rate = 0.0100063775
[DEBUG] 2018-05-22 11:38:08,977 -- BPR fold [8] iter 36: loss = 1163.4769, delta_loss = 45.92591, learn_rate = 0.010506696
[DEBUG] 2018-05-22 11:38:09,031 -- BPR fold [9] iter 36: loss = 1136.8955, delta_loss = 75.09518, learn_rate = 0.010506696
[DEBUG] 2018-05-22 11:38:09,033 -- BPR fold [10] iter 35: loss = 1246.0569, delta_loss = 50.722996, learn_rate = 0.0100063775
[DEBUG] 2018-05-22 11:38:09,046 -- BPR fold [6] iter 36: loss = 1169.4038, delta_loss = 38.305065, learn_rate = 0.010506696
[DEBUG] 2018-05-22 11:38:09,051 -- BPR fold [2] iter 36: loss = 1168.5933, delta_loss = 66.19642, learn_rate = 0.010506696
[DEBUG] 2018-05-22 11:38:09,086 -- BPR fold [5] iter 36: loss = 1149.1178, delta_loss = 61.038033, learn_rate = 0.010506696
[DEBUG] 2018-05-22 11:38:09,110 -- BPR fold [1] iter 36: loss = 1141.4474, delta_loss = 108.80616, learn_rate = 0.010506696
[DEBUG] 2018-05-22 11:38:09,115 -- BPR fold [3] iter 36: loss = 1133.3889, delta_loss = 109.65201, learn_rate = 0.010506696
[DEBUG] 2018-05-22 11:38:09,134 -- BPR fold [7] iter 36: loss = 1157.5914, delta_loss = 72.35741, learn_rate = 0.010506696
[DEBUG] 2018-05-22 11:38:09,254 -- BPR fold [8] iter 37: loss = 1093.0023, delta_loss = 70.47466, learn_rate = 0.011032031
[DEBUG] 2018-05-22 11:38:09,277 -- BPR fold [4] iter 36: loss = 1149.4486, delta_loss = 62.852913, learn_rate = 0.010506696
[DEBUG] 2018-05-22 11:38:09,339 -- BPR fold [2] iter 37: loss = 1096.8258, delta_loss = 71.76743, learn_rate = 0.011032031
[DEBUG] 2018-05-22 11:38:09,343 -- BPR fold [10] iter 36: loss = 1143.2904, delta_loss = 102.76646, learn_rate = 0.010506696
[DEBUG] 2018-05-22 11:38:09,361 -- BPR fold [6] iter 37: loss = 1083.8741, delta_loss = 85.52958, learn_rate = 0.011032031
[DEBUG] 2018-05-22 11:38:09,388 -- BPR fold [1] iter 37: loss = 1090.2666, delta_loss = 51.18082, learn_rate = 0.011032031
[DEBUG] 2018-05-22 11:38:09,401 -- BPR fold [9] iter 37: loss = 1077.3412, delta_loss = 59.554325, learn_rate = 0.011032031
[DEBUG] 2018-05-22 11:38:09,419 -- BPR fold [5] iter 37: loss = 1061.1532, delta_loss = 87.9646, learn_rate = 0.011032031
[DEBUG] 2018-05-22 11:38:09,426 -- BPR fold [7] iter 37: loss = 1093.7596, delta_loss = 63.83173, learn_rate = 0.011032031
[DEBUG] 2018-05-22 11:38:09,444 -- BPR fold [3] iter 37: loss = 1073.4187, delta_loss = 59.970234, learn_rate = 0.011032031
[DEBUG] 2018-05-22 11:38:09,545 -- BPR fold [8] iter 38: loss = 1041.5961, delta_loss = 51.406265, learn_rate = 0.011583633
[DEBUG] 2018-05-22 11:38:09,550 -- BPR fold [4] iter 37: loss = 1092.2015, delta_loss = 57.247025, learn_rate = 0.011032031
[DEBUG] 2018-05-22 11:38:09,577 -- BPR fold [6] iter 38: loss = 1029.8159, delta_loss = 54.05822, learn_rate = 0.011583633
[DEBUG] 2018-05-22 11:38:09,588 -- BPR fold [10] iter 37: loss = 1088.246, delta_loss = 55.044483, learn_rate = 0.011032031
[DEBUG] 2018-05-22 11:38:09,614 -- BPR fold [2] iter 38: loss = 1008.51337, delta_loss = 88.31244, learn_rate = 0.011583633
[DEBUG] 2018-05-22 11:38:09,635 -- BPR fold [5] iter 38: loss = 1020.7128, delta_loss = 40.44036, learn_rate = 0.011583633
[DEBUG] 2018-05-22 11:38:09,649 -- BPR fold [1] iter 38: loss = 1031.1387, delta_loss = 59.127937, learn_rate = 0.011583633
[DEBUG] 2018-05-22 11:38:09,652 -- BPR fold [9] iter 38: loss = 1038.7162, delta_loss = 38.625, learn_rate = 0.011583633
[DEBUG] 2018-05-22 11:38:09,666 -- BPR fold [7] iter 38: loss = 1030.3804, delta_loss = 63.379284, learn_rate = 0.011583633
[DEBUG] 2018-05-22 11:38:09,739 -- BPR fold [3] iter 38: loss = 1030.9597, delta_loss = 42.458935, learn_rate = 0.011583633
[DEBUG] 2018-05-22 11:38:09,755 -- BPR fold [8] iter 39: loss = 981.3987, delta_loss = 60.197342, learn_rate = 0.012162815
[DEBUG] 2018-05-22 11:38:09,820 -- BPR fold [4] iter 38: loss = 1022.42255, delta_loss = 69.77898, learn_rate = 0.011583633
[DEBUG] 2018-05-22 11:38:09,886 -- BPR fold [6] iter 39: loss = 963.6376, delta_loss = 66.1784, learn_rate = 0.012162815
[DEBUG] 2018-05-22 11:38:09,896 -- BPR fold [10] iter 38: loss = 1051.9536, delta_loss = 36.29236, learn_rate = 0.011583633
[DEBUG] 2018-05-22 11:38:09,909 -- BPR fold [2] iter 39: loss = 974.84454, delta_loss = 33.668804, learn_rate = 0.012162815
[DEBUG] 2018-05-22 11:38:09,947 -- BPR fold [9] iter 39: loss = 977.2842, delta_loss = 61.43204, learn_rate = 0.012162815
[DEBUG] 2018-05-22 11:38:09,949 -- BPR fold [5] iter 39: loss = 957.7597, delta_loss = 62.95317, learn_rate = 0.012162815
[DEBUG] 2018-05-22 11:38:09,954 -- BPR fold [7] iter 39: loss = 974.9898, delta_loss = 55.39054, learn_rate = 0.012162815
[DEBUG] 2018-05-22 11:38:09,961 -- BPR fold [1] iter 39: loss = 978.3744, delta_loss = 52.764313, learn_rate = 0.012162815
[DEBUG] 2018-05-22 11:38:10,010 -- BPR fold [3] iter 39: loss = 977.43536, delta_loss = 53.52439, learn_rate = 0.012162815
[DEBUG] 2018-05-22 11:38:10,058 -- BPR fold [8] iter 40: loss = 927.2846, delta_loss = 54.1141, learn_rate = 0.012770955
[DEBUG] 2018-05-22 11:38:10,067 -- BPR fold [4] iter 39: loss = 989.19257, delta_loss = 33.22999, learn_rate = 0.012162815
[DEBUG] 2018-05-22 11:38:10,146 -- BPR fold [6] iter 40: loss = 926.41315, delta_loss = 37.224453, learn_rate = 0.012770955
[DEBUG] 2018-05-22 11:38:10,177 -- BPR fold [2] iter 40: loss = 922.44745, delta_loss = 52.397076, learn_rate = 0.012770955
[DEBUG] 2018-05-22 11:38:10,179 -- BPR fold [10] iter 39: loss = 979.68274, delta_loss = 72.27084, learn_rate = 0.012162815
[DEBUG] 2018-05-22 11:38:10,197 -- BPR fold [9] iter 40: loss = 908.3136, delta_loss = 68.97055, learn_rate = 0.012770955
[DEBUG] 2018-05-22 11:38:10,222 -- BPR fold [1] iter 40: loss = 936.168, delta_loss = 42.206333, learn_rate = 0.012770955
[DEBUG] 2018-05-22 11:38:10,272 -- BPR fold [7] iter 40: loss = 904.86426, delta_loss = 70.12554, learn_rate = 0.012770955
[DEBUG] 2018-05-22 11:38:10,285 -- BPR fold [5] iter 40: loss = 925.8814, delta_loss = 31.878267, learn_rate = 0.012770955
[DEBUG] 2018-05-22 11:38:10,297 -- BPR fold [3] iter 40: loss = 912.5306, delta_loss = 64.90482, learn_rate = 0.012770955
[DEBUG] 2018-05-22 11:38:10,368 -- BPR fold [8] iter 41: loss = 868.4386, delta_loss = 58.846004, learn_rate = 0.013409503
[DEBUG] 2018-05-22 11:38:10,437 -- BPR fold [4] iter 40: loss = 919.49554, delta_loss = 69.69704, learn_rate = 0.012770955
[DEBUG] 2018-05-22 11:38:10,438 -- BPR fold [10] iter 40: loss = 924.88654, delta_loss = 54.796185, learn_rate = 0.012770955
[DEBUG] 2018-05-22 11:38:10,482 -- BPR fold [6] iter 41: loss = 881.39984, delta_loss = 45.013306, learn_rate = 0.013409503
[DEBUG] 2018-05-22 11:38:10,494 -- BPR fold [2] iter 41: loss = 885.7983, delta_loss = 36.64917, learn_rate = 0.013409503
[DEBUG] 2018-05-22 11:38:10,504 -- BPR fold [1] iter 41: loss = 884.25055, delta_loss = 51.91747, learn_rate = 0.013409503
[DEBUG] 2018-05-22 11:38:10,507 -- BPR fold [9] iter 41: loss = 863.9839, delta_loss = 44.3297, learn_rate = 0.013409503
[DEBUG] 2018-05-22 11:38:10,536 -- BPR fold [7] iter 41: loss = 875.2295, delta_loss = 29.63479, learn_rate = 0.013409503
[DEBUG] 2018-05-22 11:38:10,539 -- BPR fold [5] iter 41: loss = 869.1415, delta_loss = 56.739925, learn_rate = 0.013409503
[DEBUG] 2018-05-22 11:38:10,552 -- BPR fold [3] iter 41: loss = 875.3267, delta_loss = 37.203854, learn_rate = 0.013409503
[DEBUG] 2018-05-22 11:38:10,614 -- BPR fold [8] iter 42: loss = 826.2891, delta_loss = 42.149506, learn_rate = 0.014079978
[DEBUG] 2018-05-22 11:38:10,628 -- BPR fold [4] iter 41: loss = 888.0645, delta_loss = 31.431025, learn_rate = 0.013409503
[DEBUG] 2018-05-22 11:38:10,720 -- BPR fold [10] iter 41: loss = 880.5317, delta_loss = 44.354866, learn_rate = 0.013409503
[DEBUG] 2018-05-22 11:38:10,726 -- BPR fold [2] iter 42: loss = 849.6007, delta_loss = 36.19756, learn_rate = 0.014079978
[DEBUG] 2018-05-22 11:38:10,733 -- BPR fold [9] iter 42: loss = 827.62366, delta_loss = 36.36023, learn_rate = 0.014079978
[DEBUG] 2018-05-22 11:38:10,738 -- BPR fold [6] iter 42: loss = 829.3855, delta_loss = 52.014328, learn_rate = 0.014079978
[DEBUG] 2018-05-22 11:38:10,747 -- BPR fold [7] iter 42: loss = 824.7558, delta_loss = 50.473698, learn_rate = 0.014079978
[DEBUG] 2018-05-22 11:38:10,748 -- BPR fold [1] iter 42: loss = 838.0097, delta_loss = 46.24085, learn_rate = 0.014079978
[DEBUG] 2018-05-22 11:38:10,778 -- BPR fold [3] iter 42: loss = 839.87695, delta_loss = 35.44974, learn_rate = 0.014079978
[DEBUG] 2018-05-22 11:38:10,797 -- BPR fold [5] iter 42: loss = 823.31494, delta_loss = 45.826534, learn_rate = 0.014079978
[DEBUG] 2018-05-22 11:38:10,851 -- BPR fold [4] iter 42: loss = 840.41797, delta_loss = 47.646545, learn_rate = 0.014079978
[DEBUG] 2018-05-22 11:38:10,858 -- BPR fold [8] iter 43: loss = 799.0172, delta_loss = 27.27187, learn_rate = 0.014783977
[DEBUG] 2018-05-22 11:38:10,900 -- BPR fold [10] iter 42: loss = 837.02484, delta_loss = 43.506866, learn_rate = 0.014079978
[DEBUG] 2018-05-22 11:38:10,937 -- BPR fold [2] iter 43: loss = 810.75214, delta_loss = 38.848618, learn_rate = 0.014783977
[DEBUG] 2018-05-22 11:38:10,946 -- BPR fold [1] iter 43: loss = 803.58746, delta_loss = 34.422283, learn_rate = 0.014783977
[DEBUG] 2018-05-22 11:38:10,953 -- BPR fold [6] iter 43: loss = 799.7383, delta_loss = 29.647243, learn_rate = 0.014783977
[DEBUG] 2018-05-22 11:38:10,962 -- BPR fold [9] iter 43: loss = 788.55707, delta_loss = 39.066586, learn_rate = 0.014783977
[DEBUG] 2018-05-22 11:38:10,964 -- BPR fold [7] iter 43: loss = 800.9489, delta_loss = 23.806883, learn_rate = 0.014783977
[DEBUG] 2018-05-22 11:38:10,981 -- BPR fold [3] iter 43: loss = 790.0437, delta_loss = 49.833275, learn_rate = 0.014783977
[DEBUG] 2018-05-22 11:38:10,994 -- BPR fold [5] iter 43: loss = 790.4761, delta_loss = 32.838905, learn_rate = 0.014783977
[DEBUG] 2018-05-22 11:38:11,055 -- BPR fold [4] iter 43: loss = 791.3265, delta_loss = 49.091488, learn_rate = 0.014783977
[DEBUG] 2018-05-22 11:38:11,101 -- BPR fold [8] iter 44: loss = 753.5071, delta_loss = 45.51017, learn_rate = 0.015523176
[DEBUG] 2018-05-22 11:38:11,145 -- BPR fold [6] iter 44: loss = 758.72314, delta_loss = 41.015125, learn_rate = 0.015523176
[DEBUG] 2018-05-22 11:38:11,166 -- BPR fold [10] iter 43: loss = 802.9425, delta_loss = 34.082317, learn_rate = 0.014783977
[DEBUG] 2018-05-22 11:38:11,173 -- BPR fold [1] iter 44: loss = 761.6458, delta_loss = 41.941628, learn_rate = 0.015523176
[DEBUG] 2018-05-22 11:38:11,181 -- BPR fold [7] iter 44: loss = 761.5287, delta_loss = 39.42021, learn_rate = 0.015523176
[DEBUG] 2018-05-22 11:38:11,181 -- BPR fold [2] iter 44: loss = 767.8046, delta_loss = 42.947468, learn_rate = 0.015523176
[DEBUG] 2018-05-22 11:38:11,185 -- BPR fold [3] iter 44: loss = 747.57794, delta_loss = 42.46577, learn_rate = 0.015523176
[DEBUG] 2018-05-22 11:38:11,205 -- BPR fold [9] iter 44: loss = 751.865, delta_loss = 36.69213, learn_rate = 0.015523176
[DEBUG] 2018-05-22 11:38:11,215 -- BPR fold [5] iter 44: loss = 757.6816, delta_loss = 32.79449, learn_rate = 0.015523176
[DEBUG] 2018-05-22 11:38:11,291 -- BPR fold [4] iter 44: loss = 754.9436, delta_loss = 36.382915, learn_rate = 0.015523176
[DEBUG] 2018-05-22 11:38:11,305 -- BPR fold [8] iter 45: loss = 728.74475, delta_loss = 24.762283, learn_rate = 0.016299335
[DEBUG] 2018-05-22 11:38:11,348 -- BPR fold [6] iter 45: loss = 728.93677, delta_loss = 29.786345, learn_rate = 0.016299335
[DEBUG] 2018-05-22 11:38:11,374 -- BPR fold [9] iter 45: loss = 735.981, delta_loss = 15.883933, learn_rate = 0.016299335
[DEBUG] 2018-05-22 11:38:11,405 -- BPR fold [10] iter 44: loss = 783.071, delta_loss = 19.871504, learn_rate = 0.015523176
[DEBUG] 2018-05-22 11:38:11,421 -- BPR fold [1] iter 45: loss = 731.4232, delta_loss = 30.222582, learn_rate = 0.016299335
[DEBUG] 2018-05-22 11:38:11,428 -- BPR fold [2] iter 45: loss = 718.58594, delta_loss = 49.218735, learn_rate = 0.016299335
[DEBUG] 2018-05-22 11:38:11,438 -- BPR fold [7] iter 45: loss = 716.90674, delta_loss = 44.621933, learn_rate = 0.016299335
[DEBUG] 2018-05-22 11:38:11,443 -- BPR fold [5] iter 45: loss = 730.74036, delta_loss = 26.941202, learn_rate = 0.016299335
[DEBUG] 2018-05-22 11:38:11,467 -- BPR fold [3] iter 45: loss = 720.4275, delta_loss = 27.1504, learn_rate = 0.016299335
[DEBUG] 2018-05-22 11:38:11,640 -- BPR fold [4] iter 45: loss = 728.8939, delta_loss = 26.04963, learn_rate = 0.016299335
[DEBUG] 2018-05-22 11:38:11,716 -- BPR fold [8] iter 46: loss = 694.9531, delta_loss = 33.791645, learn_rate = 0.017114302
[DEBUG] 2018-05-22 11:38:11,728 -- BPR fold [6] iter 46: loss = 687.5516, delta_loss = 41.3852, learn_rate = 0.017114302
[DEBUG] 2018-05-22 11:38:11,735 -- BPR fold [10] iter 45: loss = 721.8394, delta_loss = 61.231583, learn_rate = 0.016299335
[DEBUG] 2018-05-22 11:38:11,768 -- BPR fold [7] iter 46: loss = 687.10266, delta_loss = 29.804089, learn_rate = 0.017114302
[DEBUG] 2018-05-22 11:38:11,801 -- BPR fold [9] iter 46: loss = 697.9354, delta_loss = 38.045586, learn_rate = 0.017114302
[DEBUG] 2018-05-22 11:38:11,811 -- BPR fold [2] iter 46: loss = 709.8486, delta_loss = 8.737311, learn_rate = 0.017114302
[DEBUG] 2018-05-22 11:38:11,821 -- BPR fold [1] iter 46: loss = 700.3216, delta_loss = 31.101608, learn_rate = 0.017114302
[DEBUG] 2018-05-22 11:38:11,831 -- BPR fold [3] iter 46: loss = 684.1202, delta_loss = 36.307316, learn_rate = 0.017114302
[DEBUG] 2018-05-22 11:38:11,925 -- BPR fold [5] iter 46: loss = 693.28314, delta_loss = 37.457203, learn_rate = 0.017114302
[DEBUG] 2018-05-22 11:38:12,099 -- BPR fold [6] iter 47: loss = 657.89545, delta_loss = 29.656149, learn_rate = 0.017970016
[DEBUG] 2018-05-22 11:38:12,105 -- BPR fold [4] iter 46: loss = 682.6479, delta_loss = 46.246056, learn_rate = 0.017114302
[DEBUG] 2018-05-22 11:38:12,184 -- BPR fold [8] iter 47: loss = 668.12726, delta_loss = 26.825861, learn_rate = 0.017970016
[DEBUG] 2018-05-22 11:38:12,239 -- BPR fold [2] iter 47: loss = 657.6872, delta_loss = 52.1614, learn_rate = 0.017970016
[DEBUG] 2018-05-22 11:38:12,246 -- BPR fold [3] iter 47: loss = 670.3103, delta_loss = 13.80992, learn_rate = 0.017970016
[DEBUG] 2018-05-22 11:38:12,254 -- BPR fold [7] iter 47: loss = 657.9601, delta_loss = 29.142593, learn_rate = 0.017970016
[DEBUG] 2018-05-22 11:38:12,261 -- BPR fold [5] iter 47: loss = 664.2312, delta_loss = 29.051973, learn_rate = 0.017970016
[DEBUG] 2018-05-22 11:38:12,269 -- BPR fold [10] iter 46: loss = 700.0012, delta_loss = 21.838211, learn_rate = 0.017114302
[DEBUG] 2018-05-22 11:38:12,294 -- BPR fold [9] iter 47: loss = 659.6095, delta_loss = 38.325954, learn_rate = 0.017970016
[DEBUG] 2018-05-22 11:38:12,317 -- BPR fold [1] iter 47: loss = 667.77563, delta_loss = 32.54601, learn_rate = 0.017970016
[DEBUG] 2018-05-22 11:38:12,395 -- BPR fold [6] iter 48: loss = 632.5752, delta_loss = 25.320261, learn_rate = 0.018868517
[DEBUG] 2018-05-22 11:38:12,482 -- BPR fold [4] iter 47: loss = 669.3996, delta_loss = 13.248311, learn_rate = 0.017970016
[DEBUG] 2018-05-22 11:38:12,491 -- BPR fold [7] iter 48: loss = 647.51086, delta_loss = 10.449187, learn_rate = 0.018868517
[DEBUG] 2018-05-22 11:38:12,549 -- BPR fold [3] iter 48: loss = 649.4342, delta_loss = 20.876045, learn_rate = 0.018868517
[DEBUG] 2018-05-22 11:38:12,564 -- BPR fold [8] iter 48: loss = 638.7795, delta_loss = 29.347792, learn_rate = 0.018868517
[DEBUG] 2018-05-22 11:38:12,568 -- BPR fold [9] iter 48: loss = 627.0973, delta_loss = 32.5122, learn_rate = 0.018868517
[DEBUG] 2018-05-22 11:38:12,570 -- BPR fold [10] iter 47: loss = 666.0018, delta_loss = 33.999435, learn_rate = 0.017970016
[DEBUG] 2018-05-22 11:38:12,582 -- BPR fold [1] iter 48: loss = 629.1523, delta_loss = 38.623318, learn_rate = 0.018868517
[DEBUG] 2018-05-22 11:38:12,647 -- BPR fold [2] iter 48: loss = 649.64453, delta_loss = 8.04268, learn_rate = 0.018868517
[DEBUG] 2018-05-22 11:38:12,696 -- BPR fold [5] iter 48: loss = 633.03064, delta_loss = 31.200563, learn_rate = 0.018868517
[DEBUG] 2018-05-22 11:38:12,727 -- BPR fold [6] iter 49: loss = 607.24445, delta_loss = 25.330748, learn_rate = 0.019811943
[DEBUG] 2018-05-22 11:38:12,759 -- BPR fold [3] iter 49: loss = 616.8692, delta_loss = 32.565002, learn_rate = 0.019811943
[DEBUG] 2018-05-22 11:38:12,760 -- BPR fold [7] iter 49: loss = 614.5768, delta_loss = 32.934116, learn_rate = 0.019811943
[DEBUG] 2018-05-22 11:38:12,814 -- BPR fold [4] iter 48: loss = 633.1104, delta_loss = 36.28915, learn_rate = 0.018868517
[DEBUG] 2018-05-22 11:38:12,847 -- BPR fold [1] iter 49: loss = 607.8958, delta_loss = 21.256504, learn_rate = 0.019811943
[DEBUG] 2018-05-22 11:38:12,890 -- BPR fold [9] iter 49: loss = 608.44244, delta_loss = 18.654844, learn_rate = 0.019811943
[DEBUG] 2018-05-22 11:38:12,994 -- BPR fold [10] iter 48: loss = 645.662, delta_loss = 20.339808, learn_rate = 0.018868517
[DEBUG] 2018-05-22 11:38:13,018 -- BPR fold [4] iter 49: loss = 620.7256, delta_loss = 12.38485, learn_rate = 0.019811943
[DEBUG] 2018-05-22 11:38:13,023 -- BPR fold [2] iter 49: loss = 615.8473, delta_loss = 33.79725, learn_rate = 0.019811943
[DEBUG] 2018-05-22 11:38:13,044 -- BPR fold [8] iter 49: loss = 615.81335, delta_loss = 22.96611, learn_rate = 0.019811943
[DEBUG] 2018-05-22 11:38:13,074 -- BPR fold [1] iter 50: loss = 592.17944, delta_loss = 15.716328, learn_rate = 0.02080254
[DEBUG] 2018-05-22 11:38:13,095 -- BPR fold [5] iter 49: loss = 595.268, delta_loss = 37.762634, learn_rate = 0.019811943
[DEBUG] 2018-05-22 11:38:13,097 -- BPR fold [3] iter 50: loss = 581.8322, delta_loss = 35.03703, learn_rate = 0.02080254
[DEBUG] 2018-05-22 11:38:13,105 -- BPR fold [7] iter 50: loss = 584.00903, delta_loss = 30.56775, learn_rate = 0.02080254
[DEBUG] 2018-05-22 11:38:13,199 -- BPR fold [6] iter 50: loss = 590.14966, delta_loss = 17.094788, learn_rate = 0.02080254
[DEBUG] 2018-05-22 11:38:13,248 -- BPR fold [9] iter 50: loss = 588.5586, delta_loss = 19.883865, learn_rate = 0.02080254
[DEBUG] 2018-05-22 11:38:13,338 -- BPR fold [10] iter 49: loss = 620.4897, delta_loss = 25.172318, learn_rate = 0.019811943
[DEBUG] 2018-05-22 11:38:13,397 -- BPR fold [8] iter 50: loss = 579.7513, delta_loss = 36.06206, learn_rate = 0.02080254
[DEBUG] 2018-05-22 11:38:13,420 -- BPR fold [7] iter 51: loss = 565.52704, delta_loss = 18.481968, learn_rate = 0.021842668
[DEBUG] 2018-05-22 11:38:13,432 -- BPR fold [2] iter 50: loss = 593.7141, delta_loss = 22.133186, learn_rate = 0.02080254
[DEBUG] 2018-05-22 11:38:13,440 -- BPR fold [1] iter 51: loss = 568.8195, delta_loss = 23.359913, learn_rate = 0.021842668
[DEBUG] 2018-05-22 11:38:13,465 -- BPR fold [5] iter 50: loss = 580.67834, delta_loss = 14.5896635, learn_rate = 0.02080254
[DEBUG] 2018-05-22 11:38:13,477 -- BPR fold [4] iter 50: loss = 579.89197, delta_loss = 40.833607, learn_rate = 0.02080254
[DEBUG] 2018-05-22 11:38:13,511 -- BPR fold [6] iter 51: loss = 559.99567, delta_loss = 30.153954, learn_rate = 0.021842668
[DEBUG] 2018-05-22 11:38:13,572 -- BPR fold [3] iter 51: loss = 574.35645, delta_loss = 7.475729, learn_rate = 0.021842668
[DEBUG] 2018-05-22 11:38:13,640 -- BPR fold [7] iter 52: loss = 542.0201, delta_loss = 23.506994, learn_rate = 0.0229348
[DEBUG] 2018-05-22 11:38:13,666 -- BPR fold [9] iter 51: loss = 559.6823, delta_loss = 28.87627, learn_rate = 0.021842668
[DEBUG] 2018-05-22 11:38:13,690 -- BPR fold [8] iter 51: loss = 558.7455, delta_loss = 21.005816, learn_rate = 0.021842668
[DEBUG] 2018-05-22 11:38:13,761 -- BPR fold [10] iter 50: loss = 577.3715, delta_loss = 43.118122, learn_rate = 0.02080254
[DEBUG] 2018-05-22 11:38:13,811 -- BPR fold [5] iter 51: loss = 575.4049, delta_loss = 5.273414, learn_rate = 0.021842668
[DEBUG] 2018-05-22 11:38:13,817 -- BPR fold [2] iter 51: loss = 568.5956, delta_loss = 25.118502, learn_rate = 0.021842668
[DEBUG] 2018-05-22 11:38:13,827 -- BPR fold [1] iter 52: loss = 552.51025, delta_loss = 16.30932, learn_rate = 0.0229348
[DEBUG] 2018-05-22 11:38:13,840 -- BPR fold [4] iter 51: loss = 570.73126, delta_loss = 9.160727, learn_rate = 0.021842668
[DEBUG] 2018-05-22 11:38:13,855 -- BPR fold [6] iter 52: loss = 549.2763, delta_loss = 10.719361, learn_rate = 0.0229348
[DEBUG] 2018-05-22 11:38:13,939 -- BPR fold [3] iter 52: loss = 549.4697, delta_loss = 24.886742, learn_rate = 0.0229348
[DEBUG] 2018-05-22 11:38:13,986 -- BPR fold [9] iter 52: loss = 541.9975, delta_loss = 17.684818, learn_rate = 0.0229348
[DEBUG] 2018-05-22 11:38:14,082 -- BPR fold [7] iter 53: loss = 528.77924, delta_loss = 13.240854, learn_rate = 0.024081541
[DEBUG] 2018-05-22 11:38:14,105 -- BPR fold [8] iter 52: loss = 550.1736, delta_loss = 8.571912, learn_rate = 0.0229348
[DEBUG] 2018-05-22 11:38:14,115 -- BPR fold [10] iter 51: loss = 570.78564, delta_loss = 6.585883, learn_rate = 0.021842668
[DEBUG] 2018-05-22 11:38:14,174 -- BPR fold [5] iter 52: loss = 556.7432, delta_loss = 18.661697, learn_rate = 0.0229348
[DEBUG] 2018-05-22 11:38:14,181 -- BPR fold [2] iter 52: loss = 543.3681, delta_loss = 25.227507, learn_rate = 0.0229348
[DEBUG] 2018-05-22 11:38:14,202 -- BPR fold [6] iter 53: loss = 526.39325, delta_loss = 22.883045, learn_rate = 0.024081541
[DEBUG] 2018-05-22 11:38:14,204 -- BPR fold [4] iter 52: loss = 546.3446, delta_loss = 24.386658, learn_rate = 0.0229348
[DEBUG] 2018-05-22 11:38:14,206 -- BPR fold [1] iter 53: loss = 527.31866, delta_loss = 25.191534, learn_rate = 0.024081541
[DEBUG] 2018-05-22 11:38:14,268 -- BPR fold [9] iter 53: loss = 519.47906, delta_loss = 22.518423, learn_rate = 0.024081541
[DEBUG] 2018-05-22 11:38:14,270 -- BPR fold [3] iter 53: loss = 526.0562, delta_loss = 23.413546, learn_rate = 0.024081541
[DEBUG] 2018-05-22 11:38:14,337 -- BPR fold [7] iter 54: loss = 518.4131, delta_loss = 10.366141, learn_rate = 0.025285618
[DEBUG] 2018-05-22 11:38:14,420 -- BPR fold [8] iter 53: loss = 536.9945, delta_loss = 13.17906, learn_rate = 0.024081541
[DEBUG] 2018-05-22 11:38:14,502 -- BPR fold [10] iter 52: loss = 545.38617, delta_loss = 25.39945, learn_rate = 0.0229348
[DEBUG] 2018-05-22 11:38:14,522 -- BPR fold [5] iter 53: loss = 532.82776, delta_loss = 23.915482, learn_rate = 0.024081541
[DEBUG] 2018-05-22 11:38:14,559 -- BPR fold [2] iter 53: loss = 529.097, delta_loss = 14.271106, learn_rate = 0.024081541
[DEBUG] 2018-05-22 11:38:14,561 -- BPR fold [1] iter 54: loss = 508.69284, delta_loss = 18.625845, learn_rate = 0.025285618
[DEBUG] 2018-05-22 11:38:14,570 -- BPR fold [4] iter 53: loss = 528.9833, delta_loss = 17.361319, learn_rate = 0.024081541
[DEBUG] 2018-05-22 11:38:14,592 -- BPR fold [6] iter 54: loss = 508.73514, delta_loss = 17.658144, learn_rate = 0.025285618
[DEBUG] 2018-05-22 11:38:14,661 -- BPR fold [3] iter 54: loss = 510.6356, delta_loss = 15.420606, learn_rate = 0.025285618
[DEBUG] 2018-05-22 11:38:14,672 -- BPR fold [9] iter 54: loss = 497.21457, delta_loss = 22.264494, learn_rate = 0.025285618
[DEBUG] 2018-05-22 11:38:14,751 -- BPR fold [10] iter 53: loss = 533.4728, delta_loss = 11.913399, learn_rate = 0.024081541
[DEBUG] 2018-05-22 11:38:14,767 -- BPR fold [7] iter 55: loss = 497.45572, delta_loss = 20.957367, learn_rate = 0.026549898
[DEBUG] 2018-05-22 11:38:14,785 -- BPR fold [8] iter 54: loss = 508.32452, delta_loss = 28.670015, learn_rate = 0.025285618
[DEBUG] 2018-05-22 11:38:14,858 -- BPR fold [5] iter 54: loss = 510.94092, delta_loss = 21.886818, learn_rate = 0.025285618
[DEBUG] 2018-05-22 11:38:14,871 -- BPR fold [2] iter 54: loss = 510.40536, delta_loss = 18.6916, learn_rate = 0.025285618
[DEBUG] 2018-05-22 11:38:14,895 -- BPR fold [1] iter 55: loss = 505.17114, delta_loss = 3.5217, learn_rate = 0.026549898
[DEBUG] 2018-05-22 11:38:14,974 -- BPR fold [6] iter 55: loss = 500.2811, delta_loss = 8.454034, learn_rate = 0.026549898
[DEBUG] 2018-05-22 11:38:14,987 -- BPR fold [4] iter 54: loss = 512.18567, delta_loss = 16.797575, learn_rate = 0.025285618
[DEBUG] 2018-05-22 11:38:15,036 -- BPR fold [7] iter 56: loss = 471.58728, delta_loss = 25.868423, learn_rate = 0.027877394
[DEBUG] 2018-05-22 11:38:15,047 -- BPR fold [3] iter 55: loss = 502.70532, delta_loss = 7.930267, learn_rate = 0.026549898
[DEBUG] 2018-05-22 11:38:15,070 -- BPR fold [9] iter 55: loss = 487.95328, delta_loss = 9.261298, learn_rate = 0.026549898
[DEBUG] 2018-05-22 11:38:15,201 -- BPR fold [2] iter 55: loss = 499.80563, delta_loss = 10.59973, learn_rate = 0.026549898
[DEBUG] 2018-05-22 11:38:15,230 -- BPR fold [5] iter 55: loss = 490.50882, delta_loss = 20.432095, learn_rate = 0.026549898
[DEBUG] 2018-05-22 11:38:15,213 -- BPR fold [8] iter 55: loss = 486.8635, delta_loss = 21.46102, learn_rate = 0.026549898
[DEBUG] 2018-05-22 11:38:15,202 -- BPR fold [10] iter 54: loss = 514.7462, delta_loss = 18.726597, learn_rate = 0.025285618
[DEBUG] 2018-05-22 11:38:15,256 -- BPR fold [1] iter 56: loss = 481.24362, delta_loss = 23.927538, learn_rate = 0.027877394
[DEBUG] 2018-05-22 11:38:15,273 -- BPR fold [4] iter 55: loss = 491.48352, delta_loss = 20.702188, learn_rate = 0.026549898
[DEBUG] 2018-05-22 11:38:15,316 -- BPR fold [6] iter 56: loss = 479.5616, delta_loss = 20.719482, learn_rate = 0.027877394
[DEBUG] 2018-05-22 11:38:15,372 -- BPR fold [3] iter 56: loss = 478.0388, delta_loss = 24.666538, learn_rate = 0.027877394
[DEBUG] 2018-05-22 11:38:15,414 -- BPR fold [9] iter 56: loss = 481.44717, delta_loss = 6.5061116, learn_rate = 0.027877394
[DEBUG] 2018-05-22 11:38:15,430 -- BPR fold [7] iter 57: loss = 455.1172, delta_loss = 16.470102, learn_rate = 0.029271264
[DEBUG] 2018-05-22 11:38:15,480 -- BPR fold [10] iter 55: loss = 494.92584, delta_loss = 19.82035, learn_rate = 0.026549898
[DEBUG] 2018-05-22 11:38:15,512 -- BPR fold [8] iter 56: loss = 474.27798, delta_loss = 12.5855055, learn_rate = 0.027877394
[DEBUG] 2018-05-22 11:38:15,536 -- BPR fold [2] iter 56: loss = 484.55173, delta_loss = 15.253922, learn_rate = 0.027877394
[DEBUG] 2018-05-22 11:38:15,549 -- BPR fold [5] iter 56: loss = 470.59937, delta_loss = 19.90946, learn_rate = 0.027877394
[DEBUG] 2018-05-22 11:38:15,591 -- BPR fold [6] iter 57: loss = 466.9217, delta_loss = 12.639919, learn_rate = 0.029271264
[DEBUG] 2018-05-22 11:38:15,598 -- BPR fold [1] iter 57: loss = 463.47018, delta_loss = 17.773413, learn_rate = 0.029271264
[DEBUG] 2018-05-22 11:38:15,659 -- BPR fold [9] iter 57: loss = 463.95865, delta_loss = 17.488504, learn_rate = 0.029271264
[DEBUG] 2018-05-22 11:38:15,663 -- BPR fold [4] iter 56: loss = 482.80618, delta_loss = 8.677332, learn_rate = 0.027877394
[DEBUG] 2018-05-22 11:38:15,681 -- BPR fold [3] iter 57: loss = 452.57986, delta_loss = 25.458906, learn_rate = 0.029271264
[DEBUG] 2018-05-22 11:38:15,779 -- BPR fold [7] iter 58: loss = 447.11392, delta_loss = 8.00327, learn_rate = 0.030734826
[DEBUG] 2018-05-22 11:38:15,794 -- BPR fold [2] iter 57: loss = 472.0144, delta_loss = 12.537309, learn_rate = 0.029271264
[DEBUG] 2018-05-22 11:38:15,835 -- BPR fold [8] iter 57: loss = 459.6637, delta_loss = 14.614282, learn_rate = 0.029271264
[DEBUG] 2018-05-22 11:38:15,836 -- BPR fold [10] iter 56: loss = 493.1913, delta_loss = 1.7345506, learn_rate = 0.027877394
[DEBUG] 2018-05-22 11:38:15,883 -- BPR fold [4] iter 57: loss = 464.64963, delta_loss = 18.156553, learn_rate = 0.029271264
[DEBUG] 2018-05-22 11:38:15,885 -- BPR fold [6] iter 58: loss = 447.6003, delta_loss = 19.321375, learn_rate = 0.030734826
[DEBUG] 2018-05-22 11:38:15,909 -- BPR fold [5] iter 57: loss = 463.8186, delta_loss = 6.7807665, learn_rate = 0.029271264
[DEBUG] 2018-05-22 11:38:15,929 -- BPR fold [1] iter 58: loss = 446.35565, delta_loss = 17.114555, learn_rate = 0.030734826
[DEBUG] 2018-05-22 11:38:15,966 -- BPR fold [3] iter 58: loss = 448.7109, delta_loss = 3.8689613, learn_rate = 0.030734826
[DEBUG] 2018-05-22 11:38:15,992 -- BPR fold [7] iter 59: loss = 438.38278, delta_loss = 8.731118, learn_rate = 0.032271568
[DEBUG] 2018-05-22 11:38:16,005 -- BPR fold [9] iter 58: loss = 452.31552, delta_loss = 11.643137, learn_rate = 0.030734826
[DEBUG] 2018-05-22 11:38:16,114 -- BPR fold [8] iter 58: loss = 441.09802, delta_loss = 18.565695, learn_rate = 0.030734826
[DEBUG] 2018-05-22 11:38:16,140 -- BPR fold [2] iter 58: loss = 449.3405, delta_loss = 22.673912, learn_rate = 0.030734826
[DEBUG] 2018-05-22 11:38:16,182 -- BPR fold [10] iter 57: loss = 466.11053, delta_loss = 27.080782, learn_rate = 0.029271264
[DEBUG] 2018-05-22 11:38:16,218 -- BPR fold [6] iter 59: loss = 442.7203, delta_loss = 4.880025, learn_rate = 0.032271568
[DEBUG] 2018-05-22 11:38:16,229 -- BPR fold [5] iter 58: loss = 443.73843, delta_loss = 20.080168, learn_rate = 0.030734826
[DEBUG] 2018-05-22 11:38:16,245 -- BPR fold [1] iter 59: loss = 436.9196, delta_loss = 9.436065, learn_rate = 0.032271568
[DEBUG] 2018-05-22 11:38:16,297 -- BPR fold [9] iter 59: loss = 432.43448, delta_loss = 19.881031, learn_rate = 0.032271568
[DEBUG] 2018-05-22 11:38:16,322 -- BPR fold [4] iter 58: loss = 457.25906, delta_loss = 7.390566, learn_rate = 0.030734826
[DEBUG] 2018-05-22 11:38:16,330 -- BPR fold [7] iter 60: loss = 427.3958, delta_loss = 10.986964, learn_rate = 0.033885147
[DEBUG] 2018-05-22 11:38:16,339 -- BPR fold [3] iter 59: loss = 438.562, delta_loss = 10.148897, learn_rate = 0.032271568
[DEBUG] 2018-05-22 11:38:16,412 -- BPR fold [8] iter 59: loss = 435.32993, delta_loss = 5.768082, learn_rate = 0.032271568
[DEBUG] 2018-05-22 11:38:16,423 -- BPR fold [2] iter 59: loss = 438.75757, delta_loss = 10.582945, learn_rate = 0.032271568
[DEBUG] 2018-05-22 11:38:16,482 -- BPR fold [5] iter 59: loss = 433.0428, delta_loss = 10.6956415, learn_rate = 0.032271568
[DEBUG] 2018-05-22 11:38:16,488 -- BPR fold [6] iter 60: loss = 428.70865, delta_loss = 14.011649, learn_rate = 0.033885147
[DEBUG] 2018-05-22 11:38:16,494 -- BPR fold [10] iter 58: loss = 443.68076, delta_loss = 22.429762, learn_rate = 0.030734826
[DEBUG] 2018-05-22 11:38:16,516 -- BPR fold [1] iter 60: loss = 428.05447, delta_loss = 8.8651, learn_rate = 0.033885147
[DEBUG] 2018-05-22 11:38:16,555 -- BPR fold [9] iter 60: loss = 418.68137, delta_loss = 13.753129, learn_rate = 0.033885147
[DEBUG] 2018-05-22 11:38:16,585 -- BPR fold [3] iter 60: loss = 427.51144, delta_loss = 11.050576, learn_rate = 0.033885147
[DEBUG] 2018-05-22 11:38:16,603 -- BPR fold [4] iter 59: loss = 429.97742, delta_loss = 27.281628, learn_rate = 0.032271568
[DEBUG] 2018-05-22 11:38:16,639 -- BPR fold [7] iter 61: loss = 414.62973, delta_loss = 12.766094, learn_rate = 0.035579402
[DEBUG] 2018-05-22 11:38:16,700 -- BPR fold [8] iter 60: loss = 419.70084, delta_loss = 15.629104, learn_rate = 0.033885147
[DEBUG] 2018-05-22 11:38:16,718 -- BPR fold [2] iter 60: loss = 420.92435, delta_loss = 17.833208, learn_rate = 0.033885147
[DEBUG] 2018-05-22 11:38:16,747 -- BPR fold [10] iter 59: loss = 436.21896, delta_loss = 7.4618077, learn_rate = 0.032271568
[DEBUG] 2018-05-22 11:38:16,758 -- BPR fold [6] iter 61: loss = 423.14743, delta_loss = 5.5612197, learn_rate = 0.035579402
[DEBUG] 2018-05-22 11:38:16,780 -- BPR fold [5] iter 60: loss = 424.49365, delta_loss = 8.54912, learn_rate = 0.033885147
[DEBUG] 2018-05-22 11:38:16,784 -- BPR fold [1] iter 61: loss = 418.42233, delta_loss = 9.63214, learn_rate = 0.035579402
[DEBUG] 2018-05-22 11:38:16,821 -- BPR fold [4] iter 60: loss = 424.65842, delta_loss = 5.3190036, learn_rate = 0.033885147
[DEBUG] 2018-05-22 11:38:16,822 -- BPR fold [3] iter 61: loss = 417.16183, delta_loss = 10.349593, learn_rate = 0.035579402
[DEBUG] 2018-05-22 11:38:16,825 -- BPR fold [9] iter 61: loss = 415.81137, delta_loss = 2.8699872, learn_rate = 0.035579402
[DEBUG] 2018-05-22 11:38:16,852 -- BPR fold [7] iter 62: loss = 404.66132, delta_loss = 9.968424, learn_rate = 0.037358373
[DEBUG] 2018-05-22 11:38:16,931 -- BPR fold [8] iter 61: loss = 412.52646, delta_loss = 7.174359, learn_rate = 0.035579402
[DEBUG] 2018-05-22 11:38:16,936 -- BPR fold [2] iter 61: loss = 406.55005, delta_loss = 14.374307, learn_rate = 0.035579402
[DEBUG] 2018-05-22 11:38:16,959 -- BPR fold [10] iter 60: loss = 429.47455, delta_loss = 6.744394, learn_rate = 0.033885147
[DEBUG] 2018-05-22 11:38:16,991 -- BPR fold [1] iter 62: loss = 399.54214, delta_loss = 18.880201, learn_rate = 0.037358373
[DEBUG] 2018-05-22 11:38:17,016 -- BPR fold [6] iter 62: loss = 402.4003, delta_loss = 20.747137, learn_rate = 0.037358373
[DEBUG] 2018-05-22 11:38:17,023 -- BPR fold [5] iter 61: loss = 416.19403, delta_loss = 8.299619, learn_rate = 0.035579402
[DEBUG] 2018-05-22 11:38:17,067 -- BPR fold [9] iter 62: loss = 412.24344, delta_loss = 3.5679471, learn_rate = 0.037358373
[DEBUG] 2018-05-22 11:38:17,075 -- BPR fold [4] iter 61: loss = 419.7583, delta_loss = 4.90013, learn_rate = 0.035579402
[DEBUG] 2018-05-22 11:38:17,099 -- BPR fold [3] iter 62: loss = 407.99838, delta_loss = 9.163475, learn_rate = 0.037358373
[DEBUG] 2018-05-22 11:38:17,147 -- BPR fold [8] iter 62: loss = 400.7733, delta_loss = 11.753179, learn_rate = 0.037358373
[DEBUG] 2018-05-22 11:38:17,105 -- BPR fold [7] iter 63: loss = 391.45114, delta_loss = 13.210181, learn_rate = 0.039226294
[DEBUG] 2018-05-22 11:38:17,235 -- BPR fold [2] iter 62: loss = 406.6001, delta_loss = -0.05004339, learn_rate = 0.037358373
[DEBUG] 2018-05-22 11:38:17,275 -- BPR fold [10] iter 61: loss = 412.85443, delta_loss = 16.620129, learn_rate = 0.035579402
[DEBUG] 2018-05-22 11:38:17,284 -- BPR fold [1] iter 63: loss = 399.6488, delta_loss = -0.106671944, learn_rate = 0.039226294
[DEBUG] 2018-05-22 11:38:17,358 -- BPR fold [6] iter 63: loss = 407.53314, delta_loss = -5.132837, learn_rate = 0.039226294
[DEBUG] 2018-05-22 11:38:17,358 -- BPR fold [9] iter 63: loss = 390.64294, delta_loss = 21.600498, learn_rate = 0.039226294
[DEBUG] 2018-05-22 11:38:17,366 -- BPR fold [5] iter 62: loss = 400.3128, delta_loss = 15.881242, learn_rate = 0.037358373
[DEBUG] 2018-05-22 11:38:17,372 -- BPR fold [4] iter 62: loss = 393.77606, delta_loss = 25.982246, learn_rate = 0.037358373
[DEBUG] 2018-05-22 11:38:17,389 -- BPR fold [3] iter 63: loss = 391.34213, delta_loss = 16.65623, learn_rate = 0.039226294
[DEBUG] 2018-05-22 11:38:17,428 -- BPR fold [7] iter 64: loss = 379.25528, delta_loss = 12.195835, learn_rate = 0.041187607
[DEBUG] 2018-05-22 11:38:17,522 -- BPR fold [8] iter 63: loss = 396.59848, delta_loss = 4.1748013, learn_rate = 0.039226294
[DEBUG] 2018-05-22 11:38:17,535 -- BPR fold [10] iter 62: loss = 397.1987, delta_loss = 15.655737, learn_rate = 0.037358373
[DEBUG] 2018-05-22 11:38:17,537 -- BPR fold [2] iter 63: loss = 392.0708, delta_loss = 14.529297, learn_rate = 0.018679187
[DEBUG] 2018-05-22 11:38:17,612 -- BPR fold [1] iter 64: loss = 388.43796, delta_loss = 11.210862, learn_rate = 0.019613147
[DEBUG] 2018-05-22 11:38:17,682 -- BPR fold [6] iter 64: loss = 390.4206, delta_loss = 17.112534, learn_rate = 0.019613147
[DEBUG] 2018-05-22 11:38:17,688 -- BPR fold [9] iter 64: loss = 382.79425, delta_loss = 7.8486853, learn_rate = 0.041187607
[DEBUG] 2018-05-22 11:38:17,690 -- BPR fold [5] iter 63: loss = 390.65347, delta_loss = 9.659342, learn_rate = 0.039226294
[DEBUG] 2018-05-22 11:38:17,707 -- BPR fold [4] iter 63: loss = 400.36847, delta_loss = -6.592421, learn_rate = 0.039226294
[DEBUG] 2018-05-22 11:38:17,711 -- BPR fold [7] iter 65: loss = 371.5237, delta_loss = 7.731587, learn_rate = 0.04324699
[DEBUG] 2018-05-22 11:38:17,738 -- BPR fold [3] iter 64: loss = 379.3415, delta_loss = 12.000647, learn_rate = 0.041187607
[DEBUG] 2018-05-22 11:38:17,821 -- BPR fold [8] iter 64: loss = 385.98242, delta_loss = 10.616048, learn_rate = 0.041187607
[DEBUG] 2018-05-22 11:38:17,837 -- BPR fold [10] iter 63: loss = 397.8794, delta_loss = -0.68071085, learn_rate = 0.039226294
[DEBUG] 2018-05-22 11:38:17,842 -- BPR fold [2] iter 64: loss = 388.07462, delta_loss = 3.996171, learn_rate = 0.019613147
[DEBUG] 2018-05-22 11:38:17,886 -- BPR fold [1] iter 65: loss = 392.34415, delta_loss = -3.9062111, learn_rate = 0.020593803
[DEBUG] 2018-05-22 11:38:17,928 -- BPR fold [6] iter 65: loss = 377.1339, delta_loss = 13.286668, learn_rate = 0.020593803
[DEBUG] 2018-05-22 11:38:17,948 -- BPR fold [3] iter 65: loss = 374.53702, delta_loss = 4.804467, learn_rate = 0.04324699
[DEBUG] 2018-05-22 11:38:17,948 -- BPR fold [5] iter 64: loss = 379.39145, delta_loss = 11.262024, learn_rate = 0.041187607
[DEBUG] 2018-05-22 11:38:17,949 -- BPR fold [9] iter 65: loss = 374.9911, delta_loss = 7.803172, learn_rate = 0.04324699
[DEBUG] 2018-05-22 11:38:17,973 -- BPR fold [7] iter 66: loss = 366.10522, delta_loss = 5.4184785, learn_rate = 0.045409337
[DEBUG] 2018-05-22 11:38:17,971 -- BPR fold [4] iter 64: loss = 395.1475, delta_loss = 5.2209816, learn_rate = 0.019613147
[DEBUG] 2018-05-22 11:38:18,040 -- BPR fold [8] iter 65: loss = 371.3106, delta_loss = 14.671822, learn_rate = 0.04324699
[DEBUG] 2018-05-22 11:38:18,058 -- BPR fold [2] iter 65: loss = 386.1078, delta_loss = 1.9668267, learn_rate = 0.020593803
[DEBUG] 2018-05-22 11:38:18,067 -- BPR fold [10] iter 64: loss = 389.94415, delta_loss = 7.935247, learn_rate = 0.019613147
[DEBUG] 2018-05-22 11:38:18,177 -- BPR fold [1] iter 66: loss = 379.48502, delta_loss = 12.859134, learn_rate = 0.010296902
[DEBUG] 2018-05-22 11:38:18,182 -- BPR fold [5] iter 65: loss = 372.73724, delta_loss = 6.654202, learn_rate = 0.04324699
[DEBUG] 2018-05-22 11:38:18,202 -- BPR fold [6] iter 66: loss = 376.65607, delta_loss = 0.4778621, learn_rate = 0.021623494
[DEBUG] 2018-05-22 11:38:18,217 -- BPR fold [3] iter 66: loss = 368.7796, delta_loss = 5.757435, learn_rate = 0.045409337
[DEBUG] 2018-05-22 11:38:18,248 -- BPR fold [4] iter 65: loss = 377.08466, delta_loss = 18.062847, learn_rate = 0.020593803
[DEBUG] 2018-05-22 11:38:18,280 -- BPR fold [7] iter 67: loss = 358.95966, delta_loss = 7.145583, learn_rate = 0.047679804
[DEBUG] 2018-05-22 11:38:18,299 -- BPR fold [9] iter 66: loss = 365.19598, delta_loss = 9.795095, learn_rate = 0.045409337
[DEBUG] 2018-05-22 11:38:18,420 -- BPR fold [8] iter 66: loss = 368.99738, delta_loss = 2.313227, learn_rate = 0.045409337
[DEBUG] 2018-05-22 11:38:18,422 -- BPR fold [2] iter 66: loss = 385.77356, delta_loss = 0.33422267, learn_rate = 0.021623494
[DEBUG] 2018-05-22 11:38:18,468 -- BPR fold [10] iter 65: loss = 374.24197, delta_loss = 15.70217, learn_rate = 0.020593803
[DEBUG] 2018-05-22 11:38:18,532 -- BPR fold [1] iter 67: loss = 374.27997, delta_loss = 5.2050653, learn_rate = 0.010811747
[DEBUG] 2018-05-22 11:38:18,551 -- BPR fold [6] iter 67: loss = 371.88492, delta_loss = 4.7711573, learn_rate = 0.022704668
[DEBUG] 2018-05-22 11:38:18,556 -- BPR fold [5] iter 66: loss = 369.25372, delta_loss = 3.4835122, learn_rate = 0.045409337
[DEBUG] 2018-05-22 11:38:18,564 -- BPR fold [3] iter 67: loss = 357.96136, delta_loss = 10.818209, learn_rate = 0.047679804
[DEBUG] 2018-05-22 11:38:18,578 -- BPR fold [4] iter 66: loss = 387.21442, delta_loss = -10.129782, learn_rate = 0.021623494
[DEBUG] 2018-05-22 11:38:18,580 -- BPR fold [9] iter 67: loss = 359.32428, delta_loss = 5.871706, learn_rate = 0.047679804
[DEBUG] 2018-05-22 11:38:18,624 -- BPR fold [7] iter 68: loss = 356.74704, delta_loss = 2.21259, learn_rate = 0.050063793
[DEBUG] 2018-05-22 11:38:18,709 -- BPR fold [10] iter 66: loss = 382.90063, delta_loss = -8.658649, learn_rate = 0.021623494
[DEBUG] 2018-05-22 11:38:18,722 -- BPR fold [8] iter 67: loss = 358.60165, delta_loss = 10.395739, learn_rate = 0.047679804
[DEBUG] 2018-05-22 11:38:18,750 -- BPR fold [2] iter 67: loss = 382.03506, delta_loss = 3.7384963, learn_rate = 0.022704668
[DEBUG] 2018-05-22 11:38:18,755 -- BPR fold [1] iter 68: loss = 374.155, delta_loss = 0.124960594, learn_rate = 0.011352334
[DEBUG] 2018-05-22 11:38:18,781 -- BPR fold [5] iter 67: loss = 357.51892, delta_loss = 11.734815, learn_rate = 0.047679804
[DEBUG] 2018-05-22 11:38:18,805 -- BPR fold [4] iter 67: loss = 378.5224, delta_loss = 8.69203, learn_rate = 0.010811747
[DEBUG] 2018-05-22 11:38:18,817 -- BPR fold [6] iter 68: loss = 371.27875, delta_loss = 0.60615826, learn_rate = 0.023839902
[DEBUG] 2018-05-22 11:38:18,826 -- BPR fold [9] iter 68: loss = 355.35397, delta_loss = 3.9702914, learn_rate = 0.050063793
[DEBUG] 2018-05-22 11:38:18,851 -- BPR fold [3] iter 68: loss = 348.32565, delta_loss = 9.635729, learn_rate = 0.050063793
[DEBUG] 2018-05-22 11:38:18,865 -- BPR fold [7] iter 69: loss = 346.37726, delta_loss = 10.369799, learn_rate = 0.052566983
[DEBUG] 2018-05-22 11:38:18,935 -- BPR fold [8] iter 68: loss = 354.70493, delta_loss = 3.8967237, learn_rate = 0.050063793
[DEBUG] 2018-05-22 11:38:18,941 -- BPR fold [10] iter 67: loss = 376.31195, delta_loss = 6.5886755, learn_rate = 0.010811747
[DEBUG] 2018-05-22 11:38:18,948 -- BPR fold [2] iter 68: loss = 379.7008, delta_loss = 2.3342712, learn_rate = 0.023839902
[DEBUG] 2018-05-22 11:38:18,976 -- BPR fold [9] iter 69: loss = 350.85815, delta_loss = 4.495816, learn_rate = 0.052566983
[DEBUG] 2018-05-22 11:38:19,040 -- BPR fold [1] iter 69: loss = 380.36703, delta_loss = -6.2120366, learn_rate = 0.011919951
[DEBUG] 2018-05-22 11:38:19,056 -- BPR fold [5] iter 68: loss = 349.35754, delta_loss = 8.161351, learn_rate = 0.050063793
[DEBUG] 2018-05-22 11:38:19,059 -- BPR fold [4] iter 68: loss = 368.26578, delta_loss = 10.256609, learn_rate = 0.011352334
[DEBUG] 2018-05-22 11:38:19,061 -- BPR fold [6] iter 69: loss = 368.2226, delta_loss = 3.0561595, learn_rate = 0.025031896
[DEBUG] 2018-05-22 11:38:19,104 -- BPR fold [7] iter 70: loss = 341.60437, delta_loss = 4.772899, learn_rate = 0.05519533
[DEBUG] 2018-05-22 11:38:19,108 -- BPR fold [3] iter 69: loss = 343.72824, delta_loss = 4.5974226, learn_rate = 0.052566983
[DEBUG] 2018-05-22 11:38:19,200 -- BPR fold [8] iter 69: loss = 344.81055, delta_loss = 9.894387, learn_rate = 0.052566983
[DEBUG] 2018-05-22 11:38:19,206 -- BPR fold [2] iter 69: loss = 375.02435, delta_loss = 4.6764636, learn_rate = 0.025031896
[DEBUG] 2018-05-22 11:38:19,227 -- BPR fold [10] iter 68: loss = 371.06754, delta_loss = 5.2444158, learn_rate = 0.011352334
[DEBUG] 2018-05-22 11:38:19,237 -- BPR fold [1] iter 70: loss = 372.06186, delta_loss = 8.3051815, learn_rate = 0.0059599755
[DEBUG] 2018-05-22 11:38:19,250 -- BPR fold [6] iter 70: loss = 364.1899, delta_loss = 4.0326777, learn_rate = 0.026283491
[DEBUG] 2018-05-22 11:38:19,260 -- BPR fold [5] iter 69: loss = 349.3189, delta_loss = 0.038662877, learn_rate = 0.052566983
[DEBUG] 2018-05-22 11:38:19,271 -- BPR fold [9] iter 70: loss = 339.44812, delta_loss = 11.410032, learn_rate = 0.05519533
[DEBUG] 2018-05-22 11:38:19,298 -- BPR fold [4] iter 69: loss = 373.39236, delta_loss = -5.1265674, learn_rate = 0.011919951
[DEBUG] 2018-05-22 11:38:19,318 -- BPR fold [7] iter 71: loss = 331.50946, delta_loss = 10.094898, learn_rate = 0.057955097
[DEBUG] 2018-05-22 11:38:19,326 -- BPR fold [3] iter 70: loss = 339.66458, delta_loss = 4.0636435, learn_rate = 0.05519533
[DEBUG] 2018-05-22 11:38:19,404 -- BPR fold [8] iter 70: loss = 334.96902, delta_loss = 9.841515, learn_rate = 0.05519533
[DEBUG] 2018-05-22 11:38:19,454 -- BPR fold [2] iter 70: loss = 364.09933, delta_loss = 10.925, learn_rate = 0.026283491
[DEBUG] 2018-05-22 11:38:19,470 -- BPR fold [10] iter 69: loss = 378.49347, delta_loss = -7.425922, learn_rate = 0.011919951
[DEBUG] 2018-05-22 11:38:19,499 -- BPR fold [9] iter 71: loss = 337.34567, delta_loss = 2.1024683, learn_rate = 0.057955097
[DEBUG] 2018-05-22 11:38:19,504 -- BPR fold [1] iter 71: loss = 370.19888, delta_loss = 1.8629706, learn_rate = 0.006257974
[DEBUG] 2018-05-22 11:38:19,529 -- BPR fold [6] iter 71: loss = 356.83667, delta_loss = 7.3532324, learn_rate = 0.027597666
[DEBUG] 2018-05-22 11:38:19,533 -- BPR fold [5] iter 70: loss = 339.99222, delta_loss = 9.32667, learn_rate = 0.05519533
[DEBUG] 2018-05-22 11:38:19,543 -- BPR fold [4] iter 70: loss = 364.03232, delta_loss = 9.360035, learn_rate = 0.0059599755
[DEBUG] 2018-05-22 11:38:19,554 -- BPR fold [7] iter 72: loss = 332.83145, delta_loss = -1.3219986, learn_rate = 0.060852855
[DEBUG] 2018-05-22 11:38:19,596 -- BPR fold [3] iter 71: loss = 333.64206, delta_loss = 6.0225153, learn_rate = 0.057955097
[DEBUG] 2018-05-22 11:38:19,672 -- BPR fold [8] iter 71: loss = 333.86002, delta_loss = 1.1090013, learn_rate = 0.057955097
[DEBUG] 2018-05-22 11:38:19,700 -- BPR fold [10] iter 70: loss = 372.61343, delta_loss = 5.8800235, learn_rate = 0.0059599755
[DEBUG] 2018-05-22 11:38:19,711 -- BPR fold [6] iter 72: loss = 347.34494, delta_loss = 9.4917345, learn_rate = 0.028977549
[DEBUG] 2018-05-22 11:38:19,717 -- BPR fold [2] iter 71: loss = 360.62454, delta_loss = 3.4747903, learn_rate = 0.027597666
[DEBUG] 2018-05-22 11:38:19,732 -- BPR fold [9] iter 72: loss = 332.3436, delta_loss = 5.002076, learn_rate = 0.060852855
[DEBUG] 2018-05-22 11:38:19,747 -- BPR fold [1] iter 72: loss = 379.30585, delta_loss = -9.106978, learn_rate = 0.006570873
[DEBUG] 2018-05-22 11:38:19,759 -- BPR fold [5] iter 71: loss = 332.75598, delta_loss = 7.236257, learn_rate = 0.057955097
[DEBUG] 2018-05-22 11:38:19,789 -- BPR fold [4] iter 71: loss = 368.46957, delta_loss = -4.437252, learn_rate = 0.006257974
[DEBUG] 2018-05-22 11:38:19,795 -- BPR fold [7] iter 73: loss = 325.29367, delta_loss = 7.5377874, learn_rate = 0.030426428
[DEBUG] 2018-05-22 11:38:19,831 -- BPR fold [3] iter 72: loss = 330.22116, delta_loss = 3.420922, learn_rate = 0.060852855
[DEBUG] 2018-05-22 11:38:19,891 -- BPR fold [8] iter 72: loss = 329.96048, delta_loss = 3.89954, learn_rate = 0.060852855
[DEBUG] 2018-05-22 11:38:19,914 -- BPR fold [2] iter 72: loss = 357.02124, delta_loss = 3.6033041, learn_rate = 0.028977549
[DEBUG] 2018-05-22 11:38:19,931 -- BPR fold [10] iter 71: loss = 368.25912, delta_loss = 4.3543196, learn_rate = 0.006257974
[DEBUG] 2018-05-22 11:38:19,943 -- BPR fold [9] iter 73: loss = 323.7012, delta_loss = 8.642379, learn_rate = 0.063895494
[DEBUG] 2018-05-22 11:38:19,955 -- BPR fold [6] iter 73: loss = 348.4542, delta_loss = -1.1092526, learn_rate = 0.030426428
[DEBUG] 2018-05-22 11:38:19,977 -- BPR fold [5] iter 72: loss = 332.18484, delta_loss = 0.57111096, learn_rate = 0.060852855
[DEBUG] 2018-05-22 11:38:19,983 -- BPR fold [1] iter 73: loss = 371.14423, delta_loss = 8.161637, learn_rate = 0.0032854364
[DEBUG] 2018-05-22 11:38:19,996 -- BPR fold [4] iter 72: loss = 363.05814, delta_loss = 5.4114246, learn_rate = 0.003128987
[DEBUG] 2018-05-22 11:38:20,015 -- BPR fold [7] iter 74: loss = 321.6848, delta_loss = 3.6088624, learn_rate = 0.031947747
[DEBUG] 2018-05-22 11:38:20,047 -- BPR fold [3] iter 73: loss = 322.96033, delta_loss = 7.260831, learn_rate = 0.063895494
[DEBUG] 2018-05-22 11:38:20,087 -- BPR fold [8] iter 73: loss = 333.07962, delta_loss = -3.1191301, learn_rate = 0.063895494
[DEBUG] 2018-05-22 11:38:20,151 -- BPR fold [2] iter 73: loss = 353.26212, delta_loss = 3.7591202, learn_rate = 0.030426428
[DEBUG] 2018-05-22 11:38:20,163 -- BPR fold [9] iter 74: loss = 324.52515, delta_loss = -0.8239276, learn_rate = 0.06709027
[DEBUG] 2018-05-22 11:38:20,171 -- BPR fold [6] iter 74: loss = 345.74252, delta_loss = 2.7116785, learn_rate = 0.015213214
[DEBUG] 2018-05-22 11:38:20,171 -- BPR fold [10] iter 72: loss = 371.83603, delta_loss = -3.5769036, learn_rate = 0.006570873
[DEBUG] 2018-05-22 11:38:20,176 -- BPR fold [5] iter 73: loss = 323.8053, delta_loss = 8.37956, learn_rate = 0.063895494
[DEBUG] 2018-05-22 11:38:20,186 -- BPR fold [4] iter 73: loss = 367.21613, delta_loss = -4.1579638, learn_rate = 0.0032854364
[DEBUG] 2018-05-22 11:38:20,194 -- BPR fold [1] iter 74: loss = 365.91672, delta_loss = 5.227508, learn_rate = 0.0034497082
[DEBUG] 2018-05-22 11:38:20,237 -- BPR fold [7] iter 75: loss = 323.23508, delta_loss = -1.5502651, learn_rate = 0.033545136
[DEBUG] 2018-05-22 11:38:20,265 -- BPR fold [3] iter 74: loss = 318.33432, delta_loss = 4.6259856, learn_rate = 0.06709027
[DEBUG] 2018-05-22 11:38:20,306 -- BPR fold [8] iter 74: loss = 314.3002, delta_loss = 18.779427, learn_rate = 0.031947747
[DEBUG] 2018-05-22 11:38:20,367 -- BPR fold [2] iter 74: loss = 348.07635, delta_loss = 5.1857824, learn_rate = 0.031947747
[DEBUG] 2018-05-22 11:38:20,391 -- BPR fold [9] iter 75: loss = 319.27905, delta_loss = 5.2460732, learn_rate = 0.033545136
[DEBUG] 2018-05-22 11:38:20,391 -- BPR fold [10] iter 73: loss = 367.98575, delta_loss = 3.8502862, learn_rate = 0.0032854364
[DEBUG] 2018-05-22 11:38:20,391 -- BPR fold [6] iter 75: loss = 345.32565, delta_loss = 0.41687465, learn_rate = 0.015973873
[DEBUG] 2018-05-22 11:38:20,404 -- BPR fold [1] iter 75: loss = 372.35654, delta_loss = -6.439817, learn_rate = 0.0036221936
[DEBUG] 2018-05-22 11:38:20,429 -- BPR fold [5] iter 74: loss = 318.08218, delta_loss = 5.723107, learn_rate = 0.06709027
[DEBUG] 2018-05-22 11:38:20,433 -- BPR fold [4] iter 74: loss = 357.505, delta_loss = 9.711116, learn_rate = 0.0016427182
[DEBUG] 2018-05-22 11:38:20,459 -- BPR fold [7] iter 76: loss = 320.2225, delta_loss = 3.0125575, learn_rate = 0.016772568
[DEBUG] 2018-05-22 11:38:20,490 -- BPR fold [3] iter 75: loss = 311.89365, delta_loss = 6.4406905, learn_rate = 0.070444785
[DEBUG] 2018-05-22 11:38:20,526 -- BPR fold [8] iter 75: loss = 320.00366, delta_loss = -5.703476, learn_rate = 0.033545136
[DEBUG] 2018-05-22 11:38:20,552 -- BPR fold [2] iter 75: loss = 340.1522, delta_loss = 7.9241633, learn_rate = 0.033545136
[DEBUG] 2018-05-22 11:38:20,609 -- BPR fold [10] iter 74: loss = 370.28452, delta_loss = -2.2987635, learn_rate = 0.0034497082
[DEBUG] 2018-05-22 11:38:20,611 -- BPR fold [1] iter 76: loss = 366.8021, delta_loss = 5.5544477, learn_rate = 0.0018110968
[DEBUG] 2018-05-22 11:38:20,614 -- BPR fold [9] iter 76: loss = 312.58456, delta_loss = 6.694491, learn_rate = 0.035222393
[DEBUG] 2018-05-22 11:38:20,616 -- BPR fold [6] iter 76: loss = 346.36508, delta_loss = -1.0394382, learn_rate = 0.016772568
[DEBUG] 2018-05-22 11:38:20,620 -- BPR fold [4] iter 75: loss = 361.9434, delta_loss = -4.438392, learn_rate = 0.0017248541
[DEBUG] 2018-05-22 11:38:20,629 -- BPR fold [5] iter 75: loss = 314.13083, delta_loss = 3.9513621, learn_rate = 0.070444785
[DEBUG] 2018-05-22 11:38:20,675 -- BPR fold [7] iter 77: loss = 313.09906, delta_loss = 7.1234446, learn_rate = 0.017611196
[DEBUG] 2018-05-22 11:38:20,689 -- BPR fold [3] iter 76: loss = 310.55136, delta_loss = 1.3422732, learn_rate = 0.073967025
[DEBUG] 2018-05-22 11:38:20,708 -- BPR fold [8] iter 76: loss = 314.487, delta_loss = 5.516655, learn_rate = 0.016772568
[DEBUG] 2018-05-22 11:38:20,790 -- BPR fold [10] iter 75: loss = 364.01764, delta_loss = 6.2668533, learn_rate = 0.0017248541
[DEBUG] 2018-05-22 11:38:20,790 -- BPR fold [6] iter 77: loss = 339.3304, delta_loss = 7.034683, learn_rate = 0.008386284
[DEBUG] 2018-05-22 11:38:20,793 -- BPR fold [2] iter 76: loss = 349.44525, delta_loss = -9.293062, learn_rate = 0.035222393
[DEBUG] 2018-05-22 11:38:20,800 -- BPR fold [9] iter 77: loss = 313.49014, delta_loss = -0.9055718, learn_rate = 0.036983512
[DEBUG] 2018-05-22 11:38:20,821 -- BPR fold [4] iter 76: loss = 368.52594, delta_loss = -6.5825396, learn_rate = 8.6242706E-4
[DEBUG] 2018-05-22 11:38:20,833 -- BPR fold [1] iter 77: loss = 371.2483, delta_loss = -4.446211, learn_rate = 0.0019016517
[DEBUG] 2018-05-22 11:38:20,840 -- BPR fold [5] iter 76: loss = 312.48215, delta_loss = 1.6486908, learn_rate = 0.073967025
[DEBUG] 2018-05-22 11:38:20,886 -- BPR fold [3] iter 77: loss = 303.15213, delta_loss = 7.399229, learn_rate = 0.07766537
[DEBUG] 2018-05-22 11:38:20,888 -- BPR fold [7] iter 78: loss = 312.85443, delta_loss = 0.24464534, learn_rate = 0.018491756
[DEBUG] 2018-05-22 11:38:20,944 -- BPR fold [8] iter 77: loss = 313.50958, delta_loss = 0.9774306, learn_rate = 0.017611196
[DEBUG] 2018-05-22 11:38:21,005 -- BPR fold [2] iter 77: loss = 339.52063, delta_loss = 9.924611, learn_rate = 0.017611196
[DEBUG] 2018-05-22 11:38:21,021 -- BPR fold [9] iter 78: loss = 312.34573, delta_loss = 1.144398, learn_rate = 0.018491756
[DEBUG] 2018-05-22 11:38:21,023 -- BPR fold [1] iter 78: loss = 363.31717, delta_loss = 7.931123, learn_rate = 9.5082587E-4
[DEBUG] 2018-05-22 11:38:21,035 -- BPR fold [4] iter 77: loss = 362.8839, delta_loss = 5.6420026, learn_rate = 4.3121353E-4
[DEBUG] 2018-05-22 11:38:21,038 -- BPR fold [6] iter 78: loss = 343.19385, delta_loss = -3.8634613, learn_rate = 0.008805598
[DEBUG] 2018-05-22 11:38:21,057 -- BPR fold [5] iter 77: loss = 311.6451, delta_loss = 0.83703756, learn_rate = 0.07766537
[DEBUG] 2018-05-22 11:38:21,061 -- BPR fold [10] iter 76: loss = 367.05185, delta_loss = -3.0341904, learn_rate = 0.0018110968
[DEBUG] 2018-05-22 11:38:21,111 -- BPR fold [7] iter 79: loss = 307.7189, delta_loss = 5.135528, learn_rate = 0.019416343
[DEBUG] 2018-05-22 11:38:21,130 -- BPR fold [3] iter 78: loss = 303.65146, delta_loss = -0.49932152, learn_rate = 0.081548646
[DEBUG] 2018-05-22 11:38:21,145 -- BPR fold [8] iter 78: loss = 316.5251, delta_loss = -3.015506, learn_rate = 0.018491756
[DEBUG] 2018-05-22 11:38:21,221 -- BPR fold [2] iter 78: loss = 333.88803, delta_loss = 5.632607, learn_rate = 0.018491756
[DEBUG] 2018-05-22 11:38:21,228 -- BPR fold [9] iter 79: loss = 307.248, delta_loss = 5.0977697, learn_rate = 0.019416343
[DEBUG] 2018-05-22 11:38:21,244 -- BPR fold [6] iter 79: loss = 336.10693, delta_loss = 7.0869203, learn_rate = 0.004402799
[DEBUG] 2018-05-22 11:38:21,253 -- BPR fold [1] iter 79: loss = 365.08804, delta_loss = -1.7708673, learn_rate = 9.983671E-4
[DEBUG] 2018-05-22 11:38:21,267 -- BPR fold [5] iter 78: loss = 303.80634, delta_loss = 7.838768, learn_rate = 0.081548646
[DEBUG] 2018-05-22 11:38:21,273 -- BPR fold [10] iter 77: loss = 362.25964, delta_loss = 4.7922006, learn_rate = 9.055484E-4
[DEBUG] 2018-05-22 11:38:21,291 -- BPR fold [4] iter 78: loss = 370.4887, delta_loss = -7.60477, learn_rate = 4.527742E-4
[DEBUG] 2018-05-22 11:38:21,325 -- BPR fold [7] iter 80: loss = 312.4604, delta_loss = -4.741483, learn_rate = 0.020387162
[DEBUG] 2018-05-22 11:38:21,350 -- BPR fold [3] iter 79: loss = 297.81287, delta_loss = 5.83859, learn_rate = 0.040774323
[DEBUG] 2018-05-22 11:38:21,359 -- BPR fold [8] iter 79: loss = 310.54785, delta_loss = 5.9772444, learn_rate = 0.009245878
[DEBUG] 2018-05-22 11:38:21,447 -- BPR fold [2] iter 79: loss = 335.07327, delta_loss = -1.1852576, learn_rate = 0.019416343
[DEBUG] 2018-05-22 11:38:21,456 -- BPR fold [9] iter 80: loss = 304.23752, delta_loss = 3.010469, learn_rate = 0.020387162
[DEBUG] 2018-05-22 11:38:21,460 -- BPR fold [6] iter 80: loss = 341.7066, delta_loss = -5.5996666, learn_rate = 0.004622939
[DEBUG] 2018-05-22 11:38:21,466 -- BPR fold [10] iter 78: loss = 366.27994, delta_loss = -4.020299, learn_rate = 9.5082587E-4
[DEBUG] 2018-05-22 11:38:21,474 -- BPR fold [1] iter 80: loss = 364.5377, delta_loss = 0.5503579, learn_rate = 4.9918354E-4
[DEBUG] 2018-05-22 11:38:21,511 -- BPR fold [4] iter 79: loss = 368.34354, delta_loss = 2.1451569, learn_rate = 2.263871E-4
[DEBUG] 2018-05-22 11:38:21,520 -- BPR fold [5] iter 79: loss = 298.48236, delta_loss = 5.323971, learn_rate = 0.08562607
[DEBUG] 2018-05-22 11:38:21,527 -- BPR fold [7] iter 81: loss = 310.31833, delta_loss = 2.1420486, learn_rate = 0.010193581
[DEBUG] 2018-05-22 11:38:21,570 -- BPR fold [8] iter 80: loss = 317.28906, delta_loss = -6.7412157, learn_rate = 0.009708172
[DEBUG] 2018-05-22 11:38:21,587 -- BPR fold [3] iter 80: loss = 296.2603, delta_loss = 1.552568, learn_rate = 0.042813037
[DEBUG] 2018-05-22 11:38:21,653 -- BPR fold [2] iter 80: loss = 333.8585, delta_loss = 1.2147841, learn_rate = 0.009708172
[DEBUG] 2018-05-22 11:38:21,661 -- BPR fold [9] iter 81: loss = 302.72864, delta_loss = 1.5088644, learn_rate = 0.021406518
[DEBUG] 2018-05-22 11:38:21,670 -- BPR fold [4] iter 80: loss = 367.94046, delta_loss = 0.4030868, learn_rate = 2.3770647E-4
[DEBUG] 2018-05-22 11:38:21,672 -- BPR fold [1] iter 81: loss = 366.02582, delta_loss = -1.4881475, learn_rate = 5.2414276E-4
[DEBUG] 2018-05-22 11:38:21,682 -- BPR fold [10] iter 79: loss = 364.70447, delta_loss = 1.5754625, learn_rate = 4.7541293E-4
[DEBUG] 2018-05-22 11:38:21,683 -- BPR fold [6] iter 81: loss = 341.2881, delta_loss = 0.4185095, learn_rate = 0.0023114695
[DEBUG] 2018-05-22 11:38:21,726 -- BPR fold [5] iter 80: loss = 295.88297, delta_loss = 2.599404, learn_rate = 0.08990738
[DEBUG] 2018-05-22 11:38:21,739 -- BPR fold [7] iter 82: loss = 312.61264, delta_loss = -2.2943106, learn_rate = 0.010703259
[DEBUG] 2018-05-22 11:38:21,770 -- BPR fold [3] iter 81: loss = 294.87363, delta_loss = 1.3866843, learn_rate = 0.04495369
[DEBUG] 2018-05-22 11:38:21,821 -- BPR fold [8] iter 81: loss = 312.0797, delta_loss = 5.209349, learn_rate = 0.004854086
[DEBUG] 2018-05-22 11:38:21,905 -- BPR fold [1] iter 82: loss = 373.44345, delta_loss = -7.4176164, learn_rate = 2.6207138E-4
[DEBUG] 2018-05-22 11:38:21,918 -- BPR fold [6] iter 82: loss = 338.90778, delta_loss = 2.3803089, learn_rate = 0.002427043
[DEBUG] 2018-05-22 11:38:21,919 -- BPR fold [2] iter 81: loss = 331.23553, delta_loss = 2.6229594, learn_rate = 0.010193581
[DEBUG] 2018-05-22 11:38:21,932 -- BPR fold [9] iter 82: loss = 309.0109, delta_loss = -6.282244, learn_rate = 0.022476844
[DEBUG] 2018-05-22 11:38:21,949 -- BPR fold [10] iter 80: loss = 359.678, delta_loss = 5.026478, learn_rate = 4.9918354E-4
[DEBUG] 2018-05-22 11:38:21,965 -- BPR fold [7] iter 83: loss = 313.2221, delta_loss = -0.60947794, learn_rate = 0.0053516296
[DEBUG] 2018-05-22 11:38:21,999 -- BPR fold [5] iter 81: loss = 297.24994, delta_loss = -1.3669813, learn_rate = 0.09440275
[DEBUG] 2018-05-22 11:38:22,004 -- BPR fold [4] iter 81: loss = 364.84875, delta_loss = 3.091683, learn_rate = 2.4959177E-4
[DEBUG] 2018-05-22 11:38:22,033 -- BPR fold [3] iter 82: loss = 291.99124, delta_loss = 2.8823798, learn_rate = 0.047201376
[DEBUG] 2018-05-22 11:38:22,050 -- BPR fold [8] iter 82: loss = 313.73117, delta_loss = -1.6514596, learn_rate = 0.0050967904
[DEBUG] 2018-05-22 11:38:22,114 -- BPR fold [2] iter 82: loss = 330.0352, delta_loss = 1.200347, learn_rate = 0.010703259
[DEBUG] 2018-05-22 11:38:22,121 -- BPR fold [1] iter 83: loss = 368.94388, delta_loss = 4.499576, learn_rate = 1.3103569E-4
[DEBUG] 2018-05-22 11:38:22,129 -- BPR fold [9] iter 83: loss = 304.9427, delta_loss = 4.0682025, learn_rate = 0.011238422
[DEBUG] 2018-05-22 11:38:22,142 -- BPR fold [6] iter 83: loss = 334.5623, delta_loss = 4.345507, learn_rate = 0.0025483952
[DEBUG] 2018-05-22 11:38:22,172 -- BPR fold [10] iter 81: loss = 369.8859, delta_loss = -10.207893, learn_rate = 5.2414276E-4
[DEBUG] 2018-05-22 11:38:22,197 -- BPR fold [5] iter 82: loss = 294.23532, delta_loss = 3.0146086, learn_rate = 0.047201376
[DEBUG] 2018-05-22 11:38:22,199 -- BPR fold [4] iter 82: loss = 365.04758, delta_loss = -0.1987974, learn_rate = 2.6207138E-4
[DEBUG] 2018-05-22 11:38:22,202 -- BPR fold [7] iter 84: loss = 315.07205, delta_loss = -1.8499261, learn_rate = 0.0026758148
[DEBUG] 2018-05-22 11:38:22,255 -- BPR fold [8] iter 83: loss = 312.542, delta_loss = 1.1891822, learn_rate = 0.0025483952
[DEBUG] 2018-05-22 11:38:22,266 -- BPR fold [3] iter 83: loss = 291.48813, delta_loss = 0.5031217, learn_rate = 0.049561445
[DEBUG] 2018-05-22 11:38:22,341 -- BPR fold [9] iter 84: loss = 300.32153, delta_loss = 4.6211395, learn_rate = 0.011800344
[DEBUG] 2018-05-22 11:38:22,342 -- BPR fold [2] iter 83: loss = 331.44843, delta_loss = -1.4132386, learn_rate = 0.011238422
[DEBUG] 2018-05-22 11:38:22,350 -- BPR fold [1] iter 84: loss = 359.16318, delta_loss = 9.780685, learn_rate = 1.3758747E-4
[DEBUG] 2018-05-22 11:38:22,357 -- BPR fold [6] iter 84: loss = 336.75128, delta_loss = -2.1890101, learn_rate = 0.0026758148
[DEBUG] 2018-05-22 11:38:22,385 -- BPR fold [7] iter 85: loss = 308.38828, delta_loss = 6.683762, learn_rate = 0.0013379074
[DEBUG] 2018-05-22 11:38:22,399 -- BPR fold [10] iter 82: loss = 367.74884, delta_loss = 2.1370394, learn_rate = 2.6207138E-4
[DEBUG] 2018-05-22 11:38:22,408 -- BPR fold [5] iter 83: loss = 289.4247, delta_loss = 4.810624, learn_rate = 0.049561445
[DEBUG] 2018-05-22 11:38:22,437 -- BPR fold [4] iter 83: loss = 363.26346, delta_loss = 1.7841084, learn_rate = 1.3103569E-4
[DEBUG] 2018-05-22 11:38:22,487 -- BPR fold [3] iter 84: loss = 293.1013, delta_loss = -1.6131586, learn_rate = 0.052039515
[DEBUG] 2018-05-22 11:38:22,488 -- BPR fold [8] iter 84: loss = 310.26364, delta_loss = 2.278334, learn_rate = 0.0026758148
[DEBUG] 2018-05-22 11:38:22,575 -- BPR fold [1] iter 85: loss = 370.94934, delta_loss = -11.786157, learn_rate = 1.4446685E-4
[DEBUG] 2018-05-22 11:38:22,587 -- BPR fold [9] iter 85: loss = 304.55905, delta_loss = -4.2374988, learn_rate = 0.012390361
[DEBUG] 2018-05-22 11:38:22,588 -- BPR fold [2] iter 84: loss = 326.48816, delta_loss = 4.9602523, learn_rate = 0.005619211
[DEBUG] 2018-05-22 11:38:22,589 -- BPR fold [6] iter 85: loss = 332.90784, delta_loss = 3.8434622, learn_rate = 0.0013379074
[DEBUG] 2018-05-22 11:38:22,658 -- BPR fold [10] iter 83: loss = 371.26688, delta_loss = -3.5180361, learn_rate = 2.7517494E-4
[DEBUG] 2018-05-22 11:38:22,676 -- BPR fold [7] iter 86: loss = 307.21207, delta_loss = 1.1762183, learn_rate = 0.0014048028
[DEBUG] 2018-05-22 11:38:22,680 -- BPR fold [5] iter 84: loss = 288.76547, delta_loss = 0.6592434, learn_rate = 0.052039515
[DEBUG] 2018-05-22 11:38:22,693 -- BPR fold [4] iter 84: loss = 363.6626, delta_loss = -0.39912555, learn_rate = 1.3758747E-4
[DEBUG] 2018-05-22 11:38:22,749 -- BPR fold [8] iter 85: loss = 312.9952, delta_loss = -2.731561, learn_rate = 0.0028096056
[DEBUG] 2018-05-22 11:38:22,785 -- BPR fold [3] iter 85: loss = 290.4328, delta_loss = 2.6684728, learn_rate = 0.026019758
[DEBUG] 2018-05-22 11:38:22,867 -- BPR fold [9] iter 86: loss = 304.82483, delta_loss = -0.2657908, learn_rate = 0.0061951806
[DEBUG] 2018-05-22 11:38:22,927 -- BPR fold [6] iter 86: loss = 339.37234, delta_loss = -6.464502, learn_rate = 0.0014048028
[DEBUG] 2018-05-22 11:38:22,928 -- BPR fold [1] iter 86: loss = 368.1378, delta_loss = 2.8115437, learn_rate = 7.223342E-5
[DEBUG] 2018-05-22 11:38:22,945 -- BPR fold [2] iter 85: loss = 330.68948, delta_loss = -4.2013154, learn_rate = 0.005900172
[DEBUG] 2018-05-22 11:38:22,984 -- BPR fold [10] iter 84: loss = 368.23422, delta_loss = 3.0326624, learn_rate = 1.3758747E-4
[DEBUG] 2018-05-22 11:38:22,987 -- BPR fold [5] iter 85: loss = 286.1457, delta_loss = 2.6197593, learn_rate = 0.054641493
[DEBUG] 2018-05-22 11:38:22,988 -- BPR fold [4] iter 85: loss = 365.10284, delta_loss = -1.440255, learn_rate = 6.8793735E-5
[DEBUG] 2018-05-22 11:38:22,990 -- BPR fold [7] iter 87: loss = 309.79358, delta_loss = -2.581501, learn_rate = 0.001475043
[DEBUG] 2018-05-22 11:38:23,043 -- BPR fold [3] iter 86: loss = 288.69815, delta_loss = 1.7346383, learn_rate = 0.027320746
[DEBUG] 2018-05-22 11:38:23,063 -- BPR fold [8] iter 86: loss = 308.4358, delta_loss = 4.559419, learn_rate = 0.0014048028
[DEBUG] 2018-05-22 11:38:23,129 -- BPR fold [9] iter 87: loss = 301.0079, delta_loss = 3.8169346, learn_rate = 0.0030975903
[DEBUG] 2018-05-22 11:38:23,161 -- BPR fold [1] iter 87: loss = 375.65985, delta_loss = -7.522042, learn_rate = 7.584509E-5
[DEBUG] 2018-05-22 11:38:23,175 -- BPR fold [2] iter 86: loss = 330.14594, delta_loss = 0.5435655, learn_rate = 0.002950086
[DEBUG] 2018-05-22 11:38:23,179 -- BPR fold [6] iter 87: loss = 335.82816, delta_loss = 3.5441885, learn_rate = 7.024014E-4
[DEBUG] 2018-05-22 11:38:23,199 -- BPR fold [4] iter 86: loss = 371.73914, delta_loss = -6.636308, learn_rate = 3.4396868E-5
[DEBUG] 2018-05-22 11:38:23,215 -- BPR fold [5] iter 86: loss = 286.61993, delta_loss = -0.4742257, learn_rate = 0.057373565
[DEBUG] 2018-05-22 11:38:23,218 -- BPR fold [7] iter 88: loss = 309.5658, delta_loss = 0.22777757, learn_rate = 7.375215E-4
[DEBUG] 2018-05-22 11:38:23,219 -- BPR fold [10] iter 85: loss = 364.10123, delta_loss = 4.1330028, learn_rate = 1.4446685E-4
[DEBUG] 2018-05-22 11:38:23,261 -- BPR fold [8] iter 87: loss = 309.91446, delta_loss = -1.4786723, learn_rate = 0.001475043
[DEBUG] 2018-05-22 11:38:23,275 -- BPR fold [3] iter 87: loss = 287.53015, delta_loss = 1.1680064, learn_rate = 0.028686782
[DEBUG] 2018-05-22 11:38:23,352 -- BPR fold [9] iter 88: loss = 303.47736, delta_loss = -2.469447, learn_rate = 0.0032524697
[DEBUG] 2018-05-22 11:38:23,373 -- BPR fold [6] iter 88: loss = 343.58798, delta_loss = -7.759834, learn_rate = 7.375215E-4
[DEBUG] 2018-05-22 11:38:23,380 -- BPR fold [1] iter 88: loss = 370.87024, delta_loss = 4.7895937, learn_rate = 3.7922546E-5
[DEBUG] 2018-05-22 11:38:23,381 -- BPR fold [2] iter 87: loss = 330.45773, delta_loss = -0.31180763, learn_rate = 0.0030975903
[DEBUG] 2018-05-22 11:38:23,417 -- BPR fold [5] iter 87: loss = 286.82184, delta_loss = -0.20189758, learn_rate = 0.028686782
[DEBUG] 2018-05-22 11:38:23,418 -- BPR fold [4] iter 87: loss = 363.3831, delta_loss = 8.356045, learn_rate = 1.7198434E-5
[DEBUG] 2018-05-22 11:38:23,430 -- BPR fold [10] iter 86: loss = 367.73456, delta_loss = -3.6333406, learn_rate = 1.5169018E-4
[DEBUG] 2018-05-22 11:38:23,443 -- BPR fold [7] iter 89: loss = 310.00214, delta_loss = -0.4363458, learn_rate = 7.743976E-4
[DEBUG] 2018-05-22 11:38:23,486 -- BPR fold [8] iter 88: loss = 313.16904, delta_loss = -3.2545838, learn_rate = 7.375215E-4
[DEBUG] 2018-05-22 11:38:23,493 -- BPR fold [3] iter 88: loss = 289.15573, delta_loss = -1.6255662, learn_rate = 0.030121122
[DEBUG] 2018-05-22 11:38:23,609 -- BPR fold [9] iter 89: loss = 303.50735, delta_loss = -0.029992709, learn_rate = 0.0016262349
[DEBUG] 2018-05-22 11:38:23,638 -- BPR fold [4] iter 88: loss = 361.79163, delta_loss = 1.5914786, learn_rate = 1.8058356E-5
[DEBUG] 2018-05-22 11:38:23,674 -- BPR fold [2] iter 88: loss = 329.99185, delta_loss = 0.46587577, learn_rate = 0.0015487951
[DEBUG] 2018-05-22 11:38:23,692 -- BPR fold [5] iter 88: loss = 283.11542, delta_loss = 3.7063925, learn_rate = 0.014343391
[DEBUG] 2018-05-22 11:38:23,692 -- BPR fold [6] iter 89: loss = 337.8371, delta_loss = 5.750868, learn_rate = 3.6876075E-4
[DEBUG] 2018-05-22 11:38:23,694 -- BPR fold [1] iter 89: loss = 364.14642, delta_loss = 6.7238197, learn_rate = 3.9818675E-5
[DEBUG] 2018-05-22 11:38:23,723 -- BPR fold [7] iter 90: loss = 309.74695, delta_loss = 0.25517777, learn_rate = 3.871988E-4
[DEBUG] 2018-05-22 11:38:23,739 -- BPR fold [3] iter 89: loss = 284.48563, delta_loss = 4.6701035, learn_rate = 0.015060561
[DEBUG] 2018-05-22 11:38:23,756 -- BPR fold [10] iter 87: loss = 364.7909, delta_loss = 2.94367, learn_rate = 7.584509E-5
[DEBUG] 2018-05-22 11:38:23,793 -- BPR fold [8] iter 89: loss = 314.7506, delta_loss = -1.5815686, learn_rate = 3.6876075E-4
[DEBUG] 2018-05-22 11:38:23,943 -- BPR fold [4] iter 89: loss = 362.02414, delta_loss = -0.23250115, learn_rate = 1.8961273E-5
[DEBUG] 2018-05-22 11:38:23,956 -- BPR fold [9] iter 90: loss = 304.83786, delta_loss = -1.330519, learn_rate = 8.131174E-4
[DEBUG] 2018-05-22 11:38:24,011 -- BPR fold [6] iter 90: loss = 337.97458, delta_loss = -0.1374767, learn_rate = 3.871988E-4
[DEBUG] 2018-05-22 11:38:24,021 -- BPR fold [2] iter 89: loss = 329.9765, delta_loss = 0.015358104, learn_rate = 0.0016262349
[DEBUG] 2018-05-22 11:38:24,022 -- BPR fold [1] iter 90: loss = 363.27188, delta_loss = 0.8745542, learn_rate = 4.1809606E-5
[DEBUG] 2018-05-22 11:38:24,032 -- BPR fold [5] iter 89: loss = 282.43793, delta_loss = 0.67749286, learn_rate = 0.015060561
[DEBUG] 2018-05-22 11:38:24,035 -- BPR fold [10] iter 88: loss = 369.9208, delta_loss = -5.1299214, learn_rate = 7.963735E-5
[DEBUG] 2018-05-22 11:38:24,038 -- BPR fold [7] iter 91: loss = 310.8664, delta_loss = -1.119433, learn_rate = 4.065587E-4
[DEBUG] 2018-05-22 11:38:24,059 -- BPR fold [8] iter 90: loss = 312.35782, delta_loss = 2.3927827, learn_rate = 1.8438038E-4
[DEBUG] 2018-05-22 11:38:24,081 -- BPR fold [3] iter 90: loss = 288.63626, delta_loss = -4.150629, learn_rate = 0.01581359
[DEBUG] 2018-05-22 11:38:24,250 -- BPR fold [9] iter 91: loss = 301.7407, delta_loss = 3.0971813, learn_rate = 4.065587E-4
[DEBUG] 2018-05-22 11:38:24,254 -- BPR fold [4] iter 90: loss = 367.85107, delta_loss = -5.826956, learn_rate = 9.480636E-6
[DEBUG] 2018-05-22 11:38:24,279 -- BPR fold [2] iter 90: loss = 327.74652, delta_loss = 2.2299793, learn_rate = 0.0017075466
[DEBUG] 2018-05-22 11:38:24,294 -- BPR fold [1] iter 91: loss = 366.56226, delta_loss = -3.2903957, learn_rate = 4.3900087E-5
[DEBUG] 2018-05-22 11:38:24,302 -- BPR fold [6] iter 91: loss = 337.20523, delta_loss = 0.7693416, learn_rate = 1.935994E-4
[DEBUG] 2018-05-22 11:38:24,309 -- BPR fold [7] iter 92: loss = 310.23743, delta_loss = 0.62896997, learn_rate = 2.0327936E-4
[DEBUG] 2018-05-22 11:38:24,318 -- BPR fold [10] iter 89: loss = 359.30368, delta_loss = 10.617142, learn_rate = 3.9818675E-5
[DEBUG] 2018-05-22 11:38:24,327 -- BPR fold [5] iter 90: loss = 284.67282, delta_loss = -2.2348807, learn_rate = 0.01581359
[DEBUG] 2018-05-22 11:38:24,332 -- BPR fold [3] iter 91: loss = 286.62433, delta_loss = 2.0119212, learn_rate = 0.007906795
[DEBUG] 2018-05-22 11:38:24,342 -- BPR fold [8] iter 91: loss = 309.05615, delta_loss = 3.3016868, learn_rate = 1.935994E-4
[DEBUG] 2018-05-22 11:38:24,463 -- BPR fold [9] iter 92: loss = 299.9614, delta_loss = 1.7792866, learn_rate = 4.2688666E-4
[DEBUG] 2018-05-22 11:38:24,483 -- BPR fold [4] iter 91: loss = 370.2112, delta_loss = -2.3601418, learn_rate = 4.740318E-6
[DEBUG] 2018-05-22 11:38:24,503 -- BPR fold [2] iter 91: loss = 327.2415, delta_loss = 0.50504535, learn_rate = 0.0017929239
[DEBUG] 2018-05-22 11:38:24,506 -- BPR fold [6] iter 92: loss = 336.2038, delta_loss = 1.0014405, learn_rate = 2.0327936E-4
[DEBUG] 2018-05-22 11:38:24,519 -- BPR fold [8] iter 92: loss = 313.1697, delta_loss = -4.113577, learn_rate = 2.0327936E-4
[DEBUG] 2018-05-22 11:38:24,521 -- BPR fold [5] iter 91: loss = 280.57242, delta_loss = 4.100416, learn_rate = 0.007906795
[DEBUG] 2018-05-22 11:38:24,526 -- BPR fold [10] iter 90: loss = 367.88348, delta_loss = -8.579798, learn_rate = 4.1809606E-5
[DEBUG] 2018-05-22 11:38:24,527 -- BPR fold [7] iter 93: loss = 307.83875, delta_loss = 2.3986719, learn_rate = 2.1344333E-4
[DEBUG] 2018-05-22 11:38:24,527 -- BPR fold [1] iter 92: loss = 360.40744, delta_loss = 6.154833, learn_rate = 2.1950043E-5
[DEBUG] 2018-05-22 11:38:24,585 -- BPR fold [3] iter 92: loss = 285.4766, delta_loss = 1.1477451, learn_rate = 0.008302134
[DEBUG] 2018-05-22 11:38:24,677 -- BPR fold [9] iter 93: loss = 306.03818, delta_loss = -6.076772, learn_rate = 4.4823097E-4
[DEBUG] 2018-05-22 11:38:24,703 -- BPR fold [2] iter 92: loss = 328.82495, delta_loss = -1.583477, learn_rate = 0.0018825701
[DEBUG] 2018-05-22 11:38:24,730 -- BPR fold [4] iter 92: loss = 365.15924, delta_loss = 5.0519695, learn_rate = 2.370159E-6
[DEBUG] 2018-05-22 11:38:24,746 -- BPR fold [1] iter 93: loss = 367.96445, delta_loss = -7.557006, learn_rate = 2.3047547E-5
[DEBUG] 2018-05-22 11:38:24,751 -- BPR fold [6] iter 93: loss = 342.29578, delta_loss = -6.0919785, learn_rate = 2.1344333E-4
[DEBUG] 2018-05-22 11:38:24,752 -- BPR fold [5] iter 92: loss = 282.4719, delta_loss = -1.899487, learn_rate = 0.008302134
[DEBUG] 2018-05-22 11:38:24,755 -- BPR fold [10] iter 91: loss = 360.0295, delta_loss = 7.85396, learn_rate = 2.0904803E-5
[DEBUG] 2018-05-22 11:38:24,765 -- BPR fold [8] iter 93: loss = 309.88345, delta_loss = 3.28628, learn_rate = 1.0163968E-4
[DEBUG] 2018-05-22 11:38:24,767 -- BPR fold [7] iter 94: loss = 314.22882, delta_loss = -6.3900642, learn_rate = 2.2411549E-4
[DEBUG] 2018-05-22 11:38:24,795 -- BPR fold [3] iter 93: loss = 282.88242, delta_loss = 2.5941536, learn_rate = 0.008717241
[DEBUG] 2018-05-22 11:38:24,919 -- BPR fold [9] iter 94: loss = 297.5883, delta_loss = 8.449865, learn_rate = 2.2411549E-4
[DEBUG] 2018-05-22 11:38:24,940 -- BPR fold [7] iter 95: loss = 309.6968, delta_loss = 4.531995, learn_rate = 1.1205774E-4
[DEBUG] 2018-05-22 11:38:24,957 -- BPR fold [2] iter 93: loss = 325.8916, delta_loss = 2.9333353, learn_rate = 9.4128505E-4
[DEBUG] 2018-05-22 11:38:24,966 -- BPR fold [1] iter 94: loss = 370.85233, delta_loss = -2.8878808, learn_rate = 1.15237735E-5
[DEBUG] 2018-05-22 11:38:24,953 -- BPR fold [4] iter 93: loss = 370.5609, delta_loss = -5.4016585, learn_rate = 2.4886672E-6
[DEBUG] 2018-05-22 11:38:24,971 -- BPR fold [6] iter 94: loss = 339.69662, delta_loss = 2.5991688, learn_rate = 1.06721665E-4
[DEBUG] 2018-05-22 11:38:24,986 -- BPR fold [5] iter 93: loss = 284.87073, delta_loss = -2.3988514, learn_rate = 0.004151067
[DEBUG] 2018-05-22 11:38:24,990 -- BPR fold [8] iter 94: loss = 308.1579, delta_loss = 1.7255318, learn_rate = 1.06721665E-4
[DEBUG] 2018-05-22 11:38:25,005 -- BPR fold [3] iter 94: loss = 285.3551, delta_loss = -2.4726763, learn_rate = 0.009153103
[DEBUG] 2018-05-22 11:38:25,009 -- BPR fold [10] iter 92: loss = 364.31427, delta_loss = -4.284747, learn_rate = 2.1950043E-5
[DEBUG] 2018-05-22 11:38:25,134 -- BPR fold [9] iter 95: loss = 304.78946, delta_loss = -7.2011485, learn_rate = 2.3532126E-4
[DEBUG] 2018-05-22 11:38:25,163 -- BPR fold [1] iter 95: loss = 365.86713, delta_loss = 4.985182, learn_rate = 5.7618868E-6
[DEBUG] 2018-05-22 11:38:25,165 -- BPR fold [7] iter 96: loss = 309.2055, delta_loss = 0.4913128, learn_rate = 1.1766063E-4
[DEBUG] 2018-05-22 11:38:25,166 -- BPR fold [2] iter 94: loss = 323.25732, delta_loss = 2.634285, learn_rate = 9.883493E-4
[DEBUG] 2018-05-22 11:38:25,180 -- BPR fold [4] iter 94: loss = 366.1, delta_loss = 4.4609056, learn_rate = 1.2443336E-6
[DEBUG] 2018-05-22 11:38:25,183 -- BPR fold [5] iter 94: loss = 283.64154, delta_loss = 1.2291889, learn_rate = 0.0020755336
[DEBUG] 2018-05-22 11:38:25,184 -- BPR fold [6] iter 95: loss = 340.08856, delta_loss = -0.39194414, learn_rate = 1.1205774E-4
[DEBUG] 2018-05-22 11:38:25,187 -- BPR fold [8] iter 95: loss = 309.50314, delta_loss = -1.3452257, learn_rate = 1.1205774E-4
[DEBUG] 2018-05-22 11:38:25,196 -- BPR fold [10] iter 93: loss = 361.181, delta_loss = 3.1332548, learn_rate = 1.0975022E-5
[DEBUG] 2018-05-22 11:38:25,240 -- BPR fold [3] iter 95: loss = 285.55765, delta_loss = -0.20255113, learn_rate = 0.0045765517
[DEBUG] 2018-05-22 11:38:25,354 -- BPR fold [9] iter 96: loss = 302.89566, delta_loss = 1.8937898, learn_rate = 1.1766063E-4
[DEBUG] 2018-05-22 11:38:25,373 -- BPR fold [2] iter 95: loss = 322.195, delta_loss = 1.0623169, learn_rate = 0.0010377668
[DEBUG] 2018-05-22 11:38:25,381 -- BPR fold [7] iter 97: loss = 308.89276, delta_loss = 0.31275836, learn_rate = 1.2354366E-4
[DEBUG] 2018-05-22 11:38:25,385 -- BPR fold [1] iter 96: loss = 368.84976, delta_loss = -2.9826226, learn_rate = 6.049981E-6
[DEBUG] 2018-05-22 11:38:25,389 -- BPR fold [5] iter 95: loss = 283.2075, delta_loss = 0.43406963, learn_rate = 0.0021793102
[DEBUG] 2018-05-22 11:38:25,394 -- BPR fold [8] iter 96: loss = 308.07904, delta_loss = 1.424094, learn_rate = 5.602887E-5
[DEBUG] 2018-05-22 11:38:25,402 -- BPR fold [6] iter 96: loss = 333.62286, delta_loss = 6.465693, learn_rate = 5.602887E-5
[DEBUG] 2018-05-22 11:38:25,410 -- BPR fold [4] iter 95: loss = 364.8374, delta_loss = 1.2625993, learn_rate = 1.3065502E-6
[DEBUG] 2018-05-22 11:38:25,422 -- BPR fold [10] iter 94: loss = 361.2013, delta_loss = -0.020301033, learn_rate = 1.15237735E-5
[DEBUG] 2018-05-22 11:38:25,436 -- BPR fold [3] iter 96: loss = 285.42834, delta_loss = 0.12930489, learn_rate = 0.0022882759
[DEBUG] 2018-05-22 11:38:25,543 -- BPR fold [9] iter 97: loss = 301.92688, delta_loss = 0.9687915, learn_rate = 1.2354366E-4
[DEBUG] 2018-05-22 11:38:25,584 -- BPR fold [7] iter 98: loss = 312.15808, delta_loss = -3.2653372, learn_rate = 1.2972085E-4
[DEBUG] 2018-05-22 11:38:25,595 -- BPR fold [2] iter 96: loss = 325.4746, delta_loss = -3.2796085, learn_rate = 0.0010896551
[DEBUG] 2018-05-22 11:38:25,606 -- BPR fold [1] iter 97: loss = 368.541, delta_loss = 0.308779, learn_rate = 3.0249905E-6
[DEBUG] 2018-05-22 11:38:25,617 -- BPR fold [5] iter 96: loss = 282.391, delta_loss = 0.81650525, learn_rate = 0.0022882759
[DEBUG] 2018-05-22 11:38:25,622 -- BPR fold [6] iter 97: loss = 333.05374, delta_loss = 0.5691355, learn_rate = 5.8830316E-5
[DEBUG] 2018-05-22 11:38:25,630 -- BPR fold [4] iter 96: loss = 363.8852, delta_loss = 0.9522254, learn_rate = 1.3718777E-6
[DEBUG] 2018-05-22 11:38:25,631 -- BPR fold [8] iter 97: loss = 309.6363, delta_loss = -1.5572406, learn_rate = 5.8830316E-5
[DEBUG] 2018-05-22 11:38:25,641 -- BPR fold [10] iter 95: loss = 368.01486, delta_loss = -6.8135543, learn_rate = 5.7618868E-6
[DEBUG] 2018-05-22 11:38:25,655 -- BPR fold [3] iter 97: loss = 285.70624, delta_loss = -0.27787793, learn_rate = 0.0024026895
[DEBUG] 2018-05-22 11:38:25,762 -- BPR fold [9] iter 98: loss = 301.2108, delta_loss = 0.7160931, learn_rate = 1.2972085E-4
[DEBUG] 2018-05-22 11:38:25,800 -- BPR fold [1] iter 98: loss = 362.59625, delta_loss = 5.944733, learn_rate = 3.17624E-6
[DEBUG] 2018-05-22 11:38:25,802 -- BPR fold [2] iter 97: loss = 331.2099, delta_loss = -5.735267, learn_rate = 5.4482755E-4
[DEBUG] 2018-05-22 11:38:25,813 -- BPR fold [6] iter 98: loss = 334.9003, delta_loss = -1.8465574, learn_rate = 6.177183E-5
[DEBUG] 2018-05-22 11:38:25,818 -- BPR fold [8] iter 98: loss = 310.81573, delta_loss = -1.1794641, learn_rate = 2.9415158E-5
[DEBUG] 2018-05-22 11:38:25,823 -- BPR fold [7] iter 99: loss = 309.878, delta_loss = 2.2801073, learn_rate = 6.4860425E-5
[DEBUG] 2018-05-22 11:38:25,831 -- BPR fold [5] iter 97: loss = 281.13193, delta_loss = 1.2590371, learn_rate = 0.0024026895
[DEBUG] 2018-05-22 11:38:25,836 -- BPR fold [4] iter 97: loss = 370.9258, delta_loss = -7.040623, learn_rate = 1.4404717E-6
[DEBUG] 2018-05-22 11:38:25,850 -- BPR fold [3] iter 98: loss = 284.02878, delta_loss = 1.6774604, learn_rate = 0.0012013448
[DEBUG] 2018-05-22 11:38:25,861 -- BPR fold [10] iter 96: loss = 365.80502, delta_loss = 2.2098408, learn_rate = 2.8809434E-6
[DEBUG] 2018-05-22 11:38:25,962 -- BPR fold [9] iter 99: loss = 299.63428, delta_loss = 1.5765008, learn_rate = 1.3620689E-4
[DEBUG] 2018-05-22 11:38:25,988 -- BPR fold [1] iter 99: loss = 368.57916, delta_loss = -5.9829154, learn_rate = 3.335052E-6
[DEBUG] 2018-05-22 11:38:26,017 -- BPR fold [6] iter 99: loss = 336.50232, delta_loss = -1.60203, learn_rate = 3.0885916E-5
[DEBUG] 2018-05-22 11:38:26,036 -- BPR fold [2] iter 98: loss = 326.79388, delta_loss = 4.415999, learn_rate = 2.7241377E-4
[DEBUG] 2018-05-22 11:38:26,042 -- BPR fold [4] iter 98: loss = 369.53748, delta_loss = 1.3883178, learn_rate = 7.2023585E-7
[DEBUG] 2018-05-22 11:38:26,042 -- BPR fold [7] iter 100: loss = 313.84006, delta_loss = -3.9620762, learn_rate = 6.810344E-5
[DEBUG] 2018-05-22 11:38:26,051 -- BPR fold [10] iter 97: loss = 368.46924, delta_loss = -2.664233, learn_rate = 3.0249905E-6
[DEBUG] 2018-05-22 11:38:26,056 -- BPR fold [8] iter 99: loss = 307.6566, delta_loss = 3.1591551, learn_rate = 1.4707579E-5
[DEBUG] 2018-05-22 11:38:26,063 -- BPR fold [5] iter 98: loss = 282.40585, delta_loss = -1.2739217, learn_rate = 0.002522824
[DEBUG] 2018-05-22 11:38:26,076 -- BPR fold [3] iter 99: loss = 283.9696, delta_loss = 0.05915957, learn_rate = 0.001261412
[DEBUG] 2018-05-22 11:38:26,163 -- BPR fold [9] iter 100: loss = 303.46582, delta_loss = -3.8315418, learn_rate = 1.4301724E-4
[DEBUG] 2018-05-22 11:38:26,195 -- BPR fold [1] iter 100: loss = 364.21503, delta_loss = 4.364123, learn_rate = 1.667526E-6
[DEBUG] 2018-05-22 11:38:26,218 -- BPR fold [2] iter 99: loss = 329.75488, delta_loss = -2.9609957, learn_rate = 2.8603448E-4
[DEBUG] 2018-05-22 11:38:26,239 -- BPR fold [7] iter 101: loss = 308.05835, delta_loss = 5.781713, learn_rate = 3.405172E-5
[DEBUG] 2018-05-22 11:38:26,242 -- BPR fold [6] iter 100: loss = 335.34946, delta_loss = 1.1528625, learn_rate = 1.5442958E-5
[DEBUG] 2018-05-22 11:38:26,242 -- BPR fold [5] iter 99: loss = 279.16797, delta_loss = 3.2378964, learn_rate = 0.001261412
[DEBUG] 2018-05-22 11:38:26,261 -- BPR fold [3] iter 100: loss = 285.68158, delta_loss = -1.7119557, learn_rate = 0.0013244826
[DEBUG] 2018-05-22 11:38:26,273 -- BPR fold [4] iter 99: loss = 368.4807, delta_loss = 1.056772, learn_rate = 7.5624763E-7
[DEBUG] 2018-05-22 11:38:26,279 -- BPR fold [8] iter 100: loss = 308.4505, delta_loss = -0.79389644, learn_rate = 1.5442958E-5
[DEBUG] 2018-05-22 11:38:26,287 -- BPR fold [10] iter 98: loss = 367.82208, delta_loss = 0.6471667, learn_rate = 1.5124953E-6
[DEBUG] 2018-05-22 11:38:26,414 -- BPR fold [9] iter 101: loss = 304.97775, delta_loss = -1.5119337, learn_rate = 7.150862E-5
[DEBUG] 2018-05-22 11:38:26,517 -- BPR fold [1] iter 101: loss = 360.3406, delta_loss = 3.874434, learn_rate = 1.7509022E-6
[DEBUG] 2018-05-22 11:38:26,529 -- BPR fold [4] iter 100: loss = 361.53946, delta_loss = 6.941247, learn_rate = 7.9406E-7
[DEBUG] 2018-05-22 11:38:26,545 -- BPR fold [2] iter 100: loss = 322.3279, delta_loss = 7.4269714, learn_rate = 1.4301724E-4
[DEBUG] 2018-05-22 11:38:26,550 -- BPR fold [7] iter 102: loss = 310.66867, delta_loss = -2.610329, learn_rate = 3.575431E-5
[DEBUG] 2018-05-22 11:38:26,558 -- BPR fold [5] iter 100: loss = 280.85034, delta_loss = -1.6823758, learn_rate = 0.0013244826
[DEBUG] 2018-05-22 11:38:26,562 -- BPR fold [6] iter 101: loss = 333.27252, delta_loss = 2.0769176, learn_rate = 1.6215106E-5
[DEBUG] 2018-05-22 11:38:26,577 -- BPR fold [10] iter 99: loss = 369.40414, delta_loss = -1.5820457, learn_rate = 1.58812E-6
[DEBUG] 2018-05-22 11:38:26,584 -- BPR fold [8] iter 101: loss = 311.85422, delta_loss = -3.4037294, learn_rate = 7.721479E-6
[DEBUG] 2018-05-22 11:38:26,611 -- BPR fold [3] iter 101: loss = 285.885, delta_loss = -0.20343004, learn_rate = 6.622413E-4
[DEBUG] 2018-05-22 11:38:26,712 -- BPR fold [9] iter 102: loss = 301.00687, delta_loss = 3.9708745, learn_rate = 3.575431E-5
[DEBUG] 2018-05-22 11:38:26,793 -- BPR fold [1] iter 102: loss = 367.1127, delta_loss = -6.7720876, learn_rate = 1.8384474E-6
[DEBUG] 2018-05-22 11:38:26,816 -- BPR fold [2] iter 101: loss = 329.98694, delta_loss = -7.659015, learn_rate = 1.501681E-4
[DEBUG] 2018-05-22 11:38:26,827 -- BPR fold [7] iter 103: loss = 305.8316, delta_loss = 4.8370624, learn_rate = 1.7877155E-5
[DEBUG] 2018-05-22 11:38:26,843 -- BPR fold [5] iter 101: loss = 282.39642, delta_loss = -1.5460862, learn_rate = 6.622413E-4
[DEBUG] 2018-05-22 11:38:26,879 -- BPR fold [8] iter 102: loss = 312.811, delta_loss = -0.95679414, learn_rate = 3.8607395E-6
[DEBUG] 2018-05-22 11:38:26,895 -- BPR fold [4] iter 101: loss = 363.1328, delta_loss = -1.5933298, learn_rate = 8.33763E-7
[DEBUG] 2018-05-22 11:38:26,907 -- BPR fold [6] iter 102: loss = 337.19693, delta_loss = -3.924392, learn_rate = 1.702586E-5
[DEBUG] 2018-05-22 11:38:26,925 -- BPR fold [10] iter 100: loss = 368.0078, delta_loss = 1.3963132, learn_rate = 7.9406E-7
[DEBUG] 2018-05-22 11:38:26,949 -- BPR fold [3] iter 102: loss = 285.37973, delta_loss = 0.5052517, learn_rate = 3.3112065E-4
[DEBUG] 2018-05-22 11:38:27,038 -- BPR fold [9] iter 103: loss = 302.41354, delta_loss = -1.4066608, learn_rate = 3.7542024E-5
[DEBUG] 2018-05-22 11:38:27,082 -- BPR fold [2] iter 102: loss = 326.182, delta_loss = 3.8049085, learn_rate = 7.508405E-5
[DEBUG] 2018-05-22 11:38:27,109 -- BPR fold [8] iter 103: loss = 306.98987, delta_loss = 5.8211365, learn_rate = 1.9303698E-6
[DEBUG] 2018-05-22 11:38:27,112 -- BPR fold [1] iter 103: loss = 366.10968, delta_loss = 1.0030102, learn_rate = 9.192237E-7
[DEBUG] 2018-05-22 11:38:27,125 -- BPR fold [5] iter 102: loss = 283.59018, delta_loss = -1.1937428, learn_rate = 3.3112065E-4
[DEBUG] 2018-05-22 11:38:27,143 -- BPR fold [7] iter 104: loss = 309.3584, delta_loss = -3.5267763, learn_rate = 1.8771012E-5
[DEBUG] 2018-05-22 11:38:27,149 -- BPR fold [10] iter 101: loss = 365.79077, delta_loss = 2.2170439, learn_rate = 8.33763E-7
[DEBUG] 2018-05-22 11:38:27,156 -- BPR fold [4] iter 102: loss = 374.20798, delta_loss = -11.075175, learn_rate = 4.168815E-7
[DEBUG] 2018-05-22 11:38:27,164 -- BPR fold [6] iter 103: loss = 345.4723, delta_loss = -8.27535, learn_rate = 8.51293E-6
[DEBUG] 2018-05-22 11:38:27,173 -- BPR fold [3] iter 103: loss = 283.4283, delta_loss = 1.9514389, learn_rate = 3.476767E-4
[DEBUG] 2018-05-22 11:38:27,246 -- BPR fold [9] iter 104: loss = 306.37784, delta_loss = -3.9643118, learn_rate = 1.8771012E-5
[DEBUG] 2018-05-22 11:38:27,326 -- BPR fold [1] iter 104: loss = 359.0095, delta_loss = 7.1002035, learn_rate = 9.651849E-7
[DEBUG] 2018-05-22 11:38:27,336 -- BPR fold [2] iter 103: loss = 323.22833, delta_loss = 2.953693, learn_rate = 7.883825E-5
[DEBUG] 2018-05-22 11:38:27,355 -- BPR fold [7] iter 105: loss = 310.6079, delta_loss = -1.2495172, learn_rate = 9.385506E-6
[DEBUG] 2018-05-22 11:38:27,366 -- BPR fold [4] iter 103: loss = 366.38385, delta_loss = 7.824115, learn_rate = 2.0844075E-7
[DEBUG] 2018-05-22 11:38:27,380 -- BPR fold [5] iter 103: loss = 282.94226, delta_loss = 0.647896, learn_rate = 1.6556033E-4
[DEBUG] 2018-05-22 11:38:27,392 -- BPR fold [8] iter 104: loss = 310.59955, delta_loss = -3.6096725, learn_rate = 2.0268883E-6
[DEBUG] 2018-05-22 11:38:27,393 -- BPR fold [6] iter 104: loss = 337.95172, delta_loss = 7.520564, learn_rate = 4.256465E-6
[DEBUG] 2018-05-22 11:38:27,393 -- BPR fold [10] iter 102: loss = 360.89542, delta_loss = 4.8953524, learn_rate = 8.754511E-7
[DEBUG] 2018-05-22 11:38:27,417 -- BPR fold [3] iter 104: loss = 285.74796, delta_loss = -2.319644, learn_rate = 3.6506052E-4
[DEBUG] 2018-05-22 11:38:27,556 -- BPR fold [9] iter 105: loss = 303.98566, delta_loss = 2.392178, learn_rate = 9.385506E-6
[DEBUG] 2018-05-22 11:38:27,587 -- BPR fold [1] iter 105: loss = 368.7097, delta_loss = -9.700204, learn_rate = 1.0134441E-6
[DEBUG] 2018-05-22 11:38:27,592 -- BPR fold [2] iter 104: loss = 328.83426, delta_loss = -5.60593, learn_rate = 8.278016E-5
[DEBUG] 2018-05-22 11:38:27,609 -- BPR fold [5] iter 104: loss = 283.14188, delta_loss = -0.19961467, learn_rate = 1.7383834E-4
[DEBUG] 2018-05-22 11:38:27,626 -- BPR fold [7] iter 106: loss = 311.9777, delta_loss = -1.3697814, learn_rate = 4.692753E-6
[DEBUG] 2018-05-22 11:38:27,630 -- BPR fold [8] iter 105: loss = 311.73987, delta_loss = -1.1403071, learn_rate = 1.0134441E-6
[DEBUG] 2018-05-22 11:38:27,635 -- BPR fold [6] iter 105: loss = 336.50266, delta_loss = 1.4490491, learn_rate = 4.469289E-6
[DEBUG] 2018-05-22 11:38:27,642 -- BPR fold [4] iter 104: loss = 362.06448, delta_loss = 4.3193593, learn_rate = 2.1886278E-7
[DEBUG] 2018-05-22 11:38:27,646 -- BPR fold [10] iter 103: loss = 367.55582, delta_loss = -6.6603847, learn_rate = 9.192237E-7
[DEBUG] 2018-05-22 11:38:27,663 -- BPR fold [3] iter 105: loss = 287.08115, delta_loss = -1.3332111, learn_rate = 1.8253026E-4
[DEBUG] 2018-05-22 11:38:27,778 -- BPR fold [9] iter 106: loss = 302.20395, delta_loss = 1.781717, learn_rate = 9.854782E-6
[DEBUG] 2018-05-22 11:38:27,812 -- BPR fold [2] iter 105: loss = 323.86285, delta_loss = 4.971395, learn_rate = 4.139008E-5
[DEBUG] 2018-05-22 11:38:27,830 -- BPR fold [1] iter 106: loss = 366.84225, delta_loss = 1.867435, learn_rate = 5.067221E-7
[DEBUG] 2018-05-22 11:38:27,849 -- BPR fold [8] iter 106: loss = 311.97995, delta_loss = -0.24009535, learn_rate = 5.067221E-7
[DEBUG] 2018-05-22 11:38:27,854 -- BPR fold [5] iter 105: loss = 283.46698, delta_loss = -0.3250862, learn_rate = 8.691917E-5
[DEBUG] 2018-05-22 11:38:27,860 -- BPR fold [10] iter 104: loss = 367.3874, delta_loss = 0.16841266, learn_rate = 4.5961184E-7
[DEBUG] 2018-05-22 11:38:27,872 -- BPR fold [3] iter 106: loss = 284.34366, delta_loss = 2.7375054, learn_rate = 9.126513E-5
[DEBUG] 2018-05-22 11:38:27,875 -- BPR fold [4] iter 105: loss = 364.9283, delta_loss = -2.863825, learn_rate = 2.2980592E-7
[DEBUG] 2018-05-22 11:38:27,862 -- BPR fold [6] iter 106: loss = 336.21423, delta_loss = 0.28843635, learn_rate = 4.692753E-6
[DEBUG] 2018-05-22 11:38:27,886 -- BPR fold [7] iter 107: loss = 309.38058, delta_loss = 2.5970988, learn_rate = 2.3463765E-6
[DEBUG] 2018-05-22 11:38:27,983 -- BPR fold [9] iter 107: loss = 306.6141, delta_loss = -4.41015, learn_rate = 1.034752E-5
[DEBUG] 2018-05-22 11:38:28,008 -- BPR fold [1] iter 107: loss = 361.58392, delta_loss = 5.2583284, learn_rate = 5.3205815E-7
[DEBUG] 2018-05-22 11:38:28,024 -- BPR fold [2] iter 106: loss = 329.7049, delta_loss = -5.8420258, learn_rate = 4.3459586E-5
[DEBUG] 2018-05-22 11:38:28,048 -- BPR fold [5] iter 106: loss = 282.83115, delta_loss = 0.6358313, learn_rate = 4.3459586E-5
[DEBUG] 2018-05-22 11:38:28,055 -- BPR fold [8] iter 107: loss = 313.7171, delta_loss = -1.7371489, learn_rate = 2.5336104E-7
[DEBUG] 2018-05-22 11:38:28,061 -- BPR fold [10] iter 105: loss = 362.41754, delta_loss = 4.9698577, learn_rate = 4.8259244E-7
[DEBUG] 2018-05-22 11:38:28,065 -- BPR fold [7] iter 108: loss = 314.71268, delta_loss = -5.332082, learn_rate = 2.4636954E-6
[DEBUG] 2018-05-22 11:38:28,078 -- BPR fold [4] iter 106: loss = 365.38672, delta_loss = -0.45838636, learn_rate = 1.1490296E-7
[DEBUG] 2018-05-22 11:38:28,079 -- BPR fold [6] iter 107: loss = 330.4712, delta_loss = 5.7430444, learn_rate = 4.927391E-6
[DEBUG] 2018-05-22 11:38:28,093 -- BPR fold [3] iter 107: loss = 286.8833, delta_loss = -2.5396504, learn_rate = 9.5828385E-5
[DEBUG] 2018-05-22 11:38:28,220 -- BPR fold [9] iter 108: loss = 300.356, delta_loss = 6.2581124, learn_rate = 5.17376E-6
[DEBUG] 2018-05-22 11:38:28,274 -- BPR fold [2] iter 107: loss = 321.49426, delta_loss = 8.210637, learn_rate = 2.1729793E-5
[DEBUG] 2018-05-22 11:38:28,276 -- BPR fold [1] iter 108: loss = 370.03522, delta_loss = -8.4513035, learn_rate = 5.586611E-7
[DEBUG] 2018-05-22 11:38:28,304 -- BPR fold [8] iter 108: loss = 310.8779, delta_loss = 2.8391964, learn_rate = 1.2668052E-7
[DEBUG] 2018-05-22 11:38:28,339 -- BPR fold [4] iter 107: loss = 365.06274, delta_loss = 0.32396486, learn_rate = 5.745148E-8
[DEBUG] 2018-05-22 11:38:28,342 -- BPR fold [5] iter 107: loss = 282.31442, delta_loss = 0.5167171, learn_rate = 4.5632565E-5
[DEBUG] 2018-05-22 11:38:28,343 -- BPR fold [7] iter 109: loss = 315.6725, delta_loss = -0.95983154, learn_rate = 1.2318477E-6
[DEBUG] 2018-05-22 11:38:28,360 -- BPR fold [3] iter 108: loss = 287.19418, delta_loss = -0.31089094, learn_rate = 4.7914193E-5
[DEBUG] 2018-05-22 11:38:28,363 -- BPR fold [10] iter 106: loss = 369.97665, delta_loss = -7.559128, learn_rate = 5.067221E-7
[DEBUG] 2018-05-22 11:38:28,367 -- BPR fold [6] iter 108: loss = 334.3345, delta_loss = -3.863306, learn_rate = 5.17376E-6
[DEBUG] 2018-05-22 11:38:28,498 -- BPR fold [1] iter 109: loss = 367.68744, delta_loss = 2.3477948, learn_rate = 2.7933055E-7
[DEBUG] 2018-05-22 11:38:28,520 -- BPR fold [9] iter 109: loss = 299.73694, delta_loss = 0.619057, learn_rate = 5.4324482E-6
[DEBUG] 2018-05-22 11:38:28,539 -- BPR fold [2] iter 108: loss = 324.7485, delta_loss = -3.2542443, learn_rate = 2.2816283E-5
[DEBUG] 2018-05-22 11:38:28,587 -- BPR fold [10] iter 107: loss = 366.19388, delta_loss = 3.7827876, learn_rate = 2.5336104E-7
[DEBUG] 2018-05-22 11:38:28,602 -- BPR fold [8] iter 109: loss = 312.83282, delta_loss = -1.9549104, learn_rate = 1.3301454E-7
[DEBUG] 2018-05-22 11:38:28,608 -- BPR fold [3] iter 109: loss = 286.96075, delta_loss = 0.23342843, learn_rate = 2.3957096E-5
[DEBUG] 2018-05-22 11:38:28,635 -- BPR fold [7] iter 110: loss = 309.73132, delta_loss = 5.9411592, learn_rate = 6.1592385E-7
[DEBUG] 2018-05-22 11:38:28,642 -- BPR fold [5] iter 108: loss = 282.56885, delta_loss = -0.2544147, learn_rate = 4.7914193E-5
[DEBUG] 2018-05-22 11:38:28,666 -- BPR fold [6] iter 109: loss = 334.47958, delta_loss = -0.14509195, learn_rate = 2.58688E-6
[DEBUG] 2018-05-22 11:38:28,706 -- BPR fold [4] iter 108: loss = 367.51447, delta_loss = -2.4517145, learn_rate = 6.0324055E-8
[DEBUG] 2018-05-22 11:38:28,837 -- BPR fold [9] iter 110: loss = 303.9788, delta_loss = -4.241856, learn_rate = 5.7040706E-6
[DEBUG] 2018-05-22 11:38:28,849 -- BPR fold [1] iter 110: loss = 364.41568, delta_loss = 3.2717533, learn_rate = 2.9329706E-7
[DEBUG] 2018-05-22 11:38:28,855 -- BPR fold [2] iter 109: loss = 326.65662, delta_loss = -1.908132, learn_rate = 1.1408141E-5
[DEBUG] 2018-05-22 11:38:28,895 -- BPR fold [8] iter 110: loss = 313.83276, delta_loss = -0.99994725, learn_rate = 6.650727E-8
[DEBUG] 2018-05-22 11:38:28,901 -- BPR fold [5] iter 109: loss = 282.79688, delta_loss = -0.22803228, learn_rate = 2.3957096E-5
[DEBUG] 2018-05-22 11:38:28,902 -- BPR fold [3] iter 110: loss = 283.21396, delta_loss = 3.7468219, learn_rate = 2.5154952E-5
[DEBUG] 2018-05-22 11:38:28,913 -- BPR fold [7] iter 111: loss = 307.18265, delta_loss = 2.5486925, learn_rate = 6.4672E-7
[DEBUG] 2018-05-22 11:38:28,914 -- BPR fold [10] iter 108: loss = 366.39993, delta_loss = -0.2060656, learn_rate = 2.6602908E-7
[DEBUG] 2018-05-22 11:38:28,925 -- BPR fold [6] iter 110: loss = 331.83075, delta_loss = 2.6488163, learn_rate = 1.29344E-6
[DEBUG] 2018-05-22 11:38:28,944 -- BPR fold [4] iter 109: loss = 370.22302, delta_loss = -2.7085602, learn_rate = 3.0162028E-8
[DEBUG] 2018-05-22 11:38:29,031 -- BPR fold [9] iter 111: loss = 302.7049, delta_loss = 1.2739065, learn_rate = 2.8520353E-6
[DEBUG] 2018-05-22 11:38:29,050 -- BPR fold [1] iter 111: loss = 361.3909, delta_loss = 3.024791, learn_rate = 3.0796193E-7
[DEBUG] 2018-05-22 11:38:29,054 -- BPR fold [2] iter 110: loss = 327.17004, delta_loss = -0.5134076, learn_rate = 5.7040706E-6
[DEBUG] 2018-05-22 11:38:29,088 -- BPR fold [10] iter 109: loss = 364.84454, delta_loss = 1.5553951, learn_rate = 1.3301454E-7
[DEBUG] 2018-05-22 11:38:29,089 -- BPR fold [8] iter 111: loss = 308.70786, delta_loss = 5.1249027, learn_rate = 3.3253635E-8
[DEBUG] 2018-05-22 11:38:29,103 -- BPR fold [7] iter 112: loss = 310.30148, delta_loss = -3.1188283, learn_rate = 6.7905603E-7
[DEBUG] 2018-05-22 11:38:29,107 -- BPR fold [3] iter 111: loss = 287.5274, delta_loss = -4.3134637, learn_rate = 2.64127E-5
[DEBUG] 2018-05-22 11:38:29,112 -- BPR fold [5] iter 110: loss = 281.21268, delta_loss = 1.5841972, learn_rate = 1.1978548E-5
[DEBUG] 2018-05-22 11:38:29,116 -- BPR fold [6] iter 111: loss = 335.66016, delta_loss = -3.829384, learn_rate = 1.3581121E-6
[DEBUG] 2018-05-22 11:38:29,153 -- BPR fold [4] iter 110: loss = 366.55878, delta_loss = 3.664257, learn_rate = 1.5081014E-8
[DEBUG] 2018-05-22 11:38:29,248 -- BPR fold [9] iter 112: loss = 300.67264, delta_loss = 2.0322309, learn_rate = 2.994637E-6
[DEBUG] 2018-05-22 11:38:29,279 -- BPR fold [2] iter 111: loss = 328.5754, delta_loss = -1.4053631, learn_rate = 2.8520353E-6
[DEBUG] 2018-05-22 11:38:29,314 -- BPR fold [1] iter 112: loss = 375.99326, delta_loss = -14.60238, learn_rate = 3.2336E-7
[DEBUG] 2018-05-22 11:38:29,322 -- BPR fold [7] iter 113: loss = 312.15753, delta_loss = -1.8560636, learn_rate = 3.3952801E-7
[DEBUG] 2018-05-22 11:38:29,337 -- BPR fold [8] iter 112: loss = 312.42252, delta_loss = -3.714648, learn_rate = 3.491632E-8
[DEBUG] 2018-05-22 11:38:29,342 -- BPR fold [5] iter 111: loss = 281.0067, delta_loss = 0.20597124, learn_rate = 1.2577476E-5
[DEBUG] 2018-05-22 11:38:29,353 -- BPR fold [3] iter 112: loss = 285.18314, delta_loss = 2.3442812, learn_rate = 1.320635E-5
[DEBUG] 2018-05-22 11:38:29,356 -- BPR fold [10] iter 110: loss = 359.93164, delta_loss = 4.9129195, learn_rate = 1.3966527E-7
[DEBUG] 2018-05-22 11:38:29,418 -- BPR fold [6] iter 112: loss = 332.72714, delta_loss = 2.9329944, learn_rate = 6.7905603E-7
[DEBUG] 2018-05-22 11:38:29,446 -- BPR fold [4] iter 111: loss = 361.32224, delta_loss = 5.2365417, learn_rate = 1.5835065E-8
[DEBUG] 2018-05-22 11:38:29,494 -- BPR fold [9] iter 113: loss = 303.51758, delta_loss = -2.8449395, learn_rate = 3.144369E-6
[DEBUG] 2018-05-22 11:38:29,545 -- BPR fold [2] iter 112: loss = 327.49854, delta_loss = 1.0768758, learn_rate = 1.4260177E-6
[DEBUG] 2018-05-22 11:38:29,562 -- BPR fold [8] iter 113: loss = 311.00406, delta_loss = 1.418442, learn_rate = 1.745816E-8
[DEBUG] 2018-05-22 11:38:29,586 -- BPR fold [1] iter 113: loss = 363.77332, delta_loss = 12.219945, learn_rate = 1.6168E-7
[DEBUG] 2018-05-22 11:38:29,594 -- BPR fold [5] iter 112: loss = 283.89713, delta_loss = -2.8904266, learn_rate = 1.320635E-5
[DEBUG] 2018-05-22 11:38:29,599 -- BPR fold [7] iter 114: loss = 308.77313, delta_loss = 3.3844037, learn_rate = 1.6976401E-7
[DEBUG] 2018-05-22 11:38:29,604 -- BPR fold [10] iter 111: loss = 366.21155, delta_loss = -6.27993, learn_rate = 1.4664853E-7
[DEBUG] 2018-05-22 11:38:29,620 -- BPR fold [6] iter 113: loss = 340.1096, delta_loss = -7.3824434, learn_rate = 7.1300883E-7
[DEBUG] 2018-05-22 11:38:29,621 -- BPR fold [3] iter 113: loss = 288.02158, delta_loss = -2.8384407, learn_rate = 1.3866667E-5
[DEBUG] 2018-05-22 11:38:29,665 -- BPR fold [4] iter 112: loss = 363.62027, delta_loss = -2.298039, learn_rate = 1.6626817E-8
[DEBUG] 2018-05-22 11:38:29,719 -- BPR fold [9] iter 114: loss = 301.51932, delta_loss = 1.9982812, learn_rate = 1.5721845E-6
[DEBUG] 2018-05-22 11:38:29,770 -- BPR fold [2] iter 113: loss = 323.82983, delta_loss = 3.6686916, learn_rate = 1.4973185E-6
[DEBUG] 2018-05-22 11:38:29,804 -- BPR fold [5] iter 113: loss = 283.26584, delta_loss = 0.6313028, learn_rate = 6.603175E-6
[DEBUG] 2018-05-22 11:38:29,807 -- BPR fold [9] iter 115: loss = 300.40485, delta_loss = 1.114461, learn_rate = 1.6507937E-6
[DEBUG] 2018-05-22 11:38:29,845 -- BPR fold [1] iter 114: loss = 371.6823, delta_loss = -7.908985, learn_rate = 1.6976401E-7
[DEBUG] 2018-05-22 11:38:29,860 -- BPR fold [3] iter 114: loss = 288.97144, delta_loss = -0.9498603, learn_rate = 6.9333337E-6
[DEBUG] 2018-05-22 11:38:29,894 -- BPR fold [7] iter 115: loss = 312.7374, delta_loss = -3.9642718, learn_rate = 1.7825221E-7
[DEBUG] 2018-05-22 11:38:29,896 -- BPR fold [8] iter 114: loss = 311.07074, delta_loss = -0.066687666, learn_rate = 1.8331066E-8
[DEBUG] 2018-05-22 11:38:29,952 -- BPR fold [4] iter 113: loss = 364.15213, delta_loss = -0.53186244, learn_rate = 8.313409E-9
[DEBUG] 2018-05-22 11:38:29,970 -- BPR fold [6] iter 114: loss = 333.22867, delta_loss = 6.880924, learn_rate = 3.5650442E-7
[DEBUG] 2018-05-22 11:38:29,982 -- BPR fold [10] iter 112: loss = 361.7277, delta_loss = 4.483874, learn_rate = 7.3324266E-8
[DEBUG] 2018-05-22 11:38:30,017 -- BPR fold [2] iter 114: loss = 332.58337, delta_loss = -8.753534, learn_rate = 1.5721845E-6
[DEBUG] 2018-05-22 11:38:30,027 -- BPR fold [9] iter 116: loss = 302.26492, delta_loss = -1.8600783, learn_rate = 1.7333334E-6
[DEBUG] 2018-05-22 11:38:30,060 -- BPR fold [5] iter 114: loss = 283.08777, delta_loss = 0.17805782, learn_rate = 6.9333337E-6
[DEBUG] 2018-05-22 11:38:30,076 -- BPR fold [7] iter 116: loss = 307.60175, delta_loss = 5.135658, learn_rate = 8.9126104E-8
[DEBUG] 2018-05-22 11:38:30,082 -- BPR fold [3] iter 115: loss = 280.87454, delta_loss = 8.096902, learn_rate = 3.4666668E-6
[DEBUG] 2018-05-22 11:38:30,090 -- BPR fold [1] iter 115: loss = 368.41663, delta_loss = 3.2656925, learn_rate = 8.4882004E-8
[DEBUG] 2018-05-22 11:38:30,096 -- BPR fold [8] iter 115: loss = 310.40012, delta_loss = 0.67064327, learn_rate = 9.165533E-9
[DEBUG] 2018-05-22 11:38:30,134 -- BPR fold [6] iter 115: loss = 333.84915, delta_loss = -0.62048966, learn_rate = 3.7432963E-7
[DEBUG] 2018-05-22 11:38:30,144 -- BPR fold [4] iter 114: loss = 367.85516, delta_loss = -3.7030392, learn_rate = 4.1567043E-9
[DEBUG] 2018-05-22 11:38:30,190 -- BPR fold [10] iter 113: loss = 366.96304, delta_loss = -5.235351, learn_rate = 7.699048E-8
[DEBUG] 2018-05-22 11:38:30,217 -- BPR fold [2] iter 115: loss = 323.40952, delta_loss = 9.1738615, learn_rate = 7.8609224E-7
[DEBUG] 2018-05-22 11:38:30,251 -- BPR fold [9] iter 117: loss = 302.6751, delta_loss = -0.41018918, learn_rate = 8.666667E-7
[DEBUG] 2018-05-22 11:38:30,273 -- BPR fold [5] iter 115: loss = 279.9829, delta_loss = 3.1048594, learn_rate = 7.2800003E-6
[DEBUG] 2018-05-22 11:38:30,299 -- BPR fold [3] iter 116: loss = 288.6219, delta_loss = -7.747375, learn_rate = 3.6400002E-6
[DEBUG] 2018-05-22 11:38:30,303 -- BPR fold [1] iter 116: loss = 366.30072, delta_loss = 2.1158874, learn_rate = 8.9126104E-8
[DEBUG] 2018-05-22 11:38:30,334 -- BPR fold [7] iter 117: loss = 309.05264, delta_loss = -1.4508874, learn_rate = 9.358241E-8
[DEBUG] 2018-05-22 11:38:30,337 -- BPR fold [8] iter 116: loss = 314.3529, delta_loss = -3.9527862, learn_rate = 9.62381E-9
[DEBUG] 2018-05-22 11:38:30,422 -- BPR fold [4] iter 115: loss = 367.2452, delta_loss = 0.6099587, learn_rate = 2.0783522E-9
[DEBUG] 2018-05-22 11:38:30,434 -- BPR fold [6] iter 116: loss = 340.46082, delta_loss = -6.6116533, learn_rate = 1.8716482E-7
[DEBUG] 2018-05-22 11:38:30,478 -- BPR fold [10] iter 114: loss = 357.3996, delta_loss = 9.563427, learn_rate = 3.849524E-8
[DEBUG] 2018-05-22 11:38:30,493 -- BPR fold [2] iter 116: loss = 324.08597, delta_loss = -0.676465, learn_rate = 8.2539685E-7
[DEBUG] 2018-05-22 11:38:30,522 -- BPR fold [9] iter 118: loss = 302.85544, delta_loss = -0.18031462, learn_rate = 4.3333335E-7
[DEBUG] 2018-05-22 11:38:30,541 -- BPR fold [1] iter 117: loss = 368.5075, delta_loss = -2.2067924, learn_rate = 9.358241E-8
[DEBUG] 2018-05-22 11:38:30,543 -- BPR fold [3] iter 117: loss = 288.3583, delta_loss = 0.26360565, learn_rate = 1.8200001E-6
[DEBUG] 2018-05-22 11:38:30,557 -- BPR fold [5] iter 116: loss = 282.2677, delta_loss = -2.2847745, learn_rate = 7.644E-6
[DEBUG] 2018-05-22 11:38:30,557 -- BPR fold [7] iter 118: loss = 306.14597, delta_loss = 2.906683, learn_rate = 4.6791204E-8
[DEBUG] 2018-05-22 11:38:30,589 -- BPR fold [8] iter 117: loss = 308.0805, delta_loss = 6.27238, learn_rate = 4.811905E-9
[DEBUG] 2018-05-22 11:38:30,630 -- BPR fold [4] iter 116: loss = 362.60565, delta_loss = 4.639542, learn_rate = 2.18227E-9
[DEBUG] 2018-05-22 11:38:30,661 -- BPR fold [6] iter 117: loss = 335.41318, delta_loss = 5.0476403, learn_rate = 9.358241E-8
[DEBUG] 2018-05-22 11:38:30,693 -- BPR fold [10] iter 115: loss = 361.98178, delta_loss = -4.5821657, learn_rate = 4.042E-8
[DEBUG] 2018-05-22 11:38:30,694 -- BPR fold [2] iter 117: loss = 326.2629, delta_loss = -2.1769514, learn_rate = 4.1269843E-7
[DEBUG] 2018-05-22 11:38:30,746 -- BPR fold [9] iter 119: loss = 306.4925, delta_loss = -3.6370516, learn_rate = 2.1666668E-7
[DEBUG] 2018-05-22 11:38:30,760 -- BPR fold [1] iter 118: loss = 366.1871, delta_loss = 2.3204277, learn_rate = 4.6791204E-8
[DEBUG] 2018-05-22 11:38:30,772 -- BPR fold [3] iter 118: loss = 286.8345, delta_loss = 1.5238037, learn_rate = 1.911E-6
[DEBUG] 2018-05-22 11:38:30,775 -- BPR fold [5] iter 117: loss = 279.47308, delta_loss = 2.7946124, learn_rate = 3.822E-6
[DEBUG] 2018-05-22 11:38:30,806 -- BPR fold [7] iter 119: loss = 309.24994, delta_loss = -3.103979, learn_rate = 4.9130765E-8
[DEBUG] 2018-05-22 11:38:30,837 -- BPR fold [8] iter 118: loss = 309.78836, delta_loss = -1.7078364, learn_rate = 5.0525E-9
[DEBUG] 2018-05-22 11:38:30,876 -- BPR fold [4] iter 117: loss = 360.78552, delta_loss = 1.8201419, learn_rate = 2.2913833E-9
[DEBUG] 2018-05-22 11:38:30,881 -- BPR fold [6] iter 118: loss = 336.16815, delta_loss = -0.7549637, learn_rate = 9.826153E-8
[DEBUG] 2018-05-22 11:38:30,928 -- BPR fold [10] iter 116: loss = 370.1561, delta_loss = -8.17432, learn_rate = 2.021E-8
[DEBUG] 2018-05-22 11:38:30,936 -- BPR fold [2] iter 118: loss = 327.4987, delta_loss = -1.2357548, learn_rate = 2.0634921E-7
[DEBUG] 2018-05-22 11:38:30,960 -- BPR fold [9] iter 120: loss = 304.71683, delta_loss = 1.7756642, learn_rate = 1.0833334E-7
[DEBUG] 2018-05-22 11:38:31,015 -- BPR fold [1] iter 119: loss = 364.91635, delta_loss = 1.2707254, learn_rate = 4.9130765E-8
[DEBUG] 2018-05-22 11:38:31,016 -- BPR fold [5] iter 118: loss = 279.72702, delta_loss = -0.25395173, learn_rate = 4.0131E-6
[DEBUG] 2018-05-22 11:38:31,029 -- BPR fold [3] iter 119: loss = 284.5583, delta_loss = 2.2761962, learn_rate = 2.00655E-6
[DEBUG] 2018-05-22 11:38:31,062 -- BPR fold [7] iter 120: loss = 306.9058, delta_loss = 2.3441367, learn_rate = 2.4565383E-8
[DEBUG] 2018-05-22 11:38:31,070 -- BPR fold [8] iter 119: loss = 311.4285, delta_loss = -1.6401519, learn_rate = 2.52625E-9
[DEBUG] 2018-05-22 11:38:31,145 -- BPR fold [4] iter 118: loss = 366.8125, delta_loss = -6.0269856, learn_rate = 2.4059525E-9
[DEBUG] 2018-05-22 11:38:31,177 -- BPR fold [6] iter 119: loss = 338.11798, delta_loss = -1.9498259, learn_rate = 4.9130765E-8
[DEBUG] 2018-05-22 11:38:31,248 -- BPR fold [10] iter 117: loss = 364.97742, delta_loss = 5.1786838, learn_rate = 1.0105E-8
[DEBUG] 2018-05-22 11:38:31,265 -- BPR fold [2] iter 119: loss = 329.1803, delta_loss = -1.6816249, learn_rate = 1.0317461E-7
[DEBUG] 2018-05-22 11:38:31,307 -- BPR fold [9] iter 121: loss = 299.46268, delta_loss = 5.2541265, learn_rate = 1.13750005E-7
[DEBUG] 2018-05-22 11:38:31,330 -- BPR fold [1] iter 120: loss = 363.0728, delta_loss = 1.8435547, learn_rate = 5.1587303E-8
[DEBUG] 2018-05-22 11:38:31,338 -- BPR fold [5] iter 119: loss = 281.5004, delta_loss = -1.7733669, learn_rate = 2.00655E-6
[DEBUG] 2018-05-22 11:38:31,339 -- BPR fold [3] iter 120: loss = 285.12698, delta_loss = -0.5687024, learn_rate = 2.1068774E-6
[DEBUG] 2018-05-22 11:38:31,363 -- BPR fold [7] iter 121: loss = 313.27637, delta_loss = -6.370572, learn_rate = 2.5793652E-8
[DEBUG] 2018-05-22 11:38:31,414 -- BPR fold [4] iter 119: loss = 361.92712, delta_loss = 4.8853865, learn_rate = 1.2029763E-9
[DEBUG] 2018-05-22 11:38:31,419 -- BPR fold [8] iter 120: loss = 311.32928, delta_loss = 0.09920578, learn_rate = 1.263125E-9
[DEBUG] 2018-05-22 11:38:31,441 -- BPR fold [6] iter 120: loss = 338.39825, delta_loss = -0.28029713, learn_rate = 2.4565383E-8
[DEBUG] 2018-05-22 11:38:31,504 -- BPR fold [10] iter 118: loss = 366.80716, delta_loss = -1.8297491, learn_rate = 1.06102505E-8
[DEBUG] 2018-05-22 11:38:31,520 -- BPR fold [2] iter 120: loss = 325.51074, delta_loss = 3.6695547, learn_rate = 5.1587303E-8
[DEBUG] 2018-05-22 11:38:31,536 -- BPR fold [9] iter 122: loss = 302.74338, delta_loss = -3.2806764, learn_rate = 1.194375E-7
[DEBUG] 2018-05-22 11:38:31,568 -- BPR fold [1] iter 121: loss = 360.5381, delta_loss = 2.5347173, learn_rate = 5.416667E-8
[DEBUG] 2018-05-22 11:38:31,596 -- BPR fold [5] iter 120: loss = 283.36343, delta_loss = -1.8630291, learn_rate = 1.003275E-6
[DEBUG] 2018-05-22 11:38:31,601 -- BPR fold [3] iter 121: loss = 288.51678, delta_loss = -3.3897731, learn_rate = 1.0534387E-6
[DEBUG] 2018-05-22 11:38:31,623 -- BPR fold [7] iter 122: loss = 310.56833, delta_loss = 2.7080286, learn_rate = 1.2896826E-8
[DEBUG] 2018-05-22 11:38:31,679 -- BPR fold [8] iter 121: loss = 309.11072, delta_loss = 2.2185686, learn_rate = 1.3262813E-9
[DEBUG] 2018-05-22 11:38:31,681 -- BPR fold [4] iter 120: loss = 367.23196, delta_loss = -5.3048463, learn_rate = 1.263125E-9
[DEBUG] 2018-05-22 11:38:31,692 -- BPR fold [6] iter 121: loss = 337.61334, delta_loss = 0.7849289, learn_rate = 1.2282691E-8
[DEBUG] 2018-05-22 11:38:31,749 -- BPR fold [10] iter 119: loss = 368.3167, delta_loss = -1.5095695, learn_rate = 5.3051252E-9
[DEBUG] 2018-05-22 11:38:31,769 -- BPR fold [2] iter 121: loss = 326.26743, delta_loss = -0.75667983, learn_rate = 5.416667E-8
[DEBUG] 2018-05-22 11:38:31,796 -- BPR fold [1] iter 122: loss = 368.36203, delta_loss = -7.8239217, learn_rate = 5.6875002E-8
[DEBUG] 2018-05-22 11:38:31,805 -- BPR fold [5] iter 121: loss = 283.63452, delta_loss = -0.27108845, learn_rate = 5.016375E-7
[DEBUG] 2018-05-22 11:38:31,809 -- BPR fold [9] iter 123: loss = 303.55133, delta_loss = -0.8079599, learn_rate = 5.971875E-8
[DEBUG] 2018-05-22 11:38:31,816 -- BPR fold [3] iter 122: loss = 283.4491, delta_loss = 5.06769, learn_rate = 5.2671936E-7
[DEBUG] 2018-05-22 11:38:31,836 -- BPR fold [8] iter 122: loss = 308.07294, delta_loss = 1.0377991, learn_rate = 1.3925954E-9
[DEBUG] 2018-05-22 11:38:31,848 -- BPR fold [7] iter 123: loss = 312.1868, delta_loss = -1.6184683, learn_rate = 1.3541667E-8
[DEBUG] 2018-05-22 11:38:31,887 -- BPR fold [6] iter 122: loss = 340.22446, delta_loss = -2.6111286, learn_rate = 1.2896826E-8
[DEBUG] 2018-05-22 11:38:31,894 -- BPR fold [4] iter 121: loss = 366.39142, delta_loss = 0.8405575, learn_rate = 6.315625E-10
[DEBUG] 2018-05-22 11:38:31,960 -- BPR fold [10] iter 120: loss = 362.20462, delta_loss = 6.1121087, learn_rate = 2.6525626E-9
[DEBUG] 2018-05-22 11:38:31,967 -- BPR fold [2] iter 122: loss = 325.7229, delta_loss = 0.5445224, learn_rate = 2.7083335E-8
[DEBUG] 2018-05-22 11:38:31,984 -- BPR fold [1] iter 123: loss = 366.01346, delta_loss = 2.3485656, learn_rate = 2.8437501E-8
[DEBUG] 2018-05-22 11:38:32,011 -- BPR fold [5] iter 122: loss = 280.96802, delta_loss = 2.6664834, learn_rate = 2.5081874E-7
[DEBUG] 2018-05-22 11:38:32,011 -- BPR fold [9] iter 124: loss = 306.37674, delta_loss = -2.8254209, learn_rate = 2.9859375E-8
[DEBUG] 2018-05-22 11:38:32,016 -- BPR fold [3] iter 123: loss = 285.37943, delta_loss = -1.9303374, learn_rate = 5.530554E-7
[DEBUG] 2018-05-22 11:38:32,020 -- BPR fold [7] iter 124: loss = 307.2607, delta_loss = 4.926091, learn_rate = 6.7708337E-9
[DEBUG] 2018-05-22 11:38:32,118 -- BPR fold [4] iter 122: loss = 369.07773, delta_loss = -2.686315, learn_rate = 6.6314065E-10
[DEBUG] 2018-05-22 11:38:32,127 -- BPR fold [8] iter 123: loss = 314.03223, delta_loss = -5.959287, learn_rate = 1.4622251E-9
[DEBUG] 2018-05-22 11:38:32,195 -- BPR fold [6] iter 123: loss = 333.42798, delta_loss = 6.7964926, learn_rate = 6.448413E-9
[DEBUG] 2018-05-22 11:38:32,277 -- BPR fold [10] iter 121: loss = 362.8946, delta_loss = -0.68997264, learn_rate = 2.7851907E-9
[DEBUG] 2018-05-22 11:38:32,278 -- BPR fold [3] iter 124: loss = 284.65646, delta_loss = 0.7229523, learn_rate = 2.765277E-7
[DEBUG] 2018-05-22 11:38:32,279 -- BPR fold [1] iter 124: loss = 366.2114, delta_loss = -0.19795768, learn_rate = 2.9859375E-8
[DEBUG] 2018-05-22 11:38:32,283 -- BPR fold [2] iter 123: loss = 325.34845, delta_loss = 0.37445793, learn_rate = 2.8437501E-8
[DEBUG] 2018-05-22 11:38:32,323 -- BPR fold [9] iter 125: loss = 305.80804, delta_loss = 0.56870383, learn_rate = 1.4929688E-8
[DEBUG] 2018-05-22 11:38:32,347 -- BPR fold [7] iter 125: loss = 312.55057, delta_loss = -5.289842, learn_rate = 7.1093753E-9
[DEBUG] 2018-05-22 11:38:32,360 -- BPR fold [5] iter 123: loss = 283.92447, delta_loss = -2.9564545, learn_rate = 2.6335968E-7
[DEBUG] 2018-05-22 11:38:32,403 -- BPR fold [8] iter 124: loss = 310.01297, delta_loss = 4.019259, learn_rate = 7.3111256E-10
[DEBUG] 2018-05-22 11:38:32,411 -- BPR fold [4] iter 123: loss = 368.17807, delta_loss = 0.8996396, learn_rate = 3.3157033E-10
[DEBUG] 2018-05-22 11:38:32,489 -- BPR fold [6] iter 124: loss = 338.22028, delta_loss = -4.792312, learn_rate = 6.7708337E-9
[DEBUG] 2018-05-22 11:38:32,529 -- BPR fold [2] iter 124: loss = 328.39087, delta_loss = -3.0424356, learn_rate = 2.9859375E-8
[DEBUG] 2018-05-22 11:38:32,545 -- BPR fold [10] iter 122: loss = 361.60208, delta_loss = 1.2925203, learn_rate = 1.3925954E-9
[DEBUG] 2018-05-22 11:38:32,568 -- BPR fold [1] iter 125: loss = 364.2004, delta_loss = 2.0109842, learn_rate = 1.4929688E-8
[DEBUG] 2018-05-22 11:38:32,594 -- BPR fold [9] iter 126: loss = 301.95316, delta_loss = 3.8548875, learn_rate = 1.5676171E-8
[DEBUG] 2018-05-22 11:38:32,612 -- BPR fold [3] iter 125: loss = 285.00015, delta_loss = -0.3436792, learn_rate = 2.9035405E-7
[DEBUG] 2018-05-22 11:38:32,685 -- BPR fold [5] iter 124: loss = 282.75558, delta_loss = 1.1688948, learn_rate = 1.3167984E-7
[DEBUG] 2018-05-22 11:38:32,701 -- BPR fold [7] iter 126: loss = 312.11118, delta_loss = 0.4393727, learn_rate = 3.5546877E-9
[DEBUG] 2018-05-22 11:38:32,740 -- BPR fold [8] iter 125: loss = 309.38657, delta_loss = 0.6263925, learn_rate = 7.676682E-10
[DEBUG] 2018-05-22 11:38:32,745 -- BPR fold [4] iter 124: loss = 368.33246, delta_loss = -0.15436442, learn_rate = 3.4814884E-10
[DEBUG] 2018-05-22 11:38:32,791 -- BPR fold [1] iter 126: loss = 364.4661, delta_loss = -0.2656849, learn_rate = 1.5676171E-8
[DEBUG] 2018-05-22 11:38:32,795 -- BPR fold [6] iter 125: loss = 338.9469, delta_loss = -0.72662944, learn_rate = 3.3854168E-9
[DEBUG] 2018-05-22 11:38:32,824 -- BPR fold [2] iter 125: loss = 323.44046, delta_loss = 4.9504056, learn_rate = 1.4929688E-8
[DEBUG] 2018-05-22 11:38:32,837 -- BPR fold [3] iter 126: loss = 285.751, delta_loss = -0.7508672, learn_rate = 1.4517703E-7
[DEBUG] 2018-05-22 11:38:32,855 -- BPR fold [10] iter 123: loss = 363.77032, delta_loss = -2.1682427, learn_rate = 1.4622251E-9
[DEBUG] 2018-05-22 11:38:32,861 -- BPR fold [9] iter 127: loss = 300.96783, delta_loss = 0.98533183, learn_rate = 1.645998E-8
[DEBUG] 2018-05-22 11:38:32,918 -- BPR fold [5] iter 125: loss = 283.40033, delta_loss = -0.6447545, learn_rate = 1.3826384E-7
[DEBUG] 2018-05-22 11:38:32,943 -- BPR fold [4] iter 125: loss = 368.18652, delta_loss = 0.14591202, learn_rate = 1.7407442E-10
[DEBUG] 2018-05-22 11:38:32,963 -- BPR fold [7] iter 127: loss = 311.06122, delta_loss = 1.0499609, learn_rate = 3.732422E-9
[DEBUG] 2018-05-22 11:38:32,976 -- BPR fold [8] iter 126: loss = 305.55008, delta_loss = 3.836497, learn_rate = 8.060516E-10
[DEBUG] 2018-05-22 11:38:33,023 -- BPR fold [6] iter 126: loss = 335.58005, delta_loss = 3.366878, learn_rate = 1.6927084E-9
[DEBUG] 2018-05-22 11:38:33,046 -- BPR fold [1] iter 127: loss = 359.8775, delta_loss = 4.5886016, learn_rate = 7.838086E-9
[DEBUG] 2018-05-22 11:38:33,051 -- BPR fold [2] iter 126: loss = 329.4371, delta_loss = -5.99664, learn_rate = 1.5676171E-8
[DEBUG] 2018-05-22 11:38:33,083 -- BPR fold [10] iter 124: loss = 362.1043, delta_loss = 1.6659963, learn_rate = 7.3111256E-10
[DEBUG] 2018-05-22 11:38:33,097 -- BPR fold [3] iter 127: loss = 283.32446, delta_loss = 2.4265463, learn_rate = 7.258851E-8
[DEBUG] 2018-05-22 11:38:33,102 -- BPR fold [9] iter 128: loss = 301.9217, delta_loss = -0.95385945, learn_rate = 1.728298E-8
[DEBUG] 2018-05-22 11:38:33,139 -- BPR fold [5] iter 126: loss = 282.2003, delta_loss = 1.20007, learn_rate = 6.913192E-8
[DEBUG] 2018-05-22 11:38:33,150 -- BPR fold [7] iter 128: loss = 315.34872, delta_loss = -4.287508, learn_rate = 3.919043E-9
[DEBUG] 2018-05-22 11:38:33,165 -- BPR fold [4] iter 126: loss = 366.06268, delta_loss = 2.1238427, learn_rate = 1.8277814E-10
[DEBUG] 2018-05-22 11:38:33,193 -- BPR fold [8] iter 127: loss = 311.50363, delta_loss = -5.953568, learn_rate = 8.463542E-10
[DEBUG] 2018-05-22 11:38:33,258 -- BPR fold [2] iter 127: loss = 329.4252, delta_loss = 0.01192556, learn_rate = 7.838086E-9
[DEBUG] 2018-05-22 11:38:33,275 -- BPR fold [6] iter 127: loss = 338.46573, delta_loss = -2.8856883, learn_rate = 1.7773438E-9
[DEBUG] 2018-05-22 11:38:33,263 -- BPR fold [1] iter 128: loss = 361.50095, delta_loss = -1.6234545, learn_rate = 8.22999E-9
[DEBUG] 2018-05-22 11:38:33,290 -- BPR fold [3] iter 128: loss = 282.18112, delta_loss = 1.1433525, learn_rate = 7.6217944E-8
[DEBUG] 2018-05-22 11:38:33,316 -- BPR fold [10] iter 125: loss = 365.23645, delta_loss = -3.132142, learn_rate = 7.676682E-10
[DEBUG] 2018-05-22 11:38:33,324 -- BPR fold [9] iter 129: loss = 305.48282, delta_loss = -3.5611348, learn_rate = 8.64149E-9
[DEBUG] 2018-05-22 11:38:33,357 -- BPR fold [5] iter 127: loss = 281.03973, delta_loss = 1.1605308, learn_rate = 7.258851E-8
[DEBUG] 2018-05-22 11:38:33,369 -- BPR fold [7] iter 129: loss = 308.48, delta_loss = 6.868717, learn_rate = 1.9595214E-9
[DEBUG] 2018-05-22 11:38:33,392 -- BPR fold [4] iter 127: loss = 361.7792, delta_loss = 4.283498, learn_rate = 1.9191705E-10
[DEBUG] 2018-05-22 11:38:33,405 -- BPR fold [8] iter 128: loss = 306.68976, delta_loss = 4.813864, learn_rate = 4.231771E-10
[DEBUG] 2018-05-22 11:38:33,479 -- BPR fold [2] iter 128: loss = 327.98648, delta_loss = 1.4387136, learn_rate = 8.22999E-9
[DEBUG] 2018-05-22 11:38:33,483 -- BPR fold [1] iter 129: loss = 365.895, delta_loss = -4.394025, learn_rate = 4.114995E-9
[DEBUG] 2018-05-22 11:38:33,493 -- BPR fold [6] iter 128: loss = 336.2473, delta_loss = 2.2183926, learn_rate = 8.886719E-10
[DEBUG] 2018-05-22 11:38:33,522 -- BPR fold [10] iter 126: loss = 361.2431, delta_loss = 3.9933403, learn_rate = 3.838341E-10
[DEBUG] 2018-05-22 11:38:33,534 -- BPR fold [3] iter 129: loss = 286.98532, delta_loss = -4.80422, learn_rate = 8.002884E-8
[DEBUG] 2018-05-22 11:38:33,559 -- BPR fold [9] iter 130: loss = 303.25037, delta_loss = 2.232446, learn_rate = 4.320745E-9
[DEBUG] 2018-05-22 11:38:33,564 -- BPR fold [5] iter 128: loss = 282.6883, delta_loss = -1.6485512, learn_rate = 7.6217944E-8
[DEBUG] 2018-05-22 11:38:33,598 -- BPR fold [7] iter 130: loss = 311.27408, delta_loss = -2.794054, learn_rate = 2.0574975E-9
[DEBUG] 2018-05-22 11:38:33,622 -- BPR fold [4] iter 128: loss = 367.69217, delta_loss = -5.912967, learn_rate = 2.015129E-10
[DEBUG] 2018-05-22 11:38:33,664 -- BPR fold [8] iter 129: loss = 310.63528, delta_loss = -3.945504, learn_rate = 4.4433596E-10
[DEBUG] 2018-05-22 11:38:33,696 -- BPR fold [6] iter 129: loss = 336.01422, delta_loss = 0.23311715, learn_rate = 9.331055E-10
[DEBUG] 2018-05-22 11:38:33,696 -- BPR fold [2] iter 129: loss = 328.01675, delta_loss = -0.03027561, learn_rate = 8.64149E-9
[DEBUG] 2018-05-22 11:38:33,716 -- BPR fold [1] iter 130: loss = 364.1313, delta_loss = 1.763706, learn_rate = 2.0574975E-9
[DEBUG] 2018-05-22 11:38:33,749 -- BPR fold [9] iter 131: loss = 304.8653, delta_loss = -1.6149321, learn_rate = 4.536782E-9
[DEBUG] 2018-05-22 11:38:33,755 -- BPR fold [10] iter 127: loss = 371.01743, delta_loss = -9.774321, learn_rate = 4.030258E-10
[DEBUG] 2018-05-22 11:38:33,762 -- BPR fold [3] iter 130: loss = 284.75708, delta_loss = 2.2282526, learn_rate = 4.001442E-8
[DEBUG] 2018-05-22 11:38:33,775 -- BPR fold [5] iter 129: loss = 284.11993, delta_loss = -1.43165, learn_rate = 3.8108972E-8
[DEBUG] 2018-05-22 11:38:33,806 -- BPR fold [4] iter 129: loss = 368.51874, delta_loss = -0.8265822, learn_rate = 1.0075645E-10
[DEBUG] 2018-05-22 11:38:33,832 -- BPR fold [7] iter 131: loss = 311.37228, delta_loss = -0.09820705, learn_rate = 1.0287488E-9
[DEBUG] 2018-05-22 11:38:33,851 -- BPR fold [3] iter 131: loss = 288.27707, delta_loss = -3.5199854, learn_rate = 4.201514E-8
[DEBUG] 2018-05-22 11:38:33,861 -- BPR fold [5] iter 130: loss = 282.92947, delta_loss = 1.1904792, learn_rate = 1.9054486E-8
[DEBUG] 2018-05-22 11:38:33,890 -- BPR fold [4] iter 130: loss = 364.98355, delta_loss = 3.5352063, learn_rate = 5.0378226E-11
[DEBUG] 2018-05-22 11:38:33,894 -- BPR fold [8] iter 130: loss = 310.0861, delta_loss = 0.54917467, learn_rate = 2.2216798E-10
[DEBUG] 2018-05-22 11:38:33,981 -- BPR fold [2] iter 130: loss = 324.02194, delta_loss = 3.9948003, learn_rate = 4.320745E-9
[DEBUG] 2018-05-22 11:38:33,987 -- BPR fold [1] iter 131: loss = 365.31522, delta_loss = -1.1839349, learn_rate = 2.1603725E-9
[DEBUG] 2018-05-22 11:38:33,999 -- BPR fold [3] iter 132: loss = 285.01154, delta_loss = 3.2655406, learn_rate = 2.100757E-8
[DEBUG] 2018-05-22 11:38:34,002 -- BPR fold [9] iter 132: loss = 299.63812, delta_loss = 5.2271776, learn_rate = 2.268391E-9
[DEBUG] 2018-05-22 11:38:34,017 -- BPR fold [5] iter 131: loss = 281.9048, delta_loss = 1.0246634, learn_rate = 2.000721E-8
[DEBUG] 2018-05-22 11:38:34,032 -- BPR fold [6] iter 130: loss = 341.08112, delta_loss = -5.066894, learn_rate = 9.797607E-10
[DEBUG] 2018-05-22 11:38:34,041 -- BPR fold [7] iter 132: loss = 310.16367, delta_loss = 1.2086135, learn_rate = 5.143744E-10
[DEBUG] 2018-05-22 11:38:34,089 -- BPR fold [8] iter 131: loss = 312.99548, delta_loss = -2.909394, learn_rate = 2.3327637E-10
[DEBUG] 2018-05-22 11:38:34,099 -- BPR fold [4] iter 131: loss = 365.07797, delta_loss = -0.09442161, learn_rate = 5.2897138E-11
[DEBUG] 2018-05-22 11:38:34,111 -- BPR fold [10] iter 128: loss = 366.7651, delta_loss = 4.2523236, learn_rate = 2.015129E-10
[DEBUG] 2018-05-22 11:38:34,208 -- BPR fold [9] iter 133: loss = 302.16107, delta_loss = -2.5229535, learn_rate = 2.3818107E-9
[DEBUG] 2018-05-22 11:38:34,215 -- BPR fold [1] iter 132: loss = 365.3446, delta_loss = -0.029394843, learn_rate = 1.0801863E-9
[DEBUG] 2018-05-22 11:38:34,232 -- BPR fold [3] iter 133: loss = 286.5592, delta_loss = -1.5476681, learn_rate = 2.2057948E-8
[DEBUG] 2018-05-22 11:38:34,268 -- BPR fold [2] iter 131: loss = 326.21558, delta_loss = -2.193619, learn_rate = 4.536782E-9
[DEBUG] 2018-05-22 11:38:34,282 -- BPR fold [5] iter 132: loss = 284.64194, delta_loss = -2.7371223, learn_rate = 2.100757E-8
[DEBUG] 2018-05-22 11:38:34,300 -- BPR fold [7] iter 133: loss = 308.709, delta_loss = 1.4546341, learn_rate = 5.4009314E-10
[DEBUG] 2018-05-22 11:38:34,308 -- BPR fold [6] iter 131: loss = 339.65744, delta_loss = 1.4236763, learn_rate = 4.8988036E-10
[DEBUG] 2018-05-22 11:38:34,334 -- BPR fold [4] iter 132: loss = 364.47028, delta_loss = 0.6076946, learn_rate = 2.6448569E-11
[DEBUG] 2018-05-22 11:38:34,405 -- BPR fold [10] iter 129: loss = 368.4383, delta_loss = -1.6731849, learn_rate = 2.1158855E-10
[DEBUG] 2018-05-22 11:38:34,431 -- BPR fold [8] iter 132: loss = 313.05038, delta_loss = -0.054881472, learn_rate = 1.1663819E-10
[DEBUG] 2018-05-22 11:38:34,487 -- BPR fold [3] iter 134: loss = 287.007, delta_loss = -0.44779232, learn_rate = 1.1028974E-8
[DEBUG] 2018-05-22 11:38:34,514 -- BPR fold [1] iter 133: loss = 364.30652, delta_loss = 1.0380828, learn_rate = 5.4009314E-10
[DEBUG] 2018-05-22 11:38:34,539 -- BPR fold [2] iter 132: loss = 328.12866, delta_loss = -1.9130872, learn_rate = 2.268391E-9
[DEBUG] 2018-05-22 11:38:34,549 -- BPR fold [5] iter 133: loss = 280.3233, delta_loss = 4.3186207, learn_rate = 1.0503785E-8
[DEBUG] 2018-05-22 11:38:34,558 -- BPR fold [9] iter 134: loss = 300.93665, delta_loss = 1.2244412, learn_rate = 1.1909054E-9
[DEBUG] 2018-05-22 11:38:34,575 -- BPR fold [6] iter 132: loss = 332.5276, delta_loss = 7.1298323, learn_rate = 5.143744E-10
[DEBUG] 2018-05-22 11:38:34,595 -- BPR fold [4] iter 133: loss = 367.2465, delta_loss = -2.7762234, learn_rate = 2.7770997E-11
[DEBUG] 2018-05-22 11:38:34,607 -- BPR fold [7] iter 134: loss = 309.77853, delta_loss = -1.069493, learn_rate = 5.6709776E-10
[DEBUG] 2018-05-22 11:38:34,630 -- BPR fold [10] iter 130: loss = 360.48053, delta_loss = 7.957779, learn_rate = 1.05794276E-10
[DEBUG] 2018-05-22 11:38:34,702 -- BPR fold [8] iter 133: loss = 306.56656, delta_loss = 6.4838223, learn_rate = 5.831909E-11
[DEBUG] 2018-05-22 11:38:34,800 -- BPR fold [3] iter 135: loss = 287.6785, delta_loss = -0.67151546, learn_rate = 5.514487E-9
[DEBUG] 2018-05-22 11:38:34,817 -- BPR fold [5] iter 134: loss = 280.67352, delta_loss = -0.35021076, learn_rate = 1.1028974E-8
[DEBUG] 2018-05-22 11:38:34,832 -- BPR fold [1] iter 134: loss = 366.5013, delta_loss = -2.194776, learn_rate = 5.6709776E-10
[DEBUG] 2018-05-22 11:38:34,845 -- BPR fold [6] iter 133: loss = 338.81207, delta_loss = -6.2844725, learn_rate = 5.4009314E-10
[DEBUG] 2018-05-22 11:38:34,870 -- BPR fold [9] iter 135: loss = 300.91388, delta_loss = 0.02275705, learn_rate = 1.2504506E-9
[DEBUG] 2018-05-22 11:38:34,877 -- BPR fold [2] iter 133: loss = 332.25827, delta_loss = -4.129628, learn_rate = 1.1341955E-9
[DEBUG] 2018-05-22 11:38:34,884 -- BPR fold [7] iter 135: loss = 311.0764, delta_loss = -1.2978532, learn_rate = 2.8354888E-10
[DEBUG] 2018-05-22 11:38:34,932 -- BPR fold [4] iter 134: loss = 367.87106, delta_loss = -0.6245657, learn_rate = 1.3885499E-11
[DEBUG] 2018-05-22 11:38:35,023 -- BPR fold [8] iter 134: loss = 313.1625, delta_loss = -6.595943, learn_rate = 6.1235045E-11
[DEBUG] 2018-05-22 11:38:35,029 -- BPR fold [10] iter 131: loss = 364.91165, delta_loss = -4.43113, learn_rate = 1.1108399E-10
[DEBUG] 2018-05-22 11:38:35,070 -- BPR fold [5] iter 135: loss = 282.07452, delta_loss = -1.4010187, learn_rate = 5.514487E-9
[DEBUG] 2018-05-22 11:38:35,077 -- BPR fold [1] iter 135: loss = 365.67514, delta_loss = 0.8261635, learn_rate = 2.8354888E-10
[DEBUG] 2018-05-22 11:38:35,080 -- BPR fold [6] iter 134: loss = 337.81683, delta_loss = 0.9952448, learn_rate = 2.7004657E-10
[DEBUG] 2018-05-22 11:38:35,089 -- BPR fold [3] iter 136: loss = 284.06, delta_loss = 3.6185093, learn_rate = 2.7572435E-9
[DEBUG] 2018-05-22 11:38:35,114 -- BPR fold [7] iter 136: loss = 305.6134, delta_loss = 5.462962, learn_rate = 1.4177444E-10
[DEBUG] 2018-05-22 11:38:35,122 -- BPR fold [9] iter 136: loss = 301.46783, delta_loss = -0.55394995, learn_rate = 1.3129732E-9
[DEBUG] 2018-05-22 11:38:35,127 -- BPR fold [2] iter 134: loss = 331.05573, delta_loss = 1.2025697, learn_rate = 5.6709776E-10
[DEBUG] 2018-05-22 11:38:35,196 -- BPR fold [4] iter 135: loss = 366.3802, delta_loss = 1.4908515, learn_rate = 6.9427493E-12
[DEBUG] 2018-05-22 11:38:35,198 -- BPR fold [10] iter 132: loss = 368.65164, delta_loss = -3.7400048, learn_rate = 5.5541995E-11
[DEBUG] 2018-05-22 11:38:35,211 -- BPR fold [8] iter 135: loss = 313.7206, delta_loss = -0.5581235, learn_rate = 3.0617522E-11
[DEBUG] 2018-05-22 11:38:35,290 -- BPR fold [5] iter 136: loss = 280.75287, delta_loss = 1.3216605, learn_rate = 2.7572435E-9
[DEBUG] 2018-05-22 11:38:35,295 -- BPR fold [6] iter 135: loss = 337.32538, delta_loss = 0.49143192, learn_rate = 2.8354888E-10
[DEBUG] 2018-05-22 11:38:35,296 -- BPR fold [3] iter 137: loss = 288.1847, delta_loss = -4.1246877, learn_rate = 2.8951057E-9
[DEBUG] 2018-05-22 11:38:35,304 -- BPR fold [2] iter 135: loss = 327.56012, delta_loss = 3.4955952, learn_rate = 5.954527E-10
[DEBUG] 2018-05-22 11:38:35,318 -- BPR fold [1] iter 136: loss = 368.29648, delta_loss = -2.621345, learn_rate = 2.9772634E-10
[DEBUG] 2018-05-22 11:38:35,342 -- BPR fold [9] iter 137: loss = 302.3723, delta_loss = -0.9044744, learn_rate = 6.564866E-10
[DEBUG] 2018-05-22 11:38:35,362 -- BPR fold [10] iter 133: loss = 365.08478, delta_loss = 3.5668824, learn_rate = 2.7770997E-11
[DEBUG] 2018-05-22 11:38:35,373 -- BPR fold [5] iter 137: loss = 280.73038, delta_loss = 0.02247929, learn_rate = 2.8951057E-9
[DEBUG] 2018-05-22 11:38:35,436 -- BPR fold [7] iter 137: loss = 311.79727, delta_loss = -6.183866, learn_rate = 1.4886317E-10
[DEBUG] 2018-05-22 11:38:35,440 -- BPR fold [4] iter 136: loss = 361.20767, delta_loss = 5.1725283, learn_rate = 7.289887E-12
[DEBUG] 2018-05-22 11:38:35,461 -- BPR fold [3] iter 138: loss = 289.33557, delta_loss = -1.1509026, learn_rate = 1.4475529E-9
[DEBUG] 2018-05-22 11:38:35,464 -- BPR fold [2] iter 136: loss = 323.7066, delta_loss = 3.8535185, learn_rate = 6.252253E-10
[DEBUG] 2018-05-22 11:38:35,521 -- BPR fold [6] iter 136: loss = 336.24945, delta_loss = 1.0759317, learn_rate = 2.9772634E-10
[DEBUG] 2018-05-22 11:38:35,527 -- BPR fold [5] iter 138: loss = 280.40497, delta_loss = 0.32541394, learn_rate = 3.039861E-9
[DEBUG] 2018-05-22 11:38:35,541 -- BPR fold [1] iter 137: loss = 366.2972, delta_loss = 1.9992808, learn_rate = 1.4886317E-10
[DEBUG] 2018-05-22 11:38:35,547 -- BPR fold [8] iter 136: loss = 314.16476, delta_loss = -0.4441326, learn_rate = 1.5308761E-11
[DEBUG] 2018-05-22 11:38:35,600 -- BPR fold [9] iter 138: loss = 306.14572, delta_loss = -3.77342, learn_rate = 3.282433E-10
[DEBUG] 2018-05-22 11:38:35,612 -- BPR fold [10] iter 134: loss = 365.81323, delta_loss = -0.7284514, learn_rate = 2.9159546E-11
[DEBUG] 2018-05-22 11:38:35,639 -- BPR fold [4] iter 137: loss = 362.102, delta_loss = -0.8943051, learn_rate = 7.654381E-12
[DEBUG] 2018-05-22 11:38:35,679 -- BPR fold [7] iter 138: loss = 306.48593, delta_loss = 5.3113484, learn_rate = 7.4431586E-11
[DEBUG] 2018-05-22 11:38:35,692 -- BPR fold [3] iter 139: loss = 286.75415, delta_loss = 2.5814202, learn_rate = 7.237764E-10
[DEBUG] 2018-05-22 11:38:35,699 -- BPR fold [2] iter 137: loss = 327.30597, delta_loss = -3.599375, learn_rate = 6.564866E-10
[DEBUG] 2018-05-22 11:38:35,731 -- BPR fold [6] iter 137: loss = 336.6131, delta_loss = -0.3636249, learn_rate = 3.1261266E-10
[DEBUG] 2018-05-22 11:38:35,750 -- BPR fold [5] iter 139: loss = 281.00534, delta_loss = -0.60037076, learn_rate = 3.1918541E-9
[DEBUG] 2018-05-22 11:38:35,777 -- BPR fold [8] iter 137: loss = 310.67575, delta_loss = 3.4890144, learn_rate = 7.654381E-12
[DEBUG] 2018-05-22 11:38:35,779 -- BPR fold [1] iter 138: loss = 368.1626, delta_loss = -1.8654037, learn_rate = 1.5630633E-10
[DEBUG] 2018-05-22 11:38:35,842 -- BPR fold [9] iter 139: loss = 298.76266, delta_loss = 7.3830624, learn_rate = 1.6412165E-10
[DEBUG] 2018-05-22 11:38:35,862 -- BPR fold [10] iter 135: loss = 371.4906, delta_loss = -5.6773753, learn_rate = 1.4579773E-11
[DEBUG] 2018-05-22 11:38:35,903 -- BPR fold [4] iter 138: loss = 365.12155, delta_loss = -3.019586, learn_rate = 3.8271903E-12
[DEBUG] 2018-05-22 11:38:35,934 -- BPR fold [3] iter 140: loss = 287.68796, delta_loss = -0.9337892, learn_rate = 7.5996526E-10
[DEBUG] 2018-05-22 11:38:35,978 -- BPR fold [7] iter 139: loss = 309.3945, delta_loss = -2.9085667, learn_rate = 7.8153164E-11
[DEBUG] 2018-05-22 11:38:35,998 -- BPR fold [6] iter 138: loss = 336.93396, delta_loss = -0.32085896, learn_rate = 1.5630633E-10
[DEBUG] 2018-05-22 11:38:36,001 -- BPR fold [2] iter 138: loss = 321.62335, delta_loss = 5.6826353, learn_rate = 3.282433E-10
[DEBUG] 2018-05-22 11:38:36,069 -- BPR fold [5] iter 140: loss = 280.31003, delta_loss = 0.6953238, learn_rate = 1.5959271E-9
[DEBUG] 2018-05-22 11:38:36,082 -- BPR fold [8] iter 138: loss = 311.51254, delta_loss = -0.83680075, learn_rate = 8.0371E-12
[DEBUG] 2018-05-22 11:38:36,112 -- BPR fold [1] iter 139: loss = 361.62387, delta_loss = 6.5387244, learn_rate = 7.8153164E-11
[DEBUG] 2018-05-22 11:38:36,115 -- BPR fold [9] iter 140: loss = 303.79303, delta_loss = -5.0303574, learn_rate = 1.7232772E-10
[DEBUG] 2018-05-22 11:38:36,183 -- BPR fold [4] iter 139: loss = 366.44772, delta_loss = -1.3261545, learn_rate = 1.9135952E-12
[DEBUG] 2018-05-22 11:38:36,206 -- BPR fold [10] iter 136: loss = 362.58295, delta_loss = 8.907658, learn_rate = 7.289887E-12
[DEBUG] 2018-05-22 11:38:36,213 -- BPR fold [3] iter 141: loss = 285.13617, delta_loss = 2.5517907, learn_rate = 3.7998263E-10
[DEBUG] 2018-05-22 11:38:36,273 -- BPR fold [7] iter 140: loss = 312.09006, delta_loss = -2.6955507, learn_rate = 3.9076582E-11
[DEBUG] 2018-05-22 11:38:36,279 -- BPR fold [2] iter 139: loss = 324.83572, delta_loss = -3.2123787, learn_rate = 3.4465544E-10
[DEBUG] 2018-05-22 11:38:36,297 -- BPR fold [6] iter 139: loss = 337.64413, delta_loss = -0.71018255, learn_rate = 7.8153164E-11
[DEBUG] 2018-05-22 11:38:36,313 -- BPR fold [5] iter 141: loss = 280.76828, delta_loss = -0.45826995, learn_rate = 1.6757234E-9
[DEBUG] 2018-05-22 11:38:36,323 -- BPR fold [8] iter 139: loss = 313.16388, delta_loss = -1.6513375, learn_rate = 4.01855E-12
[DEBUG] 2018-05-22 11:38:36,335 -- BPR fold [9] iter 141: loss = 299.9286, delta_loss = 3.8644407, learn_rate = 8.616386E-11
[DEBUG] 2018-05-22 11:38:36,347 -- BPR fold [1] iter 140: loss = 368.78522, delta_loss = -7.161329, learn_rate = 8.206082E-11
[DEBUG] 2018-05-22 11:38:36,394 -- BPR fold [10] iter 137: loss = 364.92105, delta_loss = -2.3381217, learn_rate = 7.654381E-12
[DEBUG] 2018-05-22 11:38:36,420 -- BPR fold [4] iter 140: loss = 367.2509, delta_loss = -0.8031795, learn_rate = 9.567976E-13
[DEBUG] 2018-05-22 11:38:36,470 -- BPR fold [7] iter 141: loss = 313.9769, delta_loss = -1.8868665, learn_rate = 1.9538291E-11
[DEBUG] 2018-05-22 11:38:36,471 -- BPR fold [3] iter 142: loss = 287.01474, delta_loss = -1.8785832, learn_rate = 3.9898176E-10
[DEBUG] 2018-05-22 11:38:36,483 -- BPR fold [2] iter 140: loss = 322.92288, delta_loss = 1.912825, learn_rate = 1.7232772E-10
[DEBUG] 2018-05-22 11:38:36,501 -- BPR fold [6] iter 140: loss = 336.03665, delta_loss = 1.6074637, learn_rate = 3.9076582E-11
[DEBUG] 2018-05-22 11:38:36,515 -- BPR fold [5] iter 142: loss = 282.34088, delta_loss = -1.5725994, learn_rate = 8.378617E-10
[DEBUG] 2018-05-22 11:38:36,546 -- BPR fold [8] iter 140: loss = 314.12546, delta_loss = -0.961568, learn_rate = 2.009275E-12
[DEBUG] 2018-05-22 11:38:36,575 -- BPR fold [1] iter 141: loss = 361.32156, delta_loss = 7.4636455, learn_rate = 4.103041E-11
[DEBUG] 2018-05-22 11:38:36,588 -- BPR fold [9] iter 142: loss = 300.0315, delta_loss = -0.10290001, learn_rate = 9.047205E-11
[DEBUG] 2018-05-22 11:38:36,639 -- BPR fold [4] iter 141: loss = 368.97168, delta_loss = -1.720775, learn_rate = 4.783988E-13
[DEBUG] 2018-05-22 11:38:36,643 -- BPR fold [10] iter 138: loss = 362.4511, delta_loss = 2.4699562, learn_rate = 3.8271903E-12
[DEBUG] 2018-05-22 11:38:36,654 -- BPR fold [3] iter 143: loss = 287.8502, delta_loss = -0.83543164, learn_rate = 1.9949088E-10
[DEBUG] 2018-05-22 11:38:36,670 -- BPR fold [2] iter 141: loss = 324.2609, delta_loss = -1.3379949, learn_rate = 1.809441E-10
[DEBUG] 2018-05-22 11:38:36,693 -- BPR fold [6] iter 141: loss = 332.18384, delta_loss = 3.852826, learn_rate = 4.103041E-11
[DEBUG] 2018-05-22 11:38:36,700 -- BPR fold [7] iter 142: loss = 308.56247, delta_loss = 5.4144454, learn_rate = 9.7691456E-12
[DEBUG] 2018-05-22 11:38:36,731 -- BPR fold [8] iter 141: loss = 309.92026, delta_loss = 4.2051797, learn_rate = 1.0046375E-12
[DEBUG] 2018-05-22 11:38:36,743 -- BPR fold [5] iter 143: loss = 282.46353, delta_loss = -0.12264245, learn_rate = 4.1893086E-10
[DEBUG] 2018-05-22 11:38:36,813 -- BPR fold [9] iter 143: loss = 300.85776, delta_loss = -0.8262879, learn_rate = 4.5236027E-11
[DEBUG] 2018-05-22 11:38:36,823 -- BPR fold [1] iter 142: loss = 366.333, delta_loss = -5.011427, learn_rate = 4.308193E-11
[DEBUG] 2018-05-22 11:38:36,908 -- BPR fold [10] iter 139: loss = 364.6228, delta_loss = -2.1717083, learn_rate = 4.01855E-12
[DEBUG] 2018-05-22 11:38:36,929 -- BPR fold [4] iter 142: loss = 367.91623, delta_loss = 1.055435, learn_rate = 2.391994E-13
[DEBUG] 2018-05-22 11:38:36,961 -- BPR fold [3] iter 144: loss = 286.0804, delta_loss = 1.7697709, learn_rate = 9.974544E-11
[DEBUG] 2018-05-22 11:38:36,963 -- BPR fold [2] iter 142: loss = 327.5192, delta_loss = -3.258315, learn_rate = 9.047205E-11
[DEBUG] 2018-05-22 11:38:36,964 -- BPR fold [7] iter 143: loss = 309.39584, delta_loss = -0.8333905, learn_rate = 1.0257603E-11
[DEBUG] 2018-05-22 11:38:37,008 -- BPR fold [6] iter 142: loss = 337.49435, delta_loss = -5.310516, learn_rate = 4.308193E-11
[DEBUG] 2018-05-22 11:38:37,041 -- BPR fold [5] iter 144: loss = 282.2829, delta_loss = 0.18064566, learn_rate = 2.0946543E-10
[DEBUG] 2018-05-22 11:38:37,064 -- BPR fold [8] iter 142: loss = 312.24945, delta_loss = -2.3291826, learn_rate = 1.0548694E-12
[DEBUG] 2018-05-22 11:38:37,113 -- BPR fold [9] iter 144: loss = 300.85236, delta_loss = 0.005412818, learn_rate = 2.2618013E-11
[DEBUG] 2018-05-22 11:38:37,145 -- BPR fold [1] iter 143: loss = 364.10068, delta_loss = 2.2323065, learn_rate = 2.1540965E-11
[DEBUG] 2018-05-22 11:38:37,237 -- BPR fold [4] iter 143: loss = 370.5957, delta_loss = -2.679454, learn_rate = 2.5115936E-13
[DEBUG] 2018-05-22 11:38:37,243 -- BPR fold [3] iter 145: loss = 288.28558, delta_loss = -2.2051783, learn_rate = 1.04732716E-10
[DEBUG] 2018-05-22 11:38:37,248 -- BPR fold [10] iter 140: loss = 364.84042, delta_loss = -0.21759646, learn_rate = 2.009275E-12
[DEBUG] 2018-05-22 11:38:37,263 -- BPR fold [7] iter 144: loss = 306.7933, delta_loss = 2.6025677, learn_rate = 5.1288015E-12
[DEBUG] 2018-05-22 11:38:37,267 -- BPR fold [2] iter 143: loss = 325.53183, delta_loss = 1.9873885, learn_rate = 4.5236027E-11
[DEBUG] 2018-05-22 11:38:37,268 -- BPR fold [6] iter 143: loss = 337.6911, delta_loss = -0.19674617, learn_rate = 2.1540965E-11
[DEBUG] 2018-05-22 11:38:37,343 -- BPR fold [8] iter 143: loss = 308.60406, delta_loss = 3.6453753, learn_rate = 5.274347E-13
[DEBUG] 2018-05-22 11:38:37,360 -- BPR fold [5] iter 145: loss = 283.57645, delta_loss = -1.2935413, learn_rate = 2.1993869E-10
[DEBUG] 2018-05-22 11:38:37,431 -- BPR fold [9] iter 145: loss = 302.03842, delta_loss = -1.1860688, learn_rate = 2.3748914E-11
[DEBUG] 2018-05-22 11:38:37,444 -- BPR fold [1] iter 144: loss = 366.22852, delta_loss = -2.1278152, learn_rate = 2.2618013E-11
[DEBUG] 2018-05-22 11:38:37,497 -- BPR fold [4] iter 144: loss = 365.35645, delta_loss = 5.239245, learn_rate = 1.2557968E-13
[DEBUG] 2018-05-22 11:38:37,515 -- BPR fold [2] iter 144: loss = 326.0729, delta_loss = -0.54109496, learn_rate = 4.749783E-11
[DEBUG] 2018-05-22 11:38:37,525 -- BPR fold [10] iter 141: loss = 362.8543, delta_loss = 1.9860972, learn_rate = 1.0046375E-12
[DEBUG] 2018-05-22 11:38:37,527 -- BPR fold [6] iter 144: loss = 336.13486, delta_loss = 1.5562465, learn_rate = 1.0770483E-11
[DEBUG] 2018-05-22 11:38:37,534 -- BPR fold [3] iter 146: loss = 287.8785, delta_loss = 0.40707427, learn_rate = 5.2366358E-11
[DEBUG] 2018-05-22 11:38:37,541 -- BPR fold [7] iter 145: loss = 309.28256, delta_loss = -2.48927, learn_rate = 5.3852413E-12
[DEBUG] 2018-05-22 11:38:37,577 -- BPR fold [5] iter 146: loss = 282.1925, delta_loss = 1.3839142, learn_rate = 1.09969346E-10
[DEBUG] 2018-05-22 11:38:37,590 -- BPR fold [8] iter 144: loss = 311.88422, delta_loss = -3.280153, learn_rate = 5.538064E-13
[DEBUG] 2018-05-22 11:38:37,632 -- BPR fold [1] iter 145: loss = 366.4634, delta_loss = -0.23491287, learn_rate = 1.1309007E-11
[DEBUG] 2018-05-22 11:38:37,644 -- BPR fold [9] iter 146: loss = 303.89307, delta_loss = -1.8546549, learn_rate = 1.1874457E-11
[DEBUG] 2018-05-22 11:38:37,702 -- BPR fold [4] iter 145: loss = 367.55118, delta_loss = -2.1947346, learn_rate = 1.3185868E-13
[DEBUG] 2018-05-22 11:38:37,717 -- BPR fold [10] iter 142: loss = 368.33264, delta_loss = -5.478315, learn_rate = 1.0548694E-12
[DEBUG] 2018-05-22 11:38:37,720 -- BPR fold [3] iter 147: loss = 286.62442, delta_loss = 1.2540861, learn_rate = 5.4984673E-11
[DEBUG] 2018-05-22 11:38:37,736 -- BPR fold [6] iter 145: loss = 333.119, delta_loss = 3.0158656, learn_rate = 1.1309007E-11
[DEBUG] 2018-05-22 11:38:37,736 -- BPR fold [7] iter 146: loss = 307.58817, delta_loss = 1.6943856, learn_rate = 2.6926206E-12
[DEBUG] 2018-05-22 11:38:37,748 -- BPR fold [2] iter 145: loss = 325.92715, delta_loss = 0.14574303, learn_rate = 2.3748914E-11
[DEBUG] 2018-05-22 11:38:37,784 -- BPR fold [5] iter 147: loss = 283.45633, delta_loss = -1.2638204, learn_rate = 1.15467816E-10
[DEBUG] 2018-05-22 11:38:37,810 -- BPR fold [8] iter 145: loss = 309.4172, delta_loss = 2.4670322, learn_rate = 2.769032E-13
[DEBUG] 2018-05-22 11:38:37,837 -- BPR fold [9] iter 147: loss = 300.57053, delta_loss = 3.322544, learn_rate = 5.9372286E-12
[DEBUG] 2018-05-22 11:38:37,858 -- BPR fold [1] iter 146: loss = 364.64948, delta_loss = 1.8139246, learn_rate = 5.6545033E-12
[DEBUG] 2018-05-22 11:38:37,923 -- BPR fold [10] iter 143: loss = 369.53934, delta_loss = -1.2067039, learn_rate = 5.274347E-13
[DEBUG] 2018-05-22 11:38:37,930 -- BPR fold [4] iter 146: loss = 364.28024, delta_loss = 3.2709296, learn_rate = 6.592934E-14
[DEBUG] 2018-05-22 11:38:37,938 -- BPR fold [2] iter 146: loss = 327.55676, delta_loss = -1.6296052, learn_rate = 2.493636E-11
[DEBUG] 2018-05-22 11:38:37,940 -- BPR fold [3] iter 148: loss = 286.01248, delta_loss = 0.611928, learn_rate = 5.7733908E-11
[DEBUG] 2018-05-22 11:38:37,941 -- BPR fold [6] iter 146: loss = 337.1316, delta_loss = -4.012589, learn_rate = 1.1874457E-11
[DEBUG] 2018-05-22 11:38:37,974 -- BPR fold [7] iter 147: loss = 308.30188, delta_loss = -0.7137114, learn_rate = 2.8272517E-12
[DEBUG] 2018-05-22 11:38:38,002 -- BPR fold [5] iter 148: loss = 281.7241, delta_loss = 1.7322348, learn_rate = 5.7733908E-11
[DEBUG] 2018-05-22 11:38:38,024 -- BPR fold [8] iter 146: loss = 313.79388, delta_loss = -4.376688, learn_rate = 2.9074838E-13
[DEBUG] 2018-05-22 11:38:38,054 -- BPR fold [1] iter 147: loss = 367.2072, delta_loss = -2.5577362, learn_rate = 5.9372286E-12
[DEBUG] 2018-05-22 11:38:38,055 -- BPR fold [9] iter 148: loss = 301.58847, delta_loss = -1.0179498, learn_rate = 6.23409E-12
[DEBUG] 2018-05-22 11:38:38,153 -- BPR fold [3] iter 149: loss = 285.4497, delta_loss = 0.56280345, learn_rate = 6.0620606E-11
[DEBUG] 2018-05-22 11:38:38,162 -- BPR fold [6] iter 147: loss = 336.0891, delta_loss = 1.042466, learn_rate = 5.9372286E-12
[DEBUG] 2018-05-22 11:38:38,171 -- BPR fold [4] iter 147: loss = 365.0378, delta_loss = -0.75754595, learn_rate = 6.92258E-14
[DEBUG] 2018-05-22 11:38:38,172 -- BPR fold [10] iter 144: loss = 367.2955, delta_loss = 2.2438204, learn_rate = 2.6371735E-13
[DEBUG] 2018-05-22 11:38:38,201 -- BPR fold [2] iter 147: loss = 329.87128, delta_loss = -2.3145125, learn_rate = 1.246818E-11
[DEBUG] 2018-05-22 11:38:38,202 -- BPR fold [7] iter 148: loss = 307.82648, delta_loss = 0.47540256, learn_rate = 1.4136258E-12
[DEBUG] 2018-05-22 11:38:38,247 -- BPR fold [5] iter 149: loss = 281.04114, delta_loss = 0.6829653, learn_rate = 6.0620606E-11
[DEBUG] 2018-05-22 11:38:38,297 -- BPR fold [1] iter 148: loss = 361.9272, delta_loss = 5.280055, learn_rate = 2.9686143E-12
[DEBUG] 2018-05-22 11:38:38,300 -- BPR fold [8] iter 147: loss = 309.23, delta_loss = 4.5638733, learn_rate = 1.4537419E-13
[DEBUG] 2018-05-22 11:38:38,312 -- BPR fold [9] iter 149: loss = 303.19406, delta_loss = -1.6055644, learn_rate = 3.117045E-12
[DEBUG] 2018-05-22 11:38:38,387 -- BPR fold [4] iter 148: loss = 364.17514, delta_loss = 0.8626636, learn_rate = 3.46129E-14
[DEBUG] 2018-05-22 11:38:38,420 -- BPR fold [6] iter 148: loss = 342.24234, delta_loss = -6.1532254, learn_rate = 6.23409E-12
[DEBUG] 2018-05-22 11:38:38,425 -- BPR fold [3] iter 150: loss = 284.0939, delta_loss = 1.3557892, learn_rate = 6.365163E-11
[DEBUG] 2018-05-22 11:38:38,460 -- BPR fold [10] iter 145: loss = 368.03238, delta_loss = -0.7368723, learn_rate = 2.769032E-13
[DEBUG] 2018-05-22 11:38:38,464 -- BPR fold [7] iter 149: loss = 311.4035, delta_loss = -3.5770102, learn_rate = 1.4843071E-12
[DEBUG] 2018-05-22 11:38:38,465 -- BPR fold [2] iter 148: loss = 329.22717, delta_loss = 0.6441268, learn_rate = 6.23409E-12
[DEBUG] 2018-05-22 11:38:38,492 -- BPR fold [5] iter 150: loss = 280.283, delta_loss = 0.7581548, learn_rate = 6.365163E-11
[DEBUG] 2018-05-22 11:38:38,505 -- BPR fold [8] iter 148: loss = 312.6081, delta_loss = -3.378076, learn_rate = 1.526429E-13
[DEBUG] 2018-05-22 11:38:38,512 -- BPR fold [9] iter 150: loss = 303.63806, delta_loss = -0.4440208, learn_rate = 1.5585225E-12
[DEBUG] 2018-05-22 11:38:38,544 -- BPR fold [1] iter 149: loss = 370.0191, delta_loss = -8.091942, learn_rate = 3.117045E-12
[DEBUG] 2018-05-22 11:38:38,615 -- BPR fold [4] iter 149: loss = 358.99585, delta_loss = 5.1792808, learn_rate = 3.6343548E-14
[DEBUG] 2018-05-22 11:38:38,691 -- BPR fold [3] iter 151: loss = 289.1433, delta_loss = -5.049422, learn_rate = 6.683421E-11
[DEBUG] 2018-05-22 11:38:38,694 -- BPR fold [6] iter 149: loss = 337.1635, delta_loss = 5.0788226, learn_rate = 3.117045E-12
[DEBUG] 2018-05-22 11:38:38,701 -- BPR fold [10] iter 146: loss = 359.30945, delta_loss = 8.72294, learn_rate = 1.384516E-13
[DEBUG] 2018-05-22 11:38:38,705 -- BPR fold [2] iter 149: loss = 327.4515, delta_loss = 1.7756647, learn_rate = 6.5457947E-12
[DEBUG] 2018-05-22 11:38:38,716 -- BPR fold [7] iter 150: loss = 309.69296, delta_loss = 1.7105283, learn_rate = 7.4215357E-13
[DEBUG] 2018-05-22 11:38:38,747 -- BPR fold [5] iter 151: loss = 281.71466, delta_loss = -1.4316794, learn_rate = 6.683421E-11
[DEBUG] 2018-05-22 11:38:38,760 -- BPR fold [1] iter 150: loss = 368.5615, delta_loss = 1.4576137, learn_rate = 1.5585225E-12
[DEBUG] 2018-05-22 11:38:38,784 -- BPR fold [9] iter 151: loss = 302.97064, delta_loss = 0.667424, learn_rate = 7.7926126E-13
[DEBUG] 2018-05-22 11:38:38,818 -- BPR fold [8] iter 149: loss = 311.9386, delta_loss = 0.66949356, learn_rate = 7.632145E-14
[DEBUG] 2018-05-22 11:38:38,908 -- BPR fold [3] iter 152: loss = 281.99673, delta_loss = 7.1465855, learn_rate = 3.3417106E-11
[DEBUG] 2018-05-22 11:38:38,910 -- BPR fold [4] iter 150: loss = 365.2793, delta_loss = -6.2834277, learn_rate = 3.8160725E-14
[DEBUG] 2018-05-22 11:38:38,916 -- BPR fold [6] iter 150: loss = 333.2208, delta_loss = 3.942716, learn_rate = 3.2728974E-12
[DEBUG] 2018-05-22 11:38:38,916 -- BPR fold [7] iter 151: loss = 310.3871, delta_loss = -0.69412494, learn_rate = 7.7926126E-13
[DEBUG] 2018-05-22 11:38:38,928 -- BPR fold [2] iter 150: loss = 326.3911, delta_loss = 1.0603898, learn_rate = 6.873084E-12
[DEBUG] 2018-05-22 11:38:38,942 -- BPR fold [5] iter 152: loss = 280.00638, delta_loss = 1.7082738, learn_rate = 3.3417106E-11
[DEBUG] 2018-05-22 11:38:38,946 -- BPR fold [10] iter 147: loss = 364.2413, delta_loss = -4.9318705, learn_rate = 1.4537419E-13
[DEBUG] 2018-05-22 11:38:39,007 -- BPR fold [1] iter 151: loss = 366.2523, delta_loss = 2.3092072, learn_rate = 1.6364487E-12
[DEBUG] 2018-05-22 11:38:39,049 -- BPR fold [9] iter 152: loss = 303.11362, delta_loss = -0.14295813, learn_rate = 8.1822434E-13
[DEBUG] 2018-05-22 11:38:39,050 -- BPR fold [8] iter 150: loss = 309.45837, delta_loss = 2.480209, learn_rate = 8.013752E-14
[DEBUG] 2018-05-22 11:38:39,143 -- BPR fold [6] iter 151: loss = 337.22128, delta_loss = -4.000489, learn_rate = 3.436542E-12
[DEBUG] 2018-05-22 11:38:39,146 -- BPR fold [7] iter 152: loss = 309.83084, delta_loss = 0.55624443, learn_rate = 3.8963063E-13
[DEBUG] 2018-05-22 11:38:39,158 -- BPR fold [2] iter 151: loss = 328.9557, delta_loss = -2.564594, learn_rate = 7.2167385E-12
[DEBUG] 2018-05-22 11:38:39,169 -- BPR fold [3] iter 153: loss = 287.78198, delta_loss = -5.7852554, learn_rate = 3.5087964E-11
[DEBUG] 2018-05-22 11:38:39,176 -- BPR fold [4] iter 151: loss = 364.51788, delta_loss = 0.7614085, learn_rate = 1.9080362E-14
[DEBUG] 2018-05-22 11:38:39,186 -- BPR fold [10] iter 148: loss = 360.85623, delta_loss = 3.3850951, learn_rate = 7.2687096E-14
[DEBUG] 2018-05-22 11:38:39,201 -- BPR fold [5] iter 153: loss = 281.6029, delta_loss = -1.59652, learn_rate = 3.5087964E-11
[DEBUG] 2018-05-22 11:38:39,214 -- BPR fold [1] iter 152: loss = 360.48367, delta_loss = 5.768622, learn_rate = 1.718271E-12
[DEBUG] 2018-05-22 11:38:39,250 -- BPR fold [9] iter 153: loss = 297.97006, delta_loss = 5.143539, learn_rate = 4.0911217E-13
[DEBUG] 2018-05-22 11:38:39,253 -- BPR fold [8] iter 151: loss = 314.361, delta_loss = -4.9026046, learn_rate = 8.4144395E-14
[DEBUG] 2018-05-22 11:38:39,369 -- BPR fold [6] iter 152: loss = 338.4921, delta_loss = -1.2708144, learn_rate = 1.718271E-12
[DEBUG] 2018-05-22 11:38:39,377 -- BPR fold [4] iter 152: loss = 366.78592, delta_loss = -2.2680295, learn_rate = 2.003438E-14
[DEBUG] 2018-05-22 11:38:39,381 -- BPR fold [7] iter 153: loss = 306.9156, delta_loss = 2.9152567, learn_rate = 4.0911217E-13
[DEBUG] 2018-05-22 11:38:39,382 -- BPR fold [2] iter 152: loss = 326.2614, delta_loss = 2.6942813, learn_rate = 3.6083692E-12
[DEBUG] 2018-05-22 11:38:39,403 -- BPR fold [10] iter 149: loss = 365.8133, delta_loss = -4.9570813, learn_rate = 7.632145E-14
[DEBUG] 2018-05-22 11:38:39,409 -- BPR fold [3] iter 154: loss = 285.03268, delta_loss = 2.7492971, learn_rate = 1.7543982E-11
[DEBUG] 2018-05-22 11:38:39,428 -- BPR fold [1] iter 153: loss = 363.97202, delta_loss = -3.4883463, learn_rate = 1.8041846E-12
[DEBUG] 2018-05-22 11:38:39,443 -- BPR fold [5] iter 154: loss = 280.7419, delta_loss = 0.8609878, learn_rate = 1.7543982E-11
[DEBUG] 2018-05-22 11:38:39,461 -- BPR fold [9] iter 154: loss = 302.9161, delta_loss = -4.9460354, learn_rate = 4.2956776E-13
[DEBUG] 2018-05-22 11:38:39,462 -- BPR fold [8] iter 152: loss = 314.29648, delta_loss = 0.064521275, learn_rate = 4.2072198E-14
[DEBUG] 2018-05-22 11:38:39,559 -- BPR fold [6] iter 153: loss = 336.46677, delta_loss = 2.0253468, learn_rate = 8.591355E-13
[DEBUG] 2018-05-22 11:38:39,580 -- BPR fold [4] iter 153: loss = 369.9286, delta_loss = -3.1426752, learn_rate = 1.001719E-14
[DEBUG] 2018-05-22 11:38:39,580 -- BPR fold [7] iter 154: loss = 308.73376, delta_loss = -1.8181752, learn_rate = 4.2956776E-13
[DEBUG] 2018-05-22 11:38:39,585 -- BPR fold [2] iter 153: loss = 323.32065, delta_loss = 2.940755, learn_rate = 3.788788E-12
[DEBUG] 2018-05-22 11:38:39,611 -- BPR fold [5] iter 155: loss = 279.71936, delta_loss = 1.0225624, learn_rate = 1.8421181E-11
[DEBUG] 2018-05-22 11:38:39,609 -- BPR fold [3] iter 155: loss = 286.958, delta_loss = -1.9253197, learn_rate = 1.8421181E-11
[DEBUG] 2018-05-22 11:38:39,625 -- BPR fold [1] iter 154: loss = 358.61438, delta_loss = 5.3576293, learn_rate = 9.020923E-13
[DEBUG] 2018-05-22 11:38:39,625 -- BPR fold [10] iter 150: loss = 365.915, delta_loss = -0.10170944, learn_rate = 3.8160725E-14
[DEBUG] 2018-05-22 11:38:39,674 -- BPR fold [9] iter 155: loss = 298.26535, delta_loss = 4.650764, learn_rate = 2.1478388E-13
[DEBUG] 2018-05-22 11:38:39,700 -- BPR fold [8] iter 153: loss = 310.6563, delta_loss = 3.6401439, learn_rate = 4.4175807E-14
[DEBUG] 2018-05-22 11:38:39,845 -- BPR fold [6] iter 154: loss = 334.00104, delta_loss = 2.4657252, learn_rate = 9.020923E-13
[DEBUG] 2018-05-22 11:38:39,883 -- BPR fold [7] iter 155: loss = 311.16348, delta_loss = -2.4297273, learn_rate = 2.1478388E-13
[DEBUG] 2018-05-22 11:38:39,912 -- BPR fold [2] iter 154: loss = 322.81177, delta_loss = 0.5088994, learn_rate = 3.978227E-12
[DEBUG] 2018-05-22 11:38:39,914 -- BPR fold [10] iter 151: loss = 360.23248, delta_loss = 5.6825147, learn_rate = 1.9080362E-14
[DEBUG] 2018-05-22 11:38:39,918 -- BPR fold [4] iter 154: loss = 365.93353, delta_loss = 3.995061, learn_rate = 5.008595E-15
[DEBUG] 2018-05-22 11:38:39,965 -- BPR fold [1] iter 155: loss = 368.21082, delta_loss = -9.596431, learn_rate = 9.47197E-13
[DEBUG] 2018-05-22 11:38:39,965 -- BPR fold [3] iter 156: loss = 283.8458, delta_loss = 3.1122324, learn_rate = 9.210591E-12
[DEBUG] 2018-05-22 11:38:39,979 -- BPR fold [5] iter 156: loss = 281.09476, delta_loss = -1.3754044, learn_rate = 1.934224E-11
[DEBUG] 2018-05-22 11:38:40,001 -- BPR fold [9] iter 156: loss = 302.77588, delta_loss = -4.510533, learn_rate = 2.2552308E-13
[DEBUG] 2018-05-22 11:38:40,013 -- BPR fold [8] iter 154: loss = 310.7294, delta_loss = -0.07308474, learn_rate = 4.6384598E-14
[DEBUG] 2018-05-22 11:38:40,123 -- BPR fold [6] iter 155: loss = 338.08774, delta_loss = -4.086698, learn_rate = 9.47197E-13
[DEBUG] 2018-05-22 11:38:40,146 -- BPR fold [7] iter 156: loss = 313.0857, delta_loss = -1.9221965, learn_rate = 1.0739194E-13
[DEBUG] 2018-05-22 11:38:40,158 -- BPR fold [2] iter 155: loss = 326.81134, delta_loss = -3.999569, learn_rate = 4.1771382E-12
[DEBUG] 2018-05-22 11:38:40,159 -- BPR fold [4] iter 155: loss = 367.75052, delta_loss = -1.8169998, learn_rate = 5.2590247E-15
[DEBUG] 2018-05-22 11:38:40,179 -- BPR fold [3] iter 157: loss = 286.97632, delta_loss = -3.1305416, learn_rate = 9.67112E-12
[DEBUG] 2018-05-22 11:38:40,197 -- BPR fold [5] iter 157: loss = 280.5942, delta_loss = 0.5005501, learn_rate = 9.67112E-12
[DEBUG] 2018-05-22 11:38:40,201 -- BPR fold [1] iter 156: loss = 367.3672, delta_loss = 0.8436246, learn_rate = 4.735985E-13
[DEBUG] 2018-05-22 11:38:40,205 -- BPR fold [8] iter 155: loss = 310.3293, delta_loss = 0.40008003, learn_rate = 2.3192299E-14
[DEBUG] 2018-05-22 11:38:40,220 -- BPR fold [10] iter 152: loss = 363.02634, delta_loss = -2.7938387, learn_rate = 2.003438E-14
[DEBUG] 2018-05-22 11:38:40,249 -- BPR fold [9] iter 157: loss = 304.1593, delta_loss = -1.3834282, learn_rate = 1.1276154E-13
[DEBUG] 2018-05-22 11:38:40,337 -- BPR fold [6] iter 156: loss = 340.08334, delta_loss = -1.9956264, learn_rate = 4.735985E-13
[DEBUG] 2018-05-22 11:38:40,351 -- BPR fold [7] iter 157: loss = 310.45074, delta_loss = 2.6349373, learn_rate = 5.369597E-14
[DEBUG] 2018-05-22 11:38:40,358 -- BPR fold [2] iter 156: loss = 327.99597, delta_loss = -1.1846533, learn_rate = 2.0885691E-12
[DEBUG] 2018-05-22 11:38:40,374 -- BPR fold [4] iter 156: loss = 366.0337, delta_loss = 1.7168407, learn_rate = 2.6295124E-15
[DEBUG] 2018-05-22 11:38:40,390 -- BPR fold [5] iter 158: loss = 279.67172, delta_loss = 0.9225003, learn_rate = 1.0154676E-11
[DEBUG] 2018-05-22 11:38:40,404 -- BPR fold [10] iter 153: loss = 370.04498, delta_loss = -7.0186515, learn_rate = 1.001719E-14
[DEBUG] 2018-05-22 11:38:40,405 -- BPR fold [1] iter 157: loss = 360.3283, delta_loss = 7.038896, learn_rate = 4.972784E-13
[DEBUG] 2018-05-22 11:38:40,406 -- BPR fold [3] iter 158: loss = 285.88754, delta_loss = 1.0887922, learn_rate = 4.83556E-12
[DEBUG] 2018-05-22 11:38:40,436 -- BPR fold [8] iter 156: loss = 312.13623, delta_loss = -1.8068938, learn_rate = 2.4351914E-14
[DEBUG] 2018-05-22 11:38:40,476 -- BPR fold [9] iter 158: loss = 301.30884, delta_loss = 2.8504603, learn_rate = 5.638077E-14
[DEBUG] 2018-05-22 11:38:40,580 -- BPR fold [7] iter 158: loss = 310.31665, delta_loss = 0.13410963, learn_rate = 5.638077E-14
[DEBUG] 2018-05-22 11:38:40,581 -- BPR fold [6] iter 157: loss = 336.03668, delta_loss = 4.046675, learn_rate = 2.3679924E-13
[DEBUG] 2018-05-22 11:38:40,599 -- BPR fold [4] iter 157: loss = 370.79562, delta_loss = -4.761933, learn_rate = 2.760988E-15
[DEBUG] 2018-05-22 11:38:40,619 -- BPR fold [2] iter 157: loss = 329.62222, delta_loss = -1.6262406, learn_rate = 1.0442846E-12
[DEBUG] 2018-05-22 11:38:40,632 -- BPR fold [5] iter 159: loss = 284.0542, delta_loss = -4.3824983, learn_rate = 1.0662409E-11
[DEBUG] 2018-05-22 11:38:40,644 -- BPR fold [1] iter 158: loss = 363.69705, delta_loss = -3.3687537, learn_rate = 5.221423E-13
[DEBUG] 2018-05-22 11:38:40,650 -- BPR fold [3] iter 159: loss = 284.31125, delta_loss = 1.576299, learn_rate = 5.077338E-12
[DEBUG] 2018-05-22 11:38:40,653 -- BPR fold [8] iter 157: loss = 311.1216, delta_loss = 1.0146062, learn_rate = 1.2175957E-14
[DEBUG] 2018-05-22 11:38:40,656 -- BPR fold [10] iter 154: loss = 363.7465, delta_loss = 6.298497, learn_rate = 5.008595E-15
[DEBUG] 2018-05-22 11:38:40,691 -- BPR fold [9] iter 159: loss = 303.52524, delta_loss = -2.2163882, learn_rate = 5.919981E-14
[DEBUG] 2018-05-22 11:38:40,763 -- BPR fold [7] iter 159: loss = 311.1581, delta_loss = -0.8414641, learn_rate = 5.919981E-14
[DEBUG] 2018-05-22 11:38:40,777 -- BPR fold [4] iter 158: loss = 372.27002, delta_loss = -1.4744155, learn_rate = 1.380494E-15
[DEBUG] 2018-05-22 11:38:40,780 -- BPR fold [6] iter 158: loss = 338.71667, delta_loss = -2.6799803, learn_rate = 2.486392E-13
[DEBUG] 2018-05-22 11:38:40,821 -- BPR fold [2] iter 158: loss = 325.41364, delta_loss = 4.208592, learn_rate = 5.221423E-13
[DEBUG] 2018-05-22 11:38:40,830 -- BPR fold [5] iter 160: loss = 285.38403, delta_loss = -1.3298254, learn_rate = 5.3312047E-12
[DEBUG] 2018-05-22 11:38:40,837 -- BPR fold [1] iter 159: loss = 364.82428, delta_loss = -1.1272237, learn_rate = 2.6107114E-13
[DEBUG] 2018-05-22 11:38:40,847 -- BPR fold [3] iter 160: loss = 286.58102, delta_loss = -2.2697973, learn_rate = 5.3312047E-12
[DEBUG] 2018-05-22 11:38:40,862 -- BPR fold [10] iter 155: loss = 364.5266, delta_loss = -0.78012824, learn_rate = 5.2590247E-15
[DEBUG] 2018-05-22 11:38:40,883 -- BPR fold [8] iter 158: loss = 313.24088, delta_loss = -2.1192467, learn_rate = 1.2784755E-14
[DEBUG] 2018-05-22 11:38:40,911 -- BPR fold [9] iter 160: loss = 298.44684, delta_loss = 5.078393, learn_rate = 2.9599905E-14
[DEBUG] 2018-05-22 11:38:40,991 -- BPR fold [7] iter 160: loss = 309.77798, delta_loss = 1.3801082, learn_rate = 2.9599905E-14
[DEBUG] 2018-05-22 11:38:40,993 -- BPR fold [6] iter 159: loss = 335.49393, delta_loss = 3.2227392, learn_rate = 1.243196E-13
[DEBUG] 2018-05-22 11:38:41,022 -- BPR fold [4] iter 159: loss = 365.54776, delta_loss = 6.7222753, learn_rate = 6.90247E-16
[DEBUG] 2018-05-22 11:38:41,033 -- BPR fold [1] iter 160: loss = 362.10114, delta_loss = 2.723143, learn_rate = 1.3053557E-13
[DEBUG] 2018-05-22 11:38:41,041 -- BPR fold [2] iter 159: loss = 329.6862, delta_loss = -4.272562, learn_rate = 5.4824943E-13
[DEBUG] 2018-05-22 11:38:41,041 -- BPR fold [5] iter 161: loss = 282.1308, delta_loss = 3.2532525, learn_rate = 2.6656023E-12
[DEBUG] 2018-05-22 11:38:41,072 -- BPR fold [3] iter 161: loss = 289.04504, delta_loss = -2.4640067, learn_rate = 2.6656023E-12
[DEBUG] 2018-05-22 11:38:41,077 -- BPR fold [10] iter 156: loss = 368.00546, delta_loss = -3.478846, learn_rate = 2.6295124E-15
[DEBUG] 2018-05-22 11:38:41,095 -- BPR fold [8] iter 159: loss = 310.8831, delta_loss = 2.357788, learn_rate = 6.3923777E-15
[DEBUG] 2018-05-22 11:38:41,123 -- BPR fold [9] iter 161: loss = 302.81805, delta_loss = -4.371233, learn_rate = 3.10799E-14
[DEBUG] 2018-05-22 11:38:41,194 -- BPR fold [7] iter 161: loss = 310.6078, delta_loss = -0.8297809, learn_rate = 3.10799E-14
[DEBUG] 2018-05-22 11:38:41,196 -- BPR fold [6] iter 160: loss = 338.06268, delta_loss = -2.5687695, learn_rate = 1.3053557E-13
[DEBUG] 2018-05-22 11:38:41,230 -- BPR fold [4] iter 160: loss = 368.88458, delta_loss = -3.3368251, learn_rate = 7.2475935E-16
[DEBUG] 2018-05-22 11:38:41,246 -- BPR fold [5] iter 162: loss = 283.96158, delta_loss = -1.8307865, learn_rate = 2.7988824E-12
[DEBUG] 2018-05-22 11:38:41,247 -- BPR fold [2] iter 160: loss = 327.90515, delta_loss = 1.7810354, learn_rate = 2.7412472E-13
[DEBUG] 2018-05-22 11:38:41,256 -- BPR fold [1] iter 161: loss = 361.3396, delta_loss = 0.76152647, learn_rate = 1.3706236E-13
[DEBUG] 2018-05-22 11:38:41,273 -- BPR fold [3] iter 162: loss = 288.20416, delta_loss = 0.840887, learn_rate = 1.3328012E-12
[DEBUG] 2018-05-22 11:38:41,285 -- BPR fold [10] iter 157: loss = 366.5007, delta_loss = 1.5047752, learn_rate = 1.3147562E-15
[DEBUG] 2018-05-22 11:38:41,298 -- BPR fold [8] iter 160: loss = 315.61346, delta_loss = -4.7303767, learn_rate = 6.7119962E-15
[DEBUG] 2018-05-22 11:38:41,325 -- BPR fold [9] iter 162: loss = 305.31943, delta_loss = -2.5013561, learn_rate = 1.553995E-14
[DEBUG] 2018-05-22 11:38:41,397 -- BPR fold [6] iter 161: loss = 332.43222, delta_loss = 5.63048, learn_rate = 6.5267785E-14
[DEBUG] 2018-05-22 11:38:41,401 -- BPR fold [7] iter 162: loss = 309.40613, delta_loss = 1.2016602, learn_rate = 1.553995E-14
[DEBUG] 2018-05-22 11:38:41,432 -- BPR fold [4] iter 161: loss = 362.8009, delta_loss = 6.0836644, learn_rate = 3.6237967E-16
[DEBUG] 2018-05-22 11:38:41,450 -- BPR fold [2] iter 161: loss = 325.90247, delta_loss = 2.0026836, learn_rate = 2.8783096E-13
[DEBUG] 2018-05-22 11:38:41,455 -- BPR fold [1] iter 162: loss = 365.9903, delta_loss = -4.6506753, learn_rate = 1.4391548E-13
[DEBUG] 2018-05-22 11:38:41,457 -- BPR fold [5] iter 163: loss = 279.54495, delta_loss = 4.4166064, learn_rate = 1.3994412E-12
[DEBUG] 2018-05-22 11:38:41,468 -- BPR fold [3] iter 163: loss = 285.91724, delta_loss = 2.2869043, learn_rate = 1.3994412E-12
[DEBUG] 2018-05-22 11:38:41,495 -- BPR fold [8] iter 161: loss = 309.70294, delta_loss = 5.910504, learn_rate = 3.3559981E-15
[DEBUG] 2018-05-22 11:38:41,514 -- BPR fold [10] iter 158: loss = 365.7348, delta_loss = 0.7659014, learn_rate = 1.380494E-15
[DEBUG] 2018-05-22 11:38:41,518 -- BPR fold [9] iter 163: loss = 302.02844, delta_loss = 3.290965, learn_rate = 7.769975E-15
[DEBUG] 2018-05-22 11:38:41,606 -- BPR fold [7] iter 163: loss = 306.1287, delta_loss = 3.2774298, learn_rate = 1.6316946E-14
[DEBUG] 2018-05-22 11:38:41,614 -- BPR fold [6] iter 162: loss = 338.92535, delta_loss = -6.493152, learn_rate = 6.853118E-14
[DEBUG] 2018-05-22 11:38:41,640 -- BPR fold [4] iter 162: loss = 365.6145, delta_loss = -2.8135924, learn_rate = 3.8049866E-16
[DEBUG] 2018-05-22 11:38:41,647 -- BPR fold [2] iter 162: loss = 324.21204, delta_loss = 1.6904416, learn_rate = 3.022225E-13
[DEBUG] 2018-05-22 11:38:41,662 -- BPR fold [1] iter 163: loss = 368.70453, delta_loss = -2.71426, learn_rate = 7.195774E-14
[DEBUG] 2018-05-22 11:38:41,667 -- BPR fold [5] iter 164: loss = 281.07538, delta_loss = -1.5304241, learn_rate = 1.4694133E-12
[DEBUG] 2018-05-22 11:38:41,678 -- BPR fold [3] iter 164: loss = 284.67267, delta_loss = 1.2445698, learn_rate = 1.4694133E-12
[DEBUG] 2018-05-22 11:38:41,694 -- BPR fold [8] iter 162: loss = 310.37735, delta_loss = -0.6743913, learn_rate = 3.523798E-15
[DEBUG] 2018-05-22 11:38:41,722 -- BPR fold [10] iter 159: loss = 370.45663, delta_loss = -4.721856, learn_rate = 1.4495187E-15
[DEBUG] 2018-05-22 11:38:41,734 -- BPR fold [9] iter 164: loss = 302.13248, delta_loss = -0.10401722, learn_rate = 8.158473E-15
[DEBUG] 2018-05-22 11:38:41,794 -- BPR fold [6] iter 163: loss = 336.89618, delta_loss = 2.0291939, learn_rate = 3.426559E-14
[DEBUG] 2018-05-22 11:38:41,807 -- BPR fold [7] iter 164: loss = 308.92078, delta_loss = -2.7920797, learn_rate = 1.7132795E-14
[DEBUG] 2018-05-22 11:38:41,837 -- BPR fold [4] iter 163: loss = 366.26718, delta_loss = -0.6526842, learn_rate = 1.9024933E-16
[DEBUG] 2018-05-22 11:38:41,848 -- BPR fold [2] iter 163: loss = 325.69037, delta_loss = -1.4783399, learn_rate = 3.1733362E-13
[DEBUG] 2018-05-22 11:38:41,855 -- BPR fold [1] iter 164: loss = 366.72177, delta_loss = 1.9827566, learn_rate = 3.597887E-14
[DEBUG] 2018-05-22 11:38:41,864 -- BPR fold [3] iter 165: loss = 285.8903, delta_loss = -1.2176094, learn_rate = 1.542884E-12
[DEBUG] 2018-05-22 11:38:41,870 -- BPR fold [5] iter 165: loss = 282.738, delta_loss = -1.6626308, learn_rate = 7.347067E-13
[DEBUG] 2018-05-22 11:38:41,894 -- BPR fold [8] iter 163: loss = 308.23093, delta_loss = 2.146401, learn_rate = 1.761899E-15
[DEBUG] 2018-05-22 11:38:41,916 -- BPR fold [10] iter 160: loss = 367.98486, delta_loss = 2.4717798, learn_rate = 7.2475935E-16
[DEBUG] 2018-05-22 11:38:41,941 -- BPR fold [9] iter 165: loss = 304.70746, delta_loss = -2.574989, learn_rate = 4.0792366E-15
[DEBUG] 2018-05-22 11:38:41,996 -- BPR fold [6] iter 164: loss = 339.0407, delta_loss = -2.1445367, learn_rate = 3.597887E-14
[DEBUG] 2018-05-22 11:38:42,030 -- BPR fold [7] iter 165: loss = 306.79428, delta_loss = 2.126496, learn_rate = 8.566397E-15
[DEBUG] 2018-05-22 11:38:42,083 -- BPR fold [4] iter 164: loss = 363.2008, delta_loss = 3.066376, learn_rate = 9.5124665E-17
[DEBUG] 2018-05-22 11:38:42,094 -- BPR fold [2] iter 164: loss = 327.37088, delta_loss = -1.6805015, learn_rate = 1.5866681E-13
[DEBUG] 2018-05-22 11:38:42,096 -- BPR fold [3] iter 166: loss = 290.5331, delta_loss = -4.6428328, learn_rate = 7.71442E-13
[DEBUG] 2018-05-22 11:38:42,121 -- BPR fold [5] iter 166: loss = 281.74432, delta_loss = 0.99369615, learn_rate = 3.6735334E-13
[DEBUG] 2018-05-22 11:38:42,123 -- BPR fold [1] iter 165: loss = 362.63617, delta_loss = 4.0856233, learn_rate = 3.7777812E-14
[DEBUG] 2018-05-22 11:38:42,173 -- BPR fold [8] iter 164: loss = 310.32816, delta_loss = -2.097222, learn_rate = 1.849994E-15
[DEBUG] 2018-05-22 11:38:42,233 -- BPR fold [10] iter 161: loss = 365.24664, delta_loss = 2.738226, learn_rate = 7.609973E-16
[DEBUG] 2018-05-22 11:38:42,253 -- BPR fold [9] iter 166: loss = 300.23468, delta_loss = 4.472798, learn_rate = 2.0396183E-15
[DEBUG] 2018-05-22 11:38:42,329 -- BPR fold [6] iter 165: loss = 342.41064, delta_loss = -3.3699381, learn_rate = 1.7989435E-14
[DEBUG] 2018-05-22 11:38:42,343 -- BPR fold [7] iter 166: loss = 309.74503, delta_loss = -2.9507442, learn_rate = 8.994717E-15
[DEBUG] 2018-05-22 11:38:42,383 -- BPR fold [4] iter 165: loss = 365.5408, delta_loss = -2.3399777, learn_rate = 9.98809E-17
[DEBUG] 2018-05-22 11:38:42,394 -- BPR fold [3] iter 167: loss = 286.11386, delta_loss = 4.4192452, learn_rate = 3.85721E-13
[DEBUG] 2018-05-22 11:38:42,394 -- BPR fold [2] iter 165: loss = 322.88824, delta_loss = 4.4826365, learn_rate = 7.9333404E-14
[DEBUG] 2018-05-22 11:38:42,406 -- BPR fold [5] iter 167: loss = 280.99933, delta_loss = 0.744982, learn_rate = 3.85721E-13
[DEBUG] 2018-05-22 11:38:42,421 -- BPR fold [1] iter 166: loss = 364.2789, delta_loss = -1.6427441, learn_rate = 3.9666702E-14
[DEBUG] 2018-05-22 11:38:42,451 -- BPR fold [8] iter 165: loss = 312.72815, delta_loss = -2.399982, learn_rate = 9.24997E-16
[DEBUG] 2018-05-22 11:38:42,472 -- BPR fold [10] iter 162: loss = 369.5196, delta_loss = -4.272951, learn_rate = 7.990472E-16
[DEBUG] 2018-05-22 11:38:42,512 -- BPR fold [9] iter 167: loss = 305.8664, delta_loss = -5.6317234, learn_rate = 2.1415994E-15
[DEBUG] 2018-05-22 11:38:42,530 -- BPR fold [7] iter 167: loss = 307.30173, delta_loss = 2.4432926, learn_rate = 4.4973587E-15
[DEBUG] 2018-05-22 11:38:42,583 -- BPR fold [6] iter 166: loss = 334.21918, delta_loss = 8.19146, learn_rate = 8.994717E-15
[DEBUG] 2018-05-22 11:38:42,603 -- BPR fold [4] iter 166: loss = 367.0946, delta_loss = -1.5538266, learn_rate = 4.994045E-17
[DEBUG] 2018-05-22 11:38:42,634 -- BPR fold [2] iter 166: loss = 324.55707, delta_loss = -1.6688287, learn_rate = 8.330007E-14
[DEBUG] 2018-05-22 11:38:42,635 -- BPR fold [5] iter 168: loss = 280.24796, delta_loss = 0.7513747, learn_rate = 4.0500706E-13
[DEBUG] 2018-05-22 11:38:42,637 -- BPR fold [3] iter 168: loss = 285.45404, delta_loss = 0.6598187, learn_rate = 4.0500706E-13
[DEBUG] 2018-05-22 11:38:42,687 -- BPR fold [1] iter 167: loss = 370.1823, delta_loss = -5.903406, learn_rate = 1.9833351E-14
[DEBUG] 2018-05-22 11:38:42,703 -- BPR fold [8] iter 166: loss = 311.74084, delta_loss = 0.987299, learn_rate = 4.624985E-16
[DEBUG] 2018-05-22 11:38:42,778 -- BPR fold [10] iter 163: loss = 361.66913, delta_loss = 7.850452, learn_rate = 3.995236E-16
[DEBUG] 2018-05-22 11:38:42,799 -- BPR fold [9] iter 168: loss = 298.64536, delta_loss = 7.2210417, learn_rate = 1.0707997E-15
[DEBUG] 2018-05-22 11:38:42,909 -- BPR fold [7] iter 168: loss = 309.284, delta_loss = -1.9822725, learn_rate = 4.7222265E-15
[DEBUG] 2018-05-22 11:38:42,924 -- BPR fold [3] iter 169: loss = 286.15558, delta_loss = -0.7015252, learn_rate = 4.252574E-13
[DEBUG] 2018-05-22 11:38:42,931 -- BPR fold [6] iter 167: loss = 341.98892, delta_loss = -7.769744, learn_rate = 9.444453E-15
[DEBUG] 2018-05-22 11:38:42,932 -- BPR fold [4] iter 167: loss = 358.49152, delta_loss = 8.603114, learn_rate = 2.4970225E-17
[DEBUG] 2018-05-22 11:38:42,943 -- BPR fold [2] iter 167: loss = 323.89563, delta_loss = 0.6614451, learn_rate = 4.1650036E-14
[DEBUG] 2018-05-22 11:38:42,945 -- BPR fold [5] iter 169: loss = 282.63562, delta_loss = -2.3876593, learn_rate = 4.252574E-13
[DEBUG] 2018-05-22 11:38:42,955 -- BPR fold [8] iter 167: loss = 308.83368, delta_loss = 2.9071548, learn_rate = 4.856234E-16
[DEBUG] 2018-05-22 11:38:42,979 -- BPR fold [1] iter 168: loss = 363.99155, delta_loss = 6.1907754, learn_rate = 9.9166755E-15
[DEBUG] 2018-05-22 11:38:43,031 -- BPR fold [10] iter 164: loss = 371.2524, delta_loss = -9.583262, learn_rate = 4.1949976E-16
[DEBUG] 2018-05-22 11:38:43,062 -- BPR fold [9] iter 169: loss = 298.81097, delta_loss = -0.16562098, learn_rate = 1.1243397E-15
[DEBUG] 2018-05-22 11:38:43,155 -- BPR fold [7] iter 169: loss = 312.6415, delta_loss = -3.357513, learn_rate = 2.3611132E-15
[DEBUG] 2018-05-22 11:38:43,163 -- BPR fold [4] iter 168: loss = 364.65427, delta_loss = -6.16275, learn_rate = 2.6218735E-17
[DEBUG] 2018-05-22 11:38:43,169 -- BPR fold [3] iter 170: loss = 289.49713, delta_loss = -3.3415487, learn_rate = 2.126287E-13
[DEBUG] 2018-05-22 11:38:43,171 -- BPR fold [6] iter 168: loss = 339.8587, delta_loss = 2.130214, learn_rate = 4.7222265E-15
[DEBUG] 2018-05-22 11:38:43,181 -- BPR fold [5] iter 170: loss = 281.8271, delta_loss = 0.8085406, learn_rate = 2.126287E-13
[DEBUG] 2018-05-22 11:38:43,212 -- BPR fold [2] iter 168: loss = 326.85837, delta_loss = -2.962738, learn_rate = 4.3732538E-14
[DEBUG] 2018-05-22 11:38:43,255 -- BPR fold [8] iter 168: loss = 309.62524, delta_loss = -0.7915518, learn_rate = 5.0990457E-16
[DEBUG] 2018-05-22 11:38:43,308 -- BPR fold [1] iter 169: loss = 364.51654, delta_loss = -0.5250163, learn_rate = 1.0412509E-14
[DEBUG] 2018-05-22 11:38:43,363 -- BPR fold [10] iter 165: loss = 363.42477, delta_loss = 7.8276334, learn_rate = 2.0974988E-16
[DEBUG] 2018-05-22 11:38:43,371 -- BPR fold [9] iter 170: loss = 299.82605, delta_loss = -1.0150757, learn_rate = 5.6216984E-16
[DEBUG] 2018-05-22 11:38:43,446 -- BPR fold [2] iter 169: loss = 323.4291, delta_loss = 3.429247, learn_rate = 2.1866269E-14
[DEBUG] 2018-05-22 11:38:43,471 -- BPR fold [4] iter 169: loss = 370.43158, delta_loss = -5.7773266, learn_rate = 1.3109368E-17
[DEBUG] 2018-05-22 11:38:43,477 -- BPR fold [7] iter 170: loss = 311.62515, delta_loss = 1.0163598, learn_rate = 1.1805566E-15
[DEBUG] 2018-05-22 11:38:43,477 -- BPR fold [3] iter 171: loss = 287.71664, delta_loss = 1.7804992, learn_rate = 1.0631435E-13
[DEBUG] 2018-05-22 11:38:43,484 -- BPR fold [6] iter 169: loss = 335.8947, delta_loss = 3.96401, learn_rate = 4.9583377E-15
[DEBUG] 2018-05-22 11:38:43,506 -- BPR fold [5] iter 171: loss = 279.8963, delta_loss = 1.9307779, learn_rate = 2.2326013E-13
[DEBUG] 2018-05-22 11:38:43,519 -- BPR fold [8] iter 169: loss = 312.61728, delta_loss = -2.9920435, learn_rate = 2.5495228E-16
[DEBUG] 2018-05-22 11:38:43,554 -- BPR fold [1] iter 170: loss = 367.66794, delta_loss = -3.151374, learn_rate = 5.2062546E-15
[DEBUG] 2018-05-22 11:38:43,621 -- BPR fold [9] iter 171: loss = 302.27878, delta_loss = -2.4527218, learn_rate = 2.8108492E-16
[DEBUG] 2018-05-22 11:38:43,625 -- BPR fold [10] iter 166: loss = 361.45972, delta_loss = 1.9650443, learn_rate = 2.2023738E-16
[DEBUG] 2018-05-22 11:38:43,689 -- BPR fold [2] iter 170: loss = 323.90823, delta_loss = -0.47913182, learn_rate = 2.2959584E-14
[DEBUG] 2018-05-22 11:38:43,697 -- BPR fold [3] iter 172: loss = 283.88947, delta_loss = 3.827159, learn_rate = 1.11630066E-13
[DEBUG] 2018-05-22 11:38:43,700 -- BPR fold [7] iter 171: loss = 305.3829, delta_loss = 6.242258, learn_rate = 1.2395844E-15
[DEBUG] 2018-05-22 11:38:43,700 -- BPR fold [6] iter 170: loss = 338.2803, delta_loss = -2.3856153, learn_rate = 5.2062546E-15
[DEBUG] 2018-05-22 11:38:43,707 -- BPR fold [4] iter 170: loss = 364.60974, delta_loss = 5.82184, learn_rate = 6.554684E-18
[DEBUG] 2018-05-22 11:38:43,720 -- BPR fold [5] iter 172: loss = 284.15985, delta_loss = -4.2635536, learn_rate = 2.3442313E-13
[DEBUG] 2018-05-22 11:38:43,730 -- BPR fold [8] iter 170: loss = 312.154, delta_loss = 0.46329787, learn_rate = 1.2747614E-16
[DEBUG] 2018-05-22 11:38:43,771 -- BPR fold [1] iter 171: loss = 363.81354, delta_loss = 3.854381, learn_rate = 2.6031273E-15
[DEBUG] 2018-05-22 11:38:43,837 -- BPR fold [10] iter 167: loss = 366.362, delta_loss = -4.90227, learn_rate = 2.3124926E-16
[DEBUG] 2018-05-22 11:38:43,853 -- BPR fold [9] iter 172: loss = 302.69876, delta_loss = -0.41999176, learn_rate = 1.4054246E-16
[DEBUG] 2018-05-22 11:38:43,890 -- BPR fold [4] iter 171: loss = 364.46426, delta_loss = 0.14547136, learn_rate = 6.882418E-18
[DEBUG] 2018-05-22 11:38:43,898 -- BPR fold [2] iter 171: loss = 324.2578, delta_loss = -0.34955975, learn_rate = 1.1479792E-14
[DEBUG] 2018-05-22 11:38:43,899 -- BPR fold [7] iter 172: loss = 307.27136, delta_loss = -1.8884851, learn_rate = 1.3015636E-15
[DEBUG] 2018-05-22 11:38:43,915 -- BPR fold [6] iter 171: loss = 334.60138, delta_loss = 3.6789389, learn_rate = 2.6031273E-15
[DEBUG] 2018-05-22 11:38:43,921 -- BPR fold [3] iter 173: loss = 284.97147, delta_loss = -1.0820043, learn_rate = 1.1721157E-13
[DEBUG] 2018-05-22 11:38:43,936 -- BPR fold [5] iter 173: loss = 282.3637, delta_loss = 1.796162, learn_rate = 1.1721157E-13
[DEBUG] 2018-05-22 11:38:43,951 -- BPR fold [8] iter 171: loss = 311.2549, delta_loss = 0.89907575, learn_rate = 1.3384996E-16
[DEBUG] 2018-05-22 11:38:43,965 -- BPR fold [1] iter 172: loss = 365.2874, delta_loss = -1.4738603, learn_rate = 2.7332836E-15
[DEBUG] 2018-05-22 11:38:44,037 -- BPR fold [9] iter 173: loss = 300.96686, delta_loss = 1.7318901, learn_rate = 7.027123E-17
[DEBUG] 2018-05-22 11:38:44,057 -- BPR fold [10] iter 168: loss = 367.16354, delta_loss = -0.8015651, learn_rate = 1.1562463E-16
[DEBUG] 2018-05-22 11:38:44,096 -- BPR fold [2] iter 172: loss = 329.6715, delta_loss = -5.413701, learn_rate = 5.739896E-15
[DEBUG] 2018-05-22 11:38:44,102 -- BPR fold [7] iter 173: loss = 309.48062, delta_loss = -2.2092464, learn_rate = 6.507818E-16
[DEBUG] 2018-05-22 11:38:44,107 -- BPR fold [6] iter 172: loss = 341.89978, delta_loss = -7.2983866, learn_rate = 2.7332836E-15
[DEBUG] 2018-05-22 11:38:44,110 -- BPR fold [4] iter 172: loss = 365.7653, delta_loss = -1.3010184, learn_rate = 7.226539E-18
[DEBUG] 2018-05-22 11:38:44,112 -- BPR fold [3] iter 174: loss = 287.46854, delta_loss = -2.4970486, learn_rate = 5.860578E-14
[DEBUG] 2018-05-22 11:38:44,136 -- BPR fold [8] iter 172: loss = 310.00278, delta_loss = 1.2521318, learn_rate = 1.4054246E-16
[DEBUG] 2018-05-22 11:38:44,147 -- BPR fold [5] iter 174: loss = 282.09125, delta_loss = 0.2724506, learn_rate = 1.2307215E-13
[DEBUG] 2018-05-22 11:38:44,159 -- BPR fold [1] iter 173: loss = 362.85883, delta_loss = 2.428589, learn_rate = 1.3666418E-15
[DEBUG] 2018-05-22 11:38:44,225 -- BPR fold [9] iter 174: loss = 300.93298, delta_loss = 0.03387206, learn_rate = 7.378479E-17
[DEBUG] 2018-05-22 11:38:44,245 -- BPR fold [10] iter 169: loss = 366.0381, delta_loss = 1.125457, learn_rate = 5.7812315E-17
[DEBUG] 2018-05-22 11:38:44,301 -- BPR fold [2] iter 173: loss = 323.2828, delta_loss = 6.388688, learn_rate = 2.869948E-15
[DEBUG] 2018-05-22 11:38:44,305 -- BPR fold [7] iter 174: loss = 305.0427, delta_loss = 4.4379363, learn_rate = 3.253909E-16
[DEBUG] 2018-05-22 11:38:44,310 -- BPR fold [4] iter 173: loss = 368.5438, delta_loss = -2.7785017, learn_rate = 3.6132697E-18
[DEBUG] 2018-05-22 11:38:44,317 -- BPR fold [3] iter 175: loss = 287.17838, delta_loss = 0.2901596, learn_rate = 2.930289E-14
[DEBUG] 2018-05-22 11:38:44,319 -- BPR fold [6] iter 173: loss = 336.97464, delta_loss = 4.9251285, learn_rate = 1.3666418E-15
[DEBUG] 2018-05-22 11:38:44,356 -- BPR fold [5] iter 175: loss = 283.2824, delta_loss = -1.1911621, learn_rate = 1.2922576E-13
[DEBUG] 2018-05-22 11:38:44,370 -- BPR fold [8] iter 173: loss = 304.60284, delta_loss = 5.3999376, learn_rate = 1.4756958E-16
[DEBUG] 2018-05-22 11:38:44,371 -- BPR fold [1] iter 174: loss = 371.32907, delta_loss = -8.470268, learn_rate = 1.434974E-15
[DEBUG] 2018-05-22 11:38:44,444 -- BPR fold [10] iter 170: loss = 367.81708, delta_loss = -1.7789668, learn_rate = 6.070293E-17
[DEBUG] 2018-05-22 11:38:44,448 -- BPR fold [9] iter 175: loss = 302.13446, delta_loss = -1.2014672, learn_rate = 7.747403E-17
[DEBUG] 2018-05-22 11:38:44,504 -- BPR fold [7] iter 175: loss = 312.11487, delta_loss = -7.072175, learn_rate = 3.4166045E-16
[DEBUG] 2018-05-22 11:38:44,511 -- BPR fold [2] iter 174: loss = 327.02917, delta_loss = -3.746353, learn_rate = 3.0134453E-15
[DEBUG] 2018-05-22 11:38:44,511 -- BPR fold [4] iter 174: loss = 366.64902, delta_loss = 1.8947761, learn_rate = 1.8066348E-18
[DEBUG] 2018-05-22 11:38:44,517 -- BPR fold [3] iter 176: loss = 289.5721, delta_loss = -2.3937547, learn_rate = 3.0768038E-14
[DEBUG] 2018-05-22 11:38:44,524 -- BPR fold [6] iter 174: loss = 333.8118, delta_loss = 3.1628363, learn_rate = 1.434974E-15
[DEBUG] 2018-05-22 11:38:44,547 -- BPR fold [5] iter 176: loss = 283.16394, delta_loss = 0.1184619, learn_rate = 6.461288E-14
[DEBUG] 2018-05-22 11:38:44,559 -- BPR fold [8] iter 174: loss = 308.75522, delta_loss = -4.1523733, learn_rate = 1.5494805E-16
[DEBUG] 2018-05-22 11:38:44,564 -- BPR fold [1] iter 175: loss = 359.96393, delta_loss = 11.36516, learn_rate = 7.17487E-16
[DEBUG] 2018-05-22 11:38:44,635 -- BPR fold [9] iter 176: loss = 301.01712, delta_loss = 1.1173525, learn_rate = 3.8737014E-17
[DEBUG] 2018-05-22 11:38:44,676 -- BPR fold [6] iter 175: loss = 336.7523, delta_loss = -2.940502, learn_rate = 1.5067226E-15
[DEBUG] 2018-05-22 11:38:44,694 -- BPR fold [10] iter 171: loss = 363.7271, delta_loss = 4.089965, learn_rate = 3.0351464E-17
[DEBUG] 2018-05-22 11:38:44,724 -- BPR fold [2] iter 175: loss = 326.86823, delta_loss = 0.1609341, learn_rate = 1.5067226E-15
[DEBUG] 2018-05-22 11:38:44,738 -- BPR fold [7] iter 176: loss = 311.43158, delta_loss = 0.68328655, learn_rate = 1.7083023E-16
[DEBUG] 2018-05-22 11:38:44,745 -- BPR fold [3] iter 177: loss = 284.91473, delta_loss = 4.6573973, learn_rate = 1.5384019E-14
[DEBUG] 2018-05-22 11:38:44,754 -- BPR fold [4] iter 175: loss = 364.28952, delta_loss = 2.3594875, learn_rate = 1.8969665E-18
[DEBUG] 2018-05-22 11:38:44,768 -- BPR fold [8] iter 175: loss = 311.08286, delta_loss = -2.3276334, learn_rate = 7.747403E-17
[DEBUG] 2018-05-22 11:38:44,778 -- BPR fold [5] iter 177: loss = 281.2171, delta_loss = 1.9468572, learn_rate = 6.7843524E-14
[DEBUG] 2018-05-22 11:38:44,802 -- BPR fold [1] iter 176: loss = 368.2772, delta_loss = -8.313271, learn_rate = 7.533613E-16
[DEBUG] 2018-05-22 11:38:44,855 -- BPR fold [10] iter 172: loss = 366.1976, delta_loss = -2.470488, learn_rate = 3.1869036E-17
[DEBUG] 2018-05-22 11:38:44,863 -- BPR fold [9] iter 177: loss = 305.05075, delta_loss = -4.033643, learn_rate = 4.0673864E-17
[DEBUG] 2018-05-22 11:38:44,914 -- BPR fold [6] iter 176: loss = 337.1012, delta_loss = -0.34888, learn_rate = 7.533613E-16
[DEBUG] 2018-05-22 11:38:44,936 -- BPR fold [7] iter 177: loss = 312.2458, delta_loss = -0.81421506, learn_rate = 1.7937175E-16
[DEBUG] 2018-05-22 11:38:44,942 -- BPR fold [2] iter 176: loss = 324.78323, delta_loss = 2.084992, learn_rate = 1.5820588E-15
[DEBUG] 2018-05-22 11:38:44,945 -- BPR fold [3] iter 178: loss = 288.8155, delta_loss = -3.9007785, learn_rate = 1.615322E-14
[DEBUG] 2018-05-22 11:38:44,946 -- BPR fold [4] iter 176: loss = 368.89462, delta_loss = -4.60509, learn_rate = 1.9918147E-18
[DEBUG] 2018-05-22 11:38:44,952 -- BPR fold [8] iter 176: loss = 311.2364, delta_loss = -0.1535474, learn_rate = 3.8737014E-17
[DEBUG] 2018-05-22 11:38:44,967 -- BPR fold [5] iter 178: loss = 283.05396, delta_loss = -1.8368621, learn_rate = 7.12357E-14
[DEBUG] 2018-05-22 11:38:45,034 -- BPR fold [1] iter 177: loss = 365.59778, delta_loss = 2.679431, learn_rate = 3.7668066E-16
[DEBUG] 2018-05-22 11:38:45,073 -- BPR fold [9] iter 178: loss = 302.27902, delta_loss = 2.771745, learn_rate = 2.0336932E-17
[DEBUG] 2018-05-22 11:38:45,123 -- BPR fold [6] iter 177: loss = 337.34427, delta_loss = -0.24307811, learn_rate = 3.7668066E-16
[DEBUG] 2018-05-22 11:38:45,128 -- BPR fold [10] iter 173: loss = 361.9898, delta_loss = 4.2077756, learn_rate = 1.5934518E-17
[DEBUG] 2018-05-22 11:38:45,148 -- BPR fold [4] iter 177: loss = 366.40125, delta_loss = 2.4933717, learn_rate = 9.959074E-19
[DEBUG] 2018-05-22 11:38:45,151 -- BPR fold [3] iter 179: loss = 282.75705, delta_loss = 6.058457, learn_rate = 8.07661E-15
[DEBUG] 2018-05-22 11:38:45,168 -- BPR fold [2] iter 177: loss = 329.01758, delta_loss = -4.2343445, learn_rate = 1.6611617E-15
[DEBUG] 2018-05-22 11:38:45,191 -- BPR fold [7] iter 178: loss = 310.37555, delta_loss = 1.8702501, learn_rate = 8.9685873E-17
[DEBUG] 2018-05-22 11:38:45,199 -- BPR fold [8] iter 177: loss = 309.75806, delta_loss = 1.478336, learn_rate = 1.9368507E-17
[DEBUG] 2018-05-22 11:38:45,252 -- BPR fold [5] iter 179: loss = 284.6983, delta_loss = -1.6443567, learn_rate = 3.561785E-14
[DEBUG] 2018-05-22 11:38:45,255 -- BPR fold [1] iter 178: loss = 360.4661, delta_loss = 5.1316643, learn_rate = 3.955147E-16
[DEBUG] 2018-05-22 11:38:45,311 -- BPR fold [9] iter 179: loss = 303.59613, delta_loss = -1.3171176, learn_rate = 2.1353778E-17
[DEBUG] 2018-05-22 11:38:45,384 -- BPR fold [3] iter 180: loss = 285.64368, delta_loss = -2.8866246, learn_rate = 8.4804405E-15
[DEBUG] 2018-05-22 11:38:45,398 -- BPR fold [10] iter 174: loss = 364.99036, delta_loss = -3.0005548, learn_rate = 1.6731245E-17
[DEBUG] 2018-05-22 11:38:45,402 -- BPR fold [6] iter 178: loss = 336.70068, delta_loss = 0.643573, learn_rate = 1.8834033E-16
[DEBUG] 2018-05-22 11:38:45,418 -- BPR fold [2] iter 178: loss = 323.95496, delta_loss = 5.0626416, learn_rate = 8.3058087E-16
[DEBUG] 2018-05-22 11:38:45,432 -- BPR fold [8] iter 178: loss = 309.0268, delta_loss = 0.7312565, learn_rate = 2.0336932E-17
[DEBUG] 2018-05-22 11:38:45,443 -- BPR fold [7] iter 179: loss = 307.32077, delta_loss = 3.0547595, learn_rate = 9.4170165E-17
[DEBUG] 2018-05-22 11:38:45,453 -- BPR fold [4] iter 178: loss = 360.74646, delta_loss = 5.6547747, learn_rate = 1.0457028E-18
[DEBUG] 2018-05-22 11:38:45,489 -- BPR fold [1] iter 179: loss = 363.7638, delta_loss = -3.2976863, learn_rate = 4.1529043E-16
[DEBUG] 2018-05-22 11:38:45,527 -- BPR fold [5] iter 180: loss = 283.90445, delta_loss = 0.7938654, learn_rate = 1.7808925E-14
[DEBUG] 2018-05-22 11:38:45,589 -- BPR fold [9] iter 180: loss = 302.8233, delta_loss = 0.7728124, learn_rate = 1.0676889E-17
[DEBUG] 2018-05-22 11:38:45,653 -- BPR fold [10] iter 175: loss = 365.41403, delta_loss = -0.42365536, learn_rate = 8.3656225E-18
[DEBUG] 2018-05-22 11:38:45,656 -- BPR fold [6] iter 179: loss = 338.4969, delta_loss = -1.7962033, learn_rate = 1.9775735E-16
[DEBUG] 2018-05-22 11:38:45,656 -- BPR fold [2] iter 179: loss = 328.51752, delta_loss = -4.562577, learn_rate = 8.721099E-16
[DEBUG] 2018-05-22 11:38:45,668 -- BPR fold [3] iter 181: loss = 285.4679, delta_loss = 0.17578694, learn_rate = 4.2402203E-15
[DEBUG] 2018-05-22 11:38:45,676 -- BPR fold [4] iter 179: loss = 366.11652, delta_loss = -5.370043, learn_rate = 1.097988E-18
[DEBUG] 2018-05-22 11:38:45,688 -- BPR fold [7] iter 180: loss = 308.3395, delta_loss = -1.0187267, learn_rate = 9.8878676E-17
[DEBUG] 2018-05-22 11:38:45,708 -- BPR fold [8] iter 179: loss = 315.60983, delta_loss = -6.583042, learn_rate = 2.1353778E-17
[DEBUG] 2018-05-22 11:38:45,747 -- BPR fold [5] iter 181: loss = 281.24414, delta_loss = 2.6602926, learn_rate = 1.869937E-14
[DEBUG] 2018-05-22 11:38:45,747 -- BPR fold [1] iter 180: loss = 369.1149, delta_loss = -5.3511286, learn_rate = 2.0764522E-16
[DEBUG] 2018-05-22 11:38:45,841 -- BPR fold [9] iter 181: loss = 300.04596, delta_loss = 2.7773583, learn_rate = 1.1210734E-17
[DEBUG] 2018-05-22 11:38:45,875 -- BPR fold [2] iter 180: loss = 327.20035, delta_loss = 1.3171682, learn_rate = 4.3605494E-16
[DEBUG] 2018-05-22 11:38:45,878 -- BPR fold [6] iter 180: loss = 336.52188, delta_loss = 1.9749973, learn_rate = 9.8878676E-17
[DEBUG] 2018-05-22 11:38:45,889 -- BPR fold [10] iter 176: loss = 364.55237, delta_loss = 0.86165476, learn_rate = 4.1828112E-18
[DEBUG] 2018-05-22 11:38:45,895 -- BPR fold [3] iter 182: loss = 284.45996, delta_loss = 1.0079191, learn_rate = 4.4522313E-15
[DEBUG] 2018-05-22 11:38:45,900 -- BPR fold [4] iter 180: loss = 367.53168, delta_loss = -1.4151757, learn_rate = 5.48994E-19
[DEBUG] 2018-05-22 11:38:45,925 -- BPR fold [8] iter 180: loss = 312.45935, delta_loss = 3.1504936, learn_rate = 1.0676889E-17
[DEBUG] 2018-05-22 11:38:45,954 -- BPR fold [7] iter 181: loss = 307.89874, delta_loss = 0.44077012, learn_rate = 4.9439338E-17
[DEBUG] 2018-05-22 11:38:45,978 -- BPR fold [5] iter 182: loss = 282.337, delta_loss = -1.0928487, learn_rate = 1.9634339E-14
[DEBUG] 2018-05-22 11:38:45,984 -- BPR fold [1] iter 181: loss = 366.755, delta_loss = 2.3599079, learn_rate = 1.0382261E-16
[DEBUG] 2018-05-22 11:38:46,041 -- BPR fold [9] iter 182: loss = 303.09982, delta_loss = -3.0538752, learn_rate = 1.1771271E-17
[DEBUG] 2018-05-22 11:38:46,094 -- BPR fold [10] iter 177: loss = 365.4917, delta_loss = -0.93933547, learn_rate = 4.391952E-18
[DEBUG] 2018-05-22 11:38:46,102 -- BPR fold [2] iter 181: loss = 325.5249, delta_loss = 1.6754413, learn_rate = 4.578577E-16
[DEBUG] 2018-05-22 11:38:46,123 -- BPR fold [6] iter 181: loss = 340.99036, delta_loss = -4.4684687, learn_rate = 1.0382261E-16
[DEBUG] 2018-05-22 11:38:46,128 -- BPR fold [8] iter 181: loss = 307.66357, delta_loss = 4.7957773, learn_rate = 1.1210734E-17
[DEBUG] 2018-05-22 11:38:46,136 -- BPR fold [3] iter 183: loss = 287.4192, delta_loss = -2.9592178, learn_rate = 4.6748426E-15
[DEBUG] 2018-05-22 11:38:46,157 -- BPR fold [4] iter 181: loss = 368.96106, delta_loss = -1.4293866, learn_rate = 2.74497E-19
[DEBUG] 2018-05-22 11:38:46,226 -- BPR fold [7] iter 182: loss = 306.53607, delta_loss = 1.3626715, learn_rate = 5.1911304E-17
[DEBUG] 2018-05-22 11:38:46,236 -- BPR fold [1] iter 182: loss = 368.3978, delta_loss = -1.6427953, learn_rate = 1.09013736E-16
[DEBUG] 2018-05-22 11:38:46,255 -- BPR fold [5] iter 183: loss = 282.68472, delta_loss = -0.3477102, learn_rate = 9.8171695E-15
[DEBUG] 2018-05-22 11:38:46,372 -- BPR fold [9] iter 183: loss = 303.17358, delta_loss = -0.07376613, learn_rate = 5.8856353E-18
[DEBUG] 2018-05-22 11:38:46,435 -- BPR fold [8] iter 182: loss = 311.39264, delta_loss = -3.7290807, learn_rate = 1.1771271E-17
[DEBUG] 2018-05-22 11:38:46,440 -- BPR fold [6] iter 182: loss = 336.10187, delta_loss = 4.888493, learn_rate = 5.1911304E-17
[DEBUG] 2018-05-22 11:38:46,450 -- BPR fold [2] iter 182: loss = 325.91742, delta_loss = -0.39251527, learn_rate = 4.807506E-16
[DEBUG] 2018-05-22 11:38:46,450 -- BPR fold [10] iter 178: loss = 362.96506, delta_loss = 2.5266488, learn_rate = 2.195976E-18
[DEBUG] 2018-05-22 11:38:46,456 -- BPR fold [4] iter 182: loss = 369.13788, delta_loss = -0.17679574, learn_rate = 1.372485E-19
[DEBUG] 2018-05-22 11:38:46,474 -- BPR fold [3] iter 184: loss = 284.49478, delta_loss = 2.9244041, learn_rate = 2.3374213E-15
[DEBUG] 2018-05-22 11:38:46,569 -- BPR fold [1] iter 183: loss = 361.3943, delta_loss = 7.003502, learn_rate = 5.4506868E-17
[DEBUG] 2018-05-22 11:38:46,584 -- BPR fold [7] iter 183: loss = 311.5156, delta_loss = -4.979517, learn_rate = 5.4506868E-17
[DEBUG] 2018-05-22 11:38:46,601 -- BPR fold [5] iter 184: loss = 282.91312, delta_loss = -0.22841087, learn_rate = 4.9085847E-15
[DEBUG] 2018-05-22 11:38:46,687 -- BPR fold [9] iter 184: loss = 306.75403, delta_loss = -3.5804412, learn_rate = 2.9428177E-18
[DEBUG] 2018-05-22 11:38:46,720 -- BPR fold [10] iter 179: loss = 367.36917, delta_loss = -4.4041157, learn_rate = 2.3057746E-18
[DEBUG] 2018-05-22 11:38:46,746 -- BPR fold [2] iter 183: loss = 328.7506, delta_loss = -2.833182, learn_rate = 2.403753E-16
[DEBUG] 2018-05-22 11:38:46,747 -- BPR fold [8] iter 183: loss = 313.37668, delta_loss = -1.984013, learn_rate = 5.8856353E-18
[DEBUG] 2018-05-22 11:38:46,754 -- BPR fold [3] iter 185: loss = 282.94147, delta_loss = 1.5532938, learn_rate = 2.4542924E-15
[DEBUG] 2018-05-22 11:38:46,769 -- BPR fold [4] iter 183: loss = 371.04306, delta_loss = -1.9051957, learn_rate = 6.862425E-20
[DEBUG] 2018-05-22 11:38:46,805 -- BPR fold [6] iter 183: loss = 339.6776, delta_loss = -3.575748, learn_rate = 5.4506868E-17
[DEBUG] 2018-05-22 11:38:46,870 -- BPR fold [1] iter 184: loss = 374.79007, delta_loss = -13.395761, learn_rate = 5.723221E-17
[DEBUG] 2018-05-22 11:38:46,881 -- BPR fold [7] iter 184: loss = 308.35123, delta_loss = 3.1643434, learn_rate = 2.7253434E-17
[DEBUG] 2018-05-22 11:38:46,888 -- BPR fold [5] iter 185: loss = 282.90112, delta_loss = 0.012002085, learn_rate = 2.4542924E-15
[DEBUG] 2018-05-22 11:38:46,955 -- BPR fold [9] iter 185: loss = 302.4588, delta_loss = 4.295234, learn_rate = 1.4714088E-18
[DEBUG] 2018-05-22 11:38:46,957 -- BPR fold [8] iter 184: loss = 311.4434, delta_loss = 1.9332813, learn_rate = 2.9428177E-18
[DEBUG] 2018-05-22 11:38:46,969 -- BPR fold [2] iter 184: loss = 326.77332, delta_loss = 1.9772978, learn_rate = 1.2018765E-16
[DEBUG] 2018-05-22 11:38:46,980 -- BPR fold [3] iter 186: loss = 287.74292, delta_loss = -4.8014336, learn_rate = 2.5770071E-15
[DEBUG] 2018-05-22 11:38:46,983 -- BPR fold [10] iter 180: loss = 360.14786, delta_loss = 7.2213073, learn_rate = 1.1528873E-18
[DEBUG] 2018-05-22 11:38:46,988 -- BPR fold [4] iter 184: loss = 368.37494, delta_loss = 2.6681306, learn_rate = 3.4312124E-20
[DEBUG] 2018-05-22 11:38:47,034 -- BPR fold [6] iter 184: loss = 331.23984, delta_loss = 8.437786, learn_rate = 2.7253434E-17
[DEBUG] 2018-05-22 11:38:47,080 -- BPR fold [7] iter 185: loss = 307.34558, delta_loss = 1.0056642, learn_rate = 2.8616105E-17
[DEBUG] 2018-05-22 11:38:47,084 -- BPR fold [1] iter 185: loss = 362.89172, delta_loss = 11.89833, learn_rate = 2.8616105E-17
[DEBUG] 2018-05-22 11:38:47,092 -- BPR fold [5] iter 186: loss = 279.3655, delta_loss = 3.5356228, learn_rate = 2.5770071E-15
[DEBUG] 2018-05-22 11:38:47,160 -- BPR fold [2] iter 185: loss = 334.80176, delta_loss = -8.028435, learn_rate = 1.2619703E-16
[DEBUG] 2018-05-22 11:38:47,161 -- BPR fold [9] iter 186: loss = 304.95523, delta_loss = -2.4964185, learn_rate = 1.5449793E-18
[DEBUG] 2018-05-22 11:38:47,164 -- BPR fold [8] iter 185: loss = 311.5752, delta_loss = -0.13182324, learn_rate = 3.0899586E-18
[DEBUG] 2018-05-22 11:38:47,204 -- BPR fold [3] iter 187: loss = 284.61716, delta_loss = 3.125769, learn_rate = 1.2885036E-15
[DEBUG] 2018-05-22 11:38:47,209 -- BPR fold [10] iter 181: loss = 363.8165, delta_loss = -3.6686323, learn_rate = 1.2105317E-18
[DEBUG] 2018-05-22 11:38:47,209 -- BPR fold [4] iter 185: loss = 363.7706, delta_loss = 4.60433, learn_rate = 3.602773E-20
[DEBUG] 2018-05-22 11:38:47,227 -- BPR fold [6] iter 185: loss = 335.2471, delta_loss = -4.007254, learn_rate = 2.8616105E-17
[DEBUG] 2018-05-22 11:38:47,267 -- BPR fold [1] iter 186: loss = 372.1268, delta_loss = -9.235085, learn_rate = 3.0046912E-17
[DEBUG] 2018-05-22 11:38:47,283 -- BPR fold [7] iter 186: loss = 307.9785, delta_loss = -0.6329151, learn_rate = 3.0046912E-17
[DEBUG] 2018-05-22 11:38:47,285 -- BPR fold [5] iter 187: loss = 286.08182, delta_loss = -6.7163215, learn_rate = 2.7058573E-15
[DEBUG] 2018-05-22 11:38:47,346 -- BPR fold [9] iter 187: loss = 303.03244, delta_loss = 1.9227855, learn_rate = 7.7248965E-19
[DEBUG] 2018-05-22 11:38:47,356 -- BPR fold [2] iter 186: loss = 328.04904, delta_loss = 6.7526965, learn_rate = 6.3098515E-17
[DEBUG] 2018-05-22 11:38:47,386 -- BPR fold [8] iter 186: loss = 314.42673, delta_loss = -2.8515337, learn_rate = 1.5449793E-18
[DEBUG] 2018-05-22 11:38:47,402 -- BPR fold [4] iter 186: loss = 370.1701, delta_loss = -6.3995113, learn_rate = 3.7829115E-20
[DEBUG] 2018-05-22 11:38:47,406 -- BPR fold [3] iter 188: loss = 288.16458, delta_loss = -3.547432, learn_rate = 1.3529287E-15
[DEBUG] 2018-05-22 11:38:47,417 -- BPR fold [10] iter 182: loss = 368.0889, delta_loss = -4.2723866, learn_rate = 6.0526584E-19
[DEBUG] 2018-05-22 11:38:47,433 -- BPR fold [6] iter 186: loss = 337.76892, delta_loss = -2.5218248, learn_rate = 1.4308052E-17
[DEBUG] 2018-05-22 11:38:47,458 -- BPR fold [1] iter 187: loss = 364.2699, delta_loss = 7.856928, learn_rate = 1.5023456E-17
[DEBUG] 2018-05-22 11:38:47,504 -- BPR fold [5] iter 188: loss = 282.86765, delta_loss = 3.2141757, learn_rate = 1.3529287E-15
[DEBUG] 2018-05-22 11:38:47,523 -- BPR fold [7] iter 187: loss = 307.78824, delta_loss = 0.19023807, learn_rate = 1.5023456E-17
[DEBUG] 2018-05-22 11:38:47,570 -- BPR fold [9] iter 188: loss = 303.88095, delta_loss = -0.8485276, learn_rate = 8.1111413E-19
[DEBUG] 2018-05-22 11:38:47,587 -- BPR fold [2] iter 187: loss = 323.10574, delta_loss = 4.943312, learn_rate = 6.625344E-17
[DEBUG] 2018-05-22 11:38:47,597 -- BPR fold [8] iter 187: loss = 311.01147, delta_loss = 3.4152627, learn_rate = 7.7248965E-19
[DEBUG] 2018-05-22 11:38:47,624 -- BPR fold [3] iter 189: loss = 285.31107, delta_loss = 2.8535223, learn_rate = 6.7646433E-16
[DEBUG] 2018-05-22 11:38:47,634 -- BPR fold [6] iter 187: loss = 333.5952, delta_loss = 4.173703, learn_rate = 7.154026E-18
[DEBUG] 2018-05-22 11:38:47,640 -- BPR fold [4] iter 187: loss = 361.86737, delta_loss = 8.302738, learn_rate = 1.8914557E-20
[DEBUG] 2018-05-22 11:38:47,641 -- BPR fold [10] iter 183: loss = 371.0687, delta_loss = -2.9798183, learn_rate = 3.0263292E-19
[DEBUG] 2018-05-22 11:38:47,698 -- BPR fold [1] iter 188: loss = 365.29733, delta_loss = -1.0274475, learn_rate = 1.5774629E-17
[DEBUG] 2018-05-22 11:38:47,724 -- BPR fold [5] iter 189: loss = 285.4881, delta_loss = -2.6204438, learn_rate = 1.4205752E-15
[DEBUG] 2018-05-22 11:38:47,745 -- BPR fold [7] iter 188: loss = 309.4844, delta_loss = -1.6961559, learn_rate = 1.5774629E-17
[DEBUG] 2018-05-22 11:38:47,783 -- BPR fold [2] iter 188: loss = 325.2936, delta_loss = -2.1878614, learn_rate = 6.9566115E-17
[DEBUG] 2018-05-22 11:38:47,799 -- BPR fold [9] iter 189: loss = 300.38736, delta_loss = 3.4935963, learn_rate = 4.0555706E-19
[DEBUG] 2018-05-22 11:38:47,810 -- BPR fold [8] iter 188: loss = 316.1232, delta_loss = -5.1117096, learn_rate = 8.1111413E-19
[DEBUG] 2018-05-22 11:38:47,853 -- BPR fold [10] iter 184: loss = 362.7198, delta_loss = 8.34892, learn_rate = 1.5131646E-19
[DEBUG] 2018-05-22 11:38:47,866 -- BPR fold [4] iter 188: loss = 369.0008, delta_loss = -7.133411, learn_rate = 1.9860285E-20
[DEBUG] 2018-05-22 11:38:47,875 -- BPR fold [3] iter 190: loss = 286.32904, delta_loss = -1.0179988, learn_rate = 7.102876E-16
[DEBUG] 2018-05-22 11:38:47,883 -- BPR fold [6] iter 188: loss = 338.78827, delta_loss = -5.1930666, learn_rate = 7.511728E-18
[DEBUG] 2018-05-22 11:38:47,968 -- BPR fold [5] iter 190: loss = 281.0482, delta_loss = 4.439896, learn_rate = 7.102876E-16
[DEBUG] 2018-05-22 11:38:47,969 -- BPR fold [1] iter 189: loss = 367.75644, delta_loss = -2.459102, learn_rate = 7.887314E-18
[DEBUG] 2018-05-22 11:38:47,986 -- BPR fold [7] iter 189: loss = 309.11008, delta_loss = 0.3743332, learn_rate = 7.887314E-18
[DEBUG] 2018-05-22 11:38:48,055 -- BPR fold [8] iter 189: loss = 312.43808, delta_loss = 3.6850982, learn_rate = 4.0555706E-19
[DEBUG] 2018-05-22 11:38:48,076 -- BPR fold [9] iter 190: loss = 300.32925, delta_loss = 0.058099538, learn_rate = 4.258349E-19
[DEBUG] 2018-05-22 11:38:48,096 -- BPR fold [2] iter 189: loss = 326.0738, delta_loss = -0.7801791, learn_rate = 3.4783057E-17
[DEBUG] 2018-05-22 11:38:48,128 -- BPR fold [4] iter 189: loss = 363.5067, delta_loss = 5.4940825, learn_rate = 9.9301425E-21
[DEBUG] 2018-05-22 11:38:48,136 -- BPR fold [3] iter 191: loss = 285.24176, delta_loss = 1.0873089, learn_rate = 3.551438E-16
[DEBUG] 2018-05-22 11:38:48,179 -- BPR fold [6] iter 189: loss = 340.7947, delta_loss = -2.0064445, learn_rate = 3.755864E-18
[DEBUG] 2018-05-22 11:38:48,208 -- BPR fold [10] iter 185: loss = 366.67258, delta_loss = -3.9527912, learn_rate = 1.5888228E-19
[DEBUG] 2018-05-22 11:38:48,237 -- BPR fold [1] iter 190: loss = 369.121, delta_loss = -1.3645635, learn_rate = 3.943657E-18
[DEBUG] 2018-05-22 11:38:48,249 -- BPR fold [5] iter 191: loss = 283.93005, delta_loss = -2.881874, learn_rate = 7.458019E-16
[DEBUG] 2018-05-22 11:38:48,267 -- BPR fold [7] iter 190: loss = 305.87704, delta_loss = 3.233018, learn_rate = 8.28168E-18
[DEBUG] 2018-05-22 11:38:48,307 -- BPR fold [9] iter 191: loss = 304.24905, delta_loss = -3.9197764, learn_rate = 4.4712664E-19
[DEBUG] 2018-05-22 11:38:48,310 -- BPR fold [8] iter 190: loss = 310.88974, delta_loss = 1.548341, learn_rate = 4.258349E-19
[DEBUG] 2018-05-22 11:38:48,336 -- BPR fold [2] iter 190: loss = 328.946, delta_loss = -2.8722396, learn_rate = 1.7391529E-17
[DEBUG] 2018-05-22 11:38:48,363 -- BPR fold [3] iter 192: loss = 288.79376, delta_loss = -3.5520315, learn_rate = 3.7290096E-16
[DEBUG] 2018-05-22 11:38:48,373 -- BPR fold [4] iter 190: loss = 366.82635, delta_loss = -3.3196359, learn_rate = 1.04266496E-20
[DEBUG] 2018-05-22 11:38:48,401 -- BPR fold [10] iter 186: loss = 368.4718, delta_loss = -1.7992375, learn_rate = 7.944114E-20
[DEBUG] 2018-05-22 11:38:48,418 -- BPR fold [6] iter 190: loss = 335.80682, delta_loss = 4.987898, learn_rate = 1.877932E-18
[DEBUG] 2018-05-22 11:38:48,456 -- BPR fold [7] iter 191: loss = 313.34134, delta_loss = -7.4642878, learn_rate = 8.695764E-18
[DEBUG] 2018-05-22 11:38:48,471 -- BPR fold [1] iter 191: loss = 362.16025, delta_loss = 6.960759, learn_rate = 1.9718286E-18
[DEBUG] 2018-05-22 11:38:48,472 -- BPR fold [5] iter 192: loss = 282.95142, delta_loss = 0.9786526, learn_rate = 3.7290096E-16
[DEBUG] 2018-05-22 11:38:48,529 -- BPR fold [8] iter 191: loss = 310.37924, delta_loss = 0.51049566, learn_rate = 4.4712664E-19
[DEBUG] 2018-05-22 11:38:48,535 -- BPR fold [9] iter 192: loss = 303.51974, delta_loss = 0.72929436, learn_rate = 2.2356332E-19
[DEBUG] 2018-05-22 11:38:48,583 -- BPR fold [2] iter 191: loss = 323.02597, delta_loss = 5.9200635, learn_rate = 8.695764E-18
[DEBUG] 2018-05-22 11:38:48,603 -- BPR fold [3] iter 193: loss = 287.09872, delta_loss = 1.695046, learn_rate = 1.8645048E-16
[DEBUG] 2018-05-22 11:38:48,619 -- BPR fold [6] iter 191: loss = 336.17526, delta_loss = -0.36844465, learn_rate = 1.9718286E-18
[DEBUG] 2018-05-22 11:38:48,623 -- BPR fold [4] iter 191: loss = 367.6483, delta_loss = -0.82194716, learn_rate = 5.2133248E-21
[DEBUG] 2018-05-22 11:38:48,647 -- BPR fold [10] iter 187: loss = 368.08914, delta_loss = 0.382668, learn_rate = 3.972057E-20
[DEBUG] 2018-05-22 11:38:48,657 -- BPR fold [1] iter 192: loss = 361.06, delta_loss = 1.1002407, learn_rate = 2.07042E-18
[DEBUG] 2018-05-22 11:38:48,673 -- BPR fold [7] iter 192: loss = 307.71265, delta_loss = 5.628698, learn_rate = 4.347882E-18
[DEBUG] 2018-05-22 11:38:48,699 -- BPR fold [5] iter 193: loss = 282.25256, delta_loss = 0.6988395, learn_rate = 3.91546E-16
[DEBUG] 2018-05-22 11:38:48,755 -- BPR fold [8] iter 192: loss = 309.7624, delta_loss = 0.6168596, learn_rate = 4.69483E-19
[DEBUG] 2018-05-22 11:38:48,772 -- BPR fold [9] iter 193: loss = 299.98865, delta_loss = 3.531111, learn_rate = 2.347415E-19
[DEBUG] 2018-05-22 11:38:48,795 -- BPR fold [2] iter 192: loss = 323.44678, delta_loss = -0.42080832, learn_rate = 9.130552E-18
[DEBUG] 2018-05-22 11:38:48,807 -- BPR fold [3] iter 194: loss = 287.08298, delta_loss = 0.01574028, learn_rate = 1.95773E-16
[DEBUG] 2018-05-22 11:38:48,850 -- BPR fold [6] iter 192: loss = 337.47073, delta_loss = -1.2954718, learn_rate = 9.859143E-19
[DEBUG] 2018-05-22 11:38:48,858 -- BPR fold [4] iter 192: loss = 359.48892, delta_loss = 8.159378, learn_rate = 2.6066624E-21
[DEBUG] 2018-05-22 11:38:48,876 -- BPR fold [10] iter 188: loss = 362.87918, delta_loss = 5.2099586, learn_rate = 4.1706598E-20
[DEBUG] 2018-05-22 11:38:48,897 -- BPR fold [7] iter 193: loss = 310.55804, delta_loss = -2.8454032, learn_rate = 4.565276E-18
[DEBUG] 2018-05-22 11:38:48,899 -- BPR fold [1] iter 193: loss = 365.9587, delta_loss = -4.898711, learn_rate = 2.173941E-18
[DEBUG] 2018-05-22 11:38:48,934 -- BPR fold [5] iter 194: loss = 284.71872, delta_loss = -2.4661467, learn_rate = 4.1112332E-16
[DEBUG] 2018-05-22 11:38:48,959 -- BPR fold [9] iter 194: loss = 301.06528, delta_loss = -1.0766318, learn_rate = 2.4647857E-19
[DEBUG] 2018-05-22 11:38:48,974 -- BPR fold [8] iter 193: loss = 307.50238, delta_loss = 2.2600229, learn_rate = 4.9295715E-19
[DEBUG] 2018-05-22 11:38:49,005 -- BPR fold [2] iter 193: loss = 327.15118, delta_loss = -3.7044122, learn_rate = 4.565276E-18
[DEBUG] 2018-05-22 11:38:49,011 -- BPR fold [3] iter 195: loss = 284.71216, delta_loss = 2.3708405, learn_rate = 2.0556166E-16
[DEBUG] 2018-05-22 11:38:49,044 -- BPR fold [6] iter 193: loss = 339.53397, delta_loss = -2.0632274, learn_rate = 4.9295715E-19
[DEBUG] 2018-05-22 11:38:49,058 -- BPR fold [4] iter 193: loss = 369.2723, delta_loss = -9.783401, learn_rate = 2.7369956E-21
[DEBUG] 2018-05-22 11:38:49,084 -- BPR fold [10] iter 189: loss = 366.72427, delta_loss = -3.845101, learn_rate = 4.379193E-20
[DEBUG] 2018-05-22 11:38:49,094 -- BPR fold [1] iter 194: loss = 369.51843, delta_loss = -3.5597212, learn_rate = 1.0869705E-18
[DEBUG] 2018-05-22 11:38:49,102 -- BPR fold [7] iter 194: loss = 311.46783, delta_loss = -0.9097899, learn_rate = 2.282638E-18
[DEBUG] 2018-05-22 11:38:49,130 -- BPR fold [5] iter 195: loss = 281.46753, delta_loss = 3.2511876, learn_rate = 2.0556166E-16
[DEBUG] 2018-05-22 11:38:49,162 -- BPR fold [8] iter 194: loss = 309.5502, delta_loss = -2.0478356, learn_rate = 5.17605E-19
[DEBUG] 2018-05-22 11:38:49,204 -- BPR fold [9] iter 195: loss = 308.68338, delta_loss = -7.618103, learn_rate = 1.2323929E-19
[DEBUG] 2018-05-22 11:38:49,232 -- BPR fold [3] iter 196: loss = 285.5158, delta_loss = -0.80366284, learn_rate = 2.1583974E-16
[DEBUG] 2018-05-22 11:38:49,233 -- BPR fold [2] iter 194: loss = 325.5169, delta_loss = 1.634287, learn_rate = 2.282638E-18
[DEBUG] 2018-05-22 11:38:49,291 -- BPR fold [4] iter 194: loss = 360.86658, delta_loss = 8.405719, learn_rate = 1.3684978E-21
[DEBUG] 2018-05-22 11:38:49,294 -- BPR fold [6] iter 194: loss = 339.27396, delta_loss = 0.25999808, learn_rate = 2.4647857E-19
[DEBUG] 2018-05-22 11:38:49,321 -- BPR fold [10] iter 190: loss = 365.59854, delta_loss = 1.1257465, learn_rate = 2.1895965E-20
[DEBUG] 2018-05-22 11:38:49,396 -- BPR fold [7] iter 195: loss = 305.14578, delta_loss = 6.3220587, learn_rate = 1.141319E-18
[DEBUG] 2018-05-22 11:38:49,402 -- BPR fold [1] iter 195: loss = 364.40134, delta_loss = 5.117094, learn_rate = 5.4348527E-19
[DEBUG] 2018-05-22 11:38:49,412 -- BPR fold [5] iter 196: loss = 280.60266, delta_loss = 0.8648658, learn_rate = 2.1583974E-16
[DEBUG] 2018-05-22 11:38:49,436 -- BPR fold [8] iter 195: loss = 315.0339, delta_loss = -5.483705, learn_rate = 2.588025E-19
[DEBUG] 2018-05-22 11:38:49,507 -- BPR fold [9] iter 196: loss = 303.55716, delta_loss = 5.12621, learn_rate = 6.1619644E-20
[DEBUG] 2018-05-22 11:38:49,540 -- BPR fold [2] iter 195: loss = 325.96902, delta_loss = -0.45213267, learn_rate = 2.3967699E-18
[DEBUG] 2018-05-22 11:38:49,569 -- BPR fold [3] iter 197: loss = 286.28384, delta_loss = -0.7680445, learn_rate = 1.0791987E-16
[DEBUG] 2018-05-22 11:38:49,596 -- BPR fold [6] iter 195: loss = 337.53098, delta_loss = 1.7430048, learn_rate = 2.588025E-19
[DEBUG] 2018-05-22 11:38:49,618 -- BPR fold [4] iter 195: loss = 365.0637, delta_loss = -4.1971126, learn_rate = 1.4369227E-21
[DEBUG] 2018-05-22 11:38:49,650 -- BPR fold [10] iter 191: loss = 363.0304, delta_loss = 2.5681527, learn_rate = 2.2990763E-20
[DEBUG] 2018-05-22 11:38:49,686 -- BPR fold [1] iter 196: loss = 354.90775, delta_loss = 9.493581, learn_rate = 5.706595E-19
[DEBUG] 2018-05-22 11:38:49,721 -- BPR fold [7] iter 196: loss = 307.86646, delta_loss = -2.7206635, learn_rate = 1.1983849E-18
[DEBUG] 2018-05-22 11:38:49,785 -- BPR fold [8] iter 196: loss = 310.7114, delta_loss = 4.32253, learn_rate = 1.2940125E-19
[DEBUG] 2018-05-22 11:38:49,791 -- BPR fold [5] iter 197: loss = 283.14383, delta_loss = -2.5411644, learn_rate = 2.2663174E-16
[DEBUG] 2018-05-22 11:38:49,882 -- BPR fold [9] iter 197: loss = 302.84637, delta_loss = 0.7107824, learn_rate = 6.4700626E-20
[DEBUG] 2018-05-22 11:38:49,888 -- BPR fold [2] iter 196: loss = 325.3527, delta_loss = 0.61633503, learn_rate = 1.1983849E-18
[DEBUG] 2018-05-22 11:38:49,893 -- BPR fold [3] iter 198: loss = 284.60022, delta_loss = 1.683642, learn_rate = 5.3959936E-17
[DEBUG] 2018-05-22 11:38:49,916 -- BPR fold [6] iter 196: loss = 335.09305, delta_loss = 2.4379168, learn_rate = 2.7174263E-19
[DEBUG] 2018-05-22 11:38:49,938 -- BPR fold [4] iter 196: loss = 369.17868, delta_loss = -4.114991, learn_rate = 7.1846134E-22
[DEBUG] 2018-05-22 11:38:49,958 -- BPR fold [10] iter 192: loss = 370.82224, delta_loss = -7.7918563, learn_rate = 2.4140302E-20
[DEBUG] 2018-05-22 11:38:49,973 -- BPR fold [1] iter 197: loss = 362.25818, delta_loss = -7.3504353, learn_rate = 5.9919247E-19
[DEBUG] 2018-05-22 11:38:49,992 -- BPR fold [7] iter 197: loss = 310.72623, delta_loss = -2.8597746, learn_rate = 5.9919247E-19
[DEBUG] 2018-05-22 11:38:50,031 -- BPR fold [5] iter 198: loss = 279.9093, delta_loss = 3.2345204, learn_rate = 1.1331587E-16
[DEBUG] 2018-05-22 11:38:50,039 -- BPR fold [8] iter 197: loss = 310.9, delta_loss = -0.18860051, learn_rate = 1.3587132E-19
[DEBUG] 2018-05-22 11:38:50,093 -- BPR fold [9] iter 198: loss = 301.31345, delta_loss = 1.5329309, learn_rate = 6.793566E-20
[DEBUG] 2018-05-22 11:38:50,106 -- BPR fold [2] iter 197: loss = 323.1067, delta_loss = 2.2460072, learn_rate = 1.2583043E-18
[DEBUG] 2018-05-22 11:38:50,111 -- BPR fold [3] iter 199: loss = 284.7797, delta_loss = -0.1794679, learn_rate = 5.6657935E-17
[DEBUG] 2018-05-22 11:38:50,134 -- BPR fold [6] iter 197: loss = 329.49628, delta_loss = 5.5967665, learn_rate = 2.8532975E-19
[DEBUG] 2018-05-22 11:38:50,138 -- BPR fold [1] iter 198: loss = 362.3831, delta_loss = -0.12490557, learn_rate = 2.9959624E-19
[DEBUG] 2018-05-22 11:38:50,155 -- BPR fold [4] iter 197: loss = 363.79398, delta_loss = 5.3847237, learn_rate = 3.5923067E-22
[DEBUG] 2018-05-22 11:38:50,169 -- BPR fold [10] iter 193: loss = 363.45892, delta_loss = 7.36332, learn_rate = 1.2070151E-20
[DEBUG] 2018-05-22 11:38:50,208 -- BPR fold [7] iter 198: loss = 309.8116, delta_loss = 0.9145918, learn_rate = 2.9959624E-19
[DEBUG] 2018-05-22 11:38:50,242 -- BPR fold [8] iter 198: loss = 309.5007, delta_loss = 1.3992736, learn_rate = 6.793566E-20
[DEBUG] 2018-05-22 11:38:50,279 -- BPR fold [5] iter 199: loss = 281.97678, delta_loss = -2.0674617, learn_rate = 1.1898166E-16
[DEBUG] 2018-05-22 11:38:50,329 -- BPR fold [9] iter 199: loss = 302.8551, delta_loss = -1.5416578, learn_rate = 7.133244E-20
[DEBUG] 2018-05-22 11:38:50,331 -- BPR fold [3] iter 200: loss = 284.94852, delta_loss = -0.16882089, learn_rate = 2.8328967E-17
[DEBUG] 2018-05-22 11:38:50,331 -- BPR fold [3] evaluate test data ... 
[DEBUG] 2018-05-22 11:38:50,334 -- BPR fold [3] has candidate items: 499
[DEBUG] 2018-05-22 11:38:50,362 -- BPR fold [6] iter 198: loss = 336.44684, delta_loss = -6.9505706, learn_rate = 2.9959624E-19
[DEBUG] 2018-05-22 11:38:50,392 -- BPR fold [2] iter 198: loss = 323.87735, delta_loss = -0.77067184, learn_rate = 1.3212194E-18
[DEBUG] 2018-05-22 11:38:50,448 -- BPR fold [4] iter 198: loss = 362.5532, delta_loss = 1.2407825, learn_rate = 3.7719221E-22
[DEBUG] 2018-05-22 11:38:50,454 -- BPR fold [1] iter 199: loss = 363.58658, delta_loss = -1.2034924, learn_rate = 1.4979812E-19
[DEBUG] 2018-05-22 11:38:50,468 -- BPR fold [10] iter 194: loss = 371.86646, delta_loss = -8.407524, learn_rate = 1.2673658E-20
[DEBUG] 2018-05-22 11:38:50,525 -- BPR fold [7] iter 199: loss = 312.7691, delta_loss = -2.957472, learn_rate = 3.1457606E-19
[DEBUG] 2018-05-22 11:38:50,582 -- BPR fold [8] iter 199: loss = 312.74942, delta_loss = -3.2487183, learn_rate = 7.133244E-20
[DEBUG] 2018-05-22 11:38:50,593 -- BPR fold [3] evaluates progress: 300 / 59
[DEBUG] 2018-05-22 11:38:50,599 -- BPR fold [5] iter 200: loss = 283.37305, delta_loss = -1.3962857, learn_rate = 5.949083E-17
[DEBUG] 2018-05-22 11:38:50,599 -- BPR fold [5] evaluate test data ... 
[DEBUG] 2018-05-22 11:38:50,600 -- BPR fold [5] has candidate items: 495
[DEBUG] 2018-05-22 11:38:50,633 -- BPR fold [3] evaluates progress: 100 / 59
[DEBUG] 2018-05-22 11:38:50,665 -- BPR fold [3] has writeen item recommendations to /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/BPR-top-10-items fold [3].txt
[DEBUG] 2018-05-22 11:38:50,682 -- BPR fold [9] iter 200: loss = 302.70248, delta_loss = 0.15263544, learn_rate = 3.566622E-20
[DEBUG] 2018-05-22 11:38:50,682 -- BPR fold [9] evaluate test data ... 
[DEBUG] 2018-05-22 11:38:50,698 -- BPR fold [5] has writeen item recommendations to /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/BPR-top-10-items fold [5].txt
[DEBUG] 2018-05-22 11:38:50,706 -- BPR fold [6] iter 199: loss = 339.32495, delta_loss = -2.8780913, learn_rate = 1.4979812E-19
[DEBUG] 2018-05-22 11:38:50,715 -- BPR fold [4] iter 199: loss = 366.85297, delta_loss = -4.2997828, learn_rate = 3.9605182E-22
[DEBUG] 2018-05-22 11:38:50,721 -- BPR fold [3]: Pre1: 0.000000, Pre3: 0.000000, Pre5: 0.000000, Pre10: 0.000000, Rec1: 0.000000, Rec3: 0.000000, Rec5: 0.000000, Rec10: 0.000000, F11: 0.000000, F13: 0.000000, F15: 0.000000, F110: 0.000000, AUC: 0.500000, MAP1: 0.000000, MAP3: 0.000000, MAP5: 0.000000, MAP10: 0.000000, NDCG: 0.000000, MRR: 0.000000	Time: 00:51, 00:00
[DEBUG] 2018-05-22 11:38:50,721 -- BPR fold [5]: Pre1: 0.000000, Pre3: 0.000000, Pre5: 0.000000, Pre10: 0.000000, Rec1: 0.000000, Rec3: 0.000000, Rec5: 0.000000, Rec10: 0.000000, F11: 0.000000, F13: 0.000000, F15: 0.000000, F110: 0.000000, AUC: 0.500000, MAP1: 0.000000, MAP3: 0.000000, MAP5: 0.000000, MAP10: 0.000000, NDCG: 0.000000, MRR: 0.000000	Time: 00:51, 00:00
[DEBUG] 2018-05-22 11:38:50,724 -- BPR fold [9] has candidate items: 496
[DEBUG] 2018-05-22 11:38:50,731 -- BPR fold [2] iter 199: loss = 320.13022, delta_loss = 3.7471488, learn_rate = 6.606097E-19
[DEBUG] 2018-05-22 11:38:50,745 -- BPR fold [1] iter 200: loss = 366.20142, delta_loss = -2.6148295, learn_rate = 7.489906E-20
[DEBUG] 2018-05-22 11:38:50,746 -- BPR fold [1] evaluate test data ... 
[DEBUG] 2018-05-22 11:38:50,748 -- BPR fold [1] has candidate items: 501
[DEBUG] 2018-05-22 11:38:50,776 -- BPR fold [10] iter 195: loss = 361.5956, delta_loss = 10.270826, learn_rate = 6.336829E-21
[DEBUG] 2018-05-22 11:38:50,837 -- BPR fold [9] has writeen item recommendations to /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/BPR-top-10-items fold [9].txt
[DEBUG] 2018-05-22 11:38:50,840 -- BPR fold [9]: Pre1: 0.000000, Pre3: 0.041667, Pre5: 0.025000, Pre10: 0.012500, Rec1: 0.000000, Rec3: 0.125000, Rec5: 0.125000, Rec10: 0.125000, F11: 0.000000, F13: 0.069444, F15: 0.041667, F110: 0.022727, AUC: 0.561995, MAP1: 0.000000, MAP3: 0.041667, MAP5: 0.041667, MAP10: 0.041667, NDCG: 0.062500, MRR: 0.041667	Time: 00:51, 00:00
[DEBUG] 2018-05-22 11:38:50,847 -- BPR fold [7] iter 200: loss = 311.32422, delta_loss = 1.4448901, learn_rate = 1.5728803E-19
[DEBUG] 2018-05-22 11:38:50,849 -- BPR fold [7] evaluate test data ... 
[DEBUG] 2018-05-22 11:38:50,853 -- BPR fold [7] has candidate items: 499
[DEBUG] 2018-05-22 11:38:50,887 -- BPR fold [8] iter 200: loss = 306.0859, delta_loss = 6.6635146, learn_rate = 3.566622E-20
[DEBUG] 2018-05-22 11:38:50,887 -- BPR fold [8] evaluate test data ... 
[DEBUG] 2018-05-22 11:38:50,889 -- BPR fold [8] has candidate items: 498
[DEBUG] 2018-05-22 11:38:50,891 -- BPR fold [1] evaluates progress: 500 / 61
[DEBUG] 2018-05-22 11:38:50,905 -- BPR fold [1] has writeen item recommendations to /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/BPR-top-10-items fold [1].txt
[DEBUG] 2018-05-22 11:38:50,906 -- BPR fold [1]: Pre1: 0.000000, Pre3: 0.000000, Pre5: 0.000000, Pre10: 0.000000, Rec1: 0.000000, Rec3: 0.000000, Rec5: 0.000000, Rec10: 0.000000, F11: 0.000000, F13: 0.000000, F15: 0.000000, F110: 0.000000, AUC: 0.500000, MAP1: 0.000000, MAP3: 0.000000, MAP5: 0.000000, MAP10: 0.000000, NDCG: 0.000000, MRR: 0.000000	Time: 00:52, 00:00
[DEBUG] 2018-05-22 11:38:50,938 -- BPR fold [7] evaluates progress: 200 / 60
[DEBUG] 2018-05-22 11:38:50,948 -- BPR fold [6] iter 200: loss = 335.03955, delta_loss = 4.2853856, learn_rate = 7.489906E-20
[DEBUG] 2018-05-22 11:38:50,948 -- BPR fold [6] evaluate test data ... 
[DEBUG] 2018-05-22 11:38:50,949 -- BPR fold [6] has candidate items: 499
[DEBUG] 2018-05-22 11:38:50,958 -- BPR fold [7] has writeen item recommendations to /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/BPR-top-10-items fold [7].txt
[DEBUG] 2018-05-22 11:38:50,959 -- BPR fold [2] iter 200: loss = 325.86148, delta_loss = -5.7312837, learn_rate = 6.936402E-19
[DEBUG] 2018-05-22 11:38:50,959 -- BPR fold [2] evaluate test data ... 
[DEBUG] 2018-05-22 11:38:50,962 -- BPR fold [7]: Pre1: 0.000000, Pre3: 0.000000, Pre5: 0.000000, Pre10: 0.000000, Rec1: 0.000000, Rec3: 0.000000, Rec5: 0.000000, Rec10: 0.000000, F11: 0.000000, F13: 0.000000, F15: 0.000000, F110: 0.000000, AUC: 0.500000, MAP1: 0.000000, MAP3: 0.000000, MAP5: 0.000000, MAP10: 0.000000, NDCG: 0.000000, MRR: 0.000000	Time: 00:52, 00:00
[DEBUG] 2018-05-22 11:38:50,964 -- BPR fold [2] has candidate items: 497
[DEBUG] 2018-05-22 11:38:50,966 -- BPR fold [4] iter 200: loss = 366.0107, delta_loss = 0.8422746, learn_rate = 1.9802591E-22
[DEBUG] 2018-05-22 11:38:50,966 -- BPR fold [4] evaluate test data ... 
[DEBUG] 2018-05-22 11:38:50,968 -- BPR fold [4] has candidate items: 497
[DEBUG] 2018-05-22 11:38:50,973 -- BPR fold [4] evaluates progress: 400 / 59
[DEBUG] 2018-05-22 11:38:50,983 -- BPR fold [8] has writeen item recommendations to /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/BPR-top-10-items fold [8].txt
[DEBUG] 2018-05-22 11:38:50,984 -- BPR fold [8]: Pre1: 0.000000, Pre3: 0.000000, Pre5: 0.000000, Pre10: 0.000000, Rec1: 0.000000, Rec3: 0.000000, Rec5: 0.000000, Rec10: 0.000000, F11: 0.000000, F13: 0.000000, F15: 0.000000, F110: 0.000000, AUC: 0.500000, MAP1: 0.000000, MAP3: 0.000000, MAP5: 0.000000, MAP10: 0.000000, NDCG: 0.000000, MRR: 0.000000	Time: 00:52, 00:00
[DEBUG] 2018-05-22 11:38:51,002 -- BPR fold [10] iter 196: loss = 368.2212, delta_loss = -6.6255693, learn_rate = 6.6536704E-21
[DEBUG] 2018-05-22 11:38:51,038 -- BPR fold [6] has writeen item recommendations to /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/BPR-top-10-items fold [6].txt
[DEBUG] 2018-05-22 11:38:51,038 -- BPR fold [2] has writeen item recommendations to /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/BPR-top-10-items fold [2].txt
[DEBUG] 2018-05-22 11:38:51,039 -- BPR fold [2]: Pre1: 0.000000, Pre3: 0.000000, Pre5: 0.000000, Pre10: 0.000000, Rec1: 0.000000, Rec3: 0.000000, Rec5: 0.000000, Rec10: 0.000000, F11: 0.000000, F13: 0.000000, F15: 0.000000, F110: 0.000000, AUC: 0.500000, MAP1: 0.000000, MAP3: 0.000000, MAP5: 0.000000, MAP10: 0.000000, NDCG: 0.000000, MRR: 0.000000	Time: 00:52, 00:00
[DEBUG] 2018-05-22 11:38:51,039 -- BPR fold [6]: Pre1: 0.000000, Pre3: 0.000000, Pre5: 0.000000, Pre10: 0.000000, Rec1: 0.000000, Rec3: 0.000000, Rec5: 0.000000, Rec10: 0.000000, F11: 0.000000, F13: 0.000000, F15: 0.000000, F110: 0.000000, AUC: 0.500000, MAP1: 0.000000, MAP3: 0.000000, MAP5: 0.000000, MAP10: 0.000000, NDCG: 0.000000, MRR: 0.000000	Time: 00:52, 00:00
[DEBUG] 2018-05-22 11:38:51,045 -- BPR fold [4] has writeen item recommendations to /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/BPR-top-10-items fold [4].txt
[DEBUG] 2018-05-22 11:38:51,046 -- BPR fold [4]: Pre1: 0.000000, Pre3: 0.000000, Pre5: 0.000000, Pre10: 0.000000, Rec1: 0.000000, Rec3: 0.000000, Rec5: 0.000000, Rec10: 0.000000, F11: 0.000000, F13: 0.000000, F15: 0.000000, F110: 0.000000, AUC: 0.500000, MAP1: 0.000000, MAP3: 0.000000, MAP5: 0.000000, MAP10: 0.000000, NDCG: 0.000000, MRR: 0.000000	Time: 00:52, 00:00
[DEBUG] 2018-05-22 11:38:51,084 -- BPR fold [10] iter 197: loss = 361.65924, delta_loss = 6.5619507, learn_rate = 3.3268352E-21
[DEBUG] 2018-05-22 11:38:51,133 -- BPR fold [10] iter 198: loss = 365.3249, delta_loss = -3.6656497, learn_rate = 3.493177E-21
[DEBUG] 2018-05-22 11:38:51,182 -- BPR fold [10] iter 199: loss = 372.14383, delta_loss = -6.8189297, learn_rate = 1.7465884E-21
[DEBUG] 2018-05-22 11:38:51,229 -- BPR fold [10] iter 200: loss = 367.1604, delta_loss = 4.983419, learn_rate = 8.732942E-22
[DEBUG] 2018-05-22 11:38:51,229 -- BPR fold [10] evaluate test data ... 
[DEBUG] 2018-05-22 11:38:51,230 -- BPR fold [10] has candidate items: 498
[DEBUG] 2018-05-22 11:38:51,251 -- BPR fold [10] has writeen item recommendations to /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/BPR-top-10-items fold [10].txt
[DEBUG] 2018-05-22 11:38:51,252 -- BPR fold [10]: Pre1: 0.000000, Pre3: 0.000000, Pre5: 0.000000, Pre10: 0.000000, Rec1: 0.000000, Rec3: 0.000000, Rec5: 0.000000, Rec10: 0.000000, F11: 0.000000, F13: 0.000000, F15: 0.000000, F110: 0.000000, AUC: 0.500000, MAP1: 0.000000, MAP3: 0.000000, MAP5: 0.000000, MAP10: 0.000000, NDCG: 0.000000, MRR: 0.000000	Time: 00:52, 00:00
[DEBUG] 2018-05-22 11:38:51,254 -- Evaluation for fold 1 has written to file: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/bpr_evalfolds.csv
[DEBUG] 2018-05-22 11:38:51,255 -- Evaluation for fold 2 has written to file: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/bpr_evalfolds.csv
[DEBUG] 2018-05-22 11:38:51,255 -- Evaluation for fold 3 has written to file: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/bpr_evalfolds.csv
[DEBUG] 2018-05-22 11:38:51,256 -- Evaluation for fold 4 has written to file: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/bpr_evalfolds.csv
[DEBUG] 2018-05-22 11:38:51,256 -- Evaluation for fold 5 has written to file: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/bpr_evalfolds.csv
[DEBUG] 2018-05-22 11:38:51,257 -- Evaluation for fold 6 has written to file: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/bpr_evalfolds.csv
[DEBUG] 2018-05-22 11:38:51,258 -- Evaluation for fold 7 has written to file: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/bpr_evalfolds.csv
[DEBUG] 2018-05-22 11:38:51,259 -- Evaluation for fold 8 has written to file: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/bpr_evalfolds.csv
[DEBUG] 2018-05-22 11:38:51,259 -- Evaluation for fold 9 has written to file: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/bpr_evalfolds.csv
[DEBUG] 2018-05-22 11:38:51,260 -- Evaluation for fold 10 has written to file: /Users/igorsantana/Projects/v2-tcc-pesquisa/datasets/CARSKit.Workspace/bpr_evalfolds.csv
[ERROR] 2018-05-22 11:38:51,262 -- 
